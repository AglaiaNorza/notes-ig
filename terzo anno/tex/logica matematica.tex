%! TEX program = xelatex
\documentclass[a4paper,11pt]{report}

\usepackage{./../packages/mainstyle}
\usepackage{./../packages/colors}
\usepackage{./../packages/frameboxes}
\usepackage{./../packages/title}
\usepackage{./../packages/packs}
\usepackage{./../packages/macros}

\usepackage[italian]{babel}

\usepackage{float}
\usepackage{enumitem}
\usepackage{bussproofs}
\usepackage{mdframed}

\newcommand{\Ra}{R^{\mathcal{A}}}
\newcommand{\fa}{f^{\mathcal{A}}}
\newcommand{\ca}{c^{\mathcal{A}}}

\newcommand{\SAT}{\texttt{SAT}}
\newcommand{\UNSAT}{\texttt{UNSAT}}
\newcommand{\TAUT}{\texttt{TAUT}}

\newcommand{\ass}[2]{%
    \left( \begin{smallmatrix} #1 \\ #2 \end{smallmatrix} \right)
}

% usage: \tworowmatrix{a & b & c}{1 & 2 & 3}
\NewDocumentCommand{\tworowmatrix}{ m m }{
    \begin{bmatrix}
        #1 \\
        #2
    \end{bmatrix}
}

\setcoursename{Logica Matematica}
\setcoursebook{tbd}
\setauthorname{aglaia norza}
\setauthoremail{thisisaglaia@gmail.com}
\setauthorgithub{AglaiaNorza}

\begin{document}

\maketitle

\tableofcontents

\chapter{Logica Proposizionale}

\section{Introduzione}

La logica proposizionale è un linguaggio formale con una semplice struttura sintattica basata su proposizioni elementari (atomiche) e sui seguenti connettivi logici:


\begin{itemize}
    \item \textit{Negazione} ($\neg$): inverte il valore di verità di un enunciato: se un enunciato è vero, la sua negazione è falsa, e viceversa.

    \item \textit{Congiunzione} ($\land$): il risultato è vero se e solo se entrambi i componenti sono veri.

    \item \textit{Disgiunzione} ($\lor$): il risultato è vero se almeno uno dei componenti è vero.

    \item \textit{Implicazione} ($\to$): rappresenta l’enunciato logico “se ... allora”. Il risultato è falso solo se il primo componente è vero e il secondo è falso. 

    \item \textit{Equivalenza} ($\leftrightarrow$): rappresenta l’enunciato logico “se e solo se”. 
        Il risultato è vero quando entrambi i componenti hanno lo stesso valore di verità, cioè sono entrambi veri o entrambi falsi.
\end{itemize}

Introduciamo anche il concetto di disgiunzione esclusiva o "XOR" (\( \oplus \)), il cui risultato è vero solo se gli operandi sono diversi tra di loro (uno vero e uno falso).

\begin{defframe}{Linguaggio proposizionale}{}
    Un linguaggio proposizionale è un insieme infinito \( \mathcal{L} \) di simboli detti \textbf{variabili proposizionali}, tipicamente denotato come \( \{p_i : i \in I\} \) {\color{gray} (con \( I \) "insieme di indici")}.
\end{defframe}

\begin{defframe}{Proposizione}{}
    Una \textbf{proposizione} in un linguaggio proposizionale è un elemento dell'insieme PROP così definito:
    \begin{enumerate}
        \item tutte le variabili appartengono a PROP
        \item se \( A \in \) PROP, allora \( \neg A \in \) PROP
        \item se \( A, B \in \) PROP, allora \( (A \land B), (A \lor B), (A \to B) \in \) PROP
        \item nient'altro appartiene a PROP {\color{gray}(PROP è il più piccolo insieme che contiene le variabili e soddisfa le proprietà di chiusura sui connettivi 1 e 2)}
    \end{enumerate}
\end{defframe}

Per facilitare la leggibilità delle formule, definiamo le seguenti regole di \textit{precedenza}: \( \neg \) ha precedenza su \( \land, \lor \), e questi ultimi hanno precedenza su \( \to \).

\section{Assegnamenti, tavole di verità}

Per un linguaggio \( \mathcal{L} \), un \textbf{assegnamento} è una funzione 
\[
    \alpha : \mathcal{L} \to \{0, 1\}
\]

Estendiamo \( \alpha \) ad \( \hat{\alpha} : \text{PROP} \to \{0,1\} \) in questo modo:
\vspace{0.5em}
\begin{itemize}
    \item \( \hat{\alpha}(\neg A) = \begin{cases}
            1 &  A = 0 \\
            0 & A = 1
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \land B) = \begin{cases}
            1 & \hat{\alpha}(A) = \hat{\alpha}(B)  = 1 \\
            0 & altrimenti
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \lor B) = \begin{cases}
            0 & \hat{\alpha}(A) = \hat{\alpha}(B)  = 0 \\
            1 & altrimenti
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \to B) = \begin{cases}
            0 & \hat{\alpha}(A) = 1 \land \hat{\alpha}(B)  = 0 \\
            1 & altrimenti
        \end{cases}\)

\end{itemize}

\begin{gframe}{notazione}
    Utilizzeremo \( \alpha \) al posto di \( \hat{\alpha} \) per comodità di notazione.
\end{gframe}

Osserviamo che è possibile rappresentare gli assegnamenti in modo compatto utilizzando le \textbf{tavole di verità}, una presentazione tabulare della funzione di assegnamento.

Per esempio, possiamo riscrivere la definizione di \( \alpha(\neg A) \) come segue:

\[  
    \begin{array}{c | c}
        A & \neg A \\
        \hline
        0 & 1 \\
        1 & 0

    \end{array}
\]

Ogni riga di una tavola di verità corrisponde ad un assegnamento \( \alpha \).

Si noti anche che dalla definizione di \( \alpha \) segue che un'implicazione può essere vera senza che ci sia connessione causale o di significato tra antecedente e conseguente (per esempio, "se tutti i quadrati sono pari allora \( \pi \) è irrazionale"). 

In secondo luogo, segue anche che una proposizione è sempre vera se il suo antecedente è falso (il che rispecchia la pratica matematica di considerare vera a vuoto una proposizione ipotetica la cui premessa non si applica).


{\color{CadetBlue} Questo è giustificabile come segue:
    \begin{itemize}
        \item vogliamo che \( (A \land B) \to B \) sia sempre vera
        \item il caso \( 1 \to 1 \) deve essere vero, perché corrisponde al caso in cui \( A \) e \( B \) sono vere; 

            il caso \( 0 \to 0  \) deve essere vero, perché corrisponde al caso in cui \( A\land B \) è falso perché \( B \) è falso; il caso \( 0 \to 0 \) deve essere vero perché corrisponde al caso in cui \( A \land B \) è falso perché \( B \) è falso; 

            il caso \( 0 \to 1 \) deve essere vero perché corrisponde al caso in cui \( A \land B \) è falso perché \( A \) è falso ma \( B \) è vero; 

            resta dunque soltanto il caso \( 1 \to 0 \), che non corrisponde a nessun caso di \( A \land B \to B \).
    \end{itemize}

In più, si vuole che valga, per contrapposizione \( (A \to B)\to(\neg B \to \neg A) \).}

\label{asseq}
Osserviamo che, data \( A = p_1, p_2, \dots, p_k \) e due assegnamenti \( \alpha \) e \( \beta \) t.c.:
\begin{align*}
    \alpha(p_1) &= \beta(p_1) \\
                &\dots \\
    \alpha(p_k) &= \beta(p_k)
\end{align*}

allora necessariamente \( \alpha(A) = \alpha(B) \). 

\begin{gframe}[colframe=PineGreen]{soddisfacibilità}
    Se per una formula \( A \) e un assegnamento \( \alpha \) si ha \( \alpha (A) = 1 \), si dice che ``\(A \) soddisfa \( \alpha \)'' (o ``\( A \) è vera sotto \( \alpha \)'').
    \begin{itemize}
        \item Se \( A \) ha almeno un assegnamento che la soddisfa, si dice \textbf{soddisfacibile} (\( A \in \texttt{SAT} \)).
        \item Se non esiste un assegnamento che la soddisfa, \( A \) si dice \textbf{insoddisfacibile} (\( A \in \texttt{UNSAT} \)).
        \item Se \( A \) è soddisfatta da tutti i possibili assegnamenti, si dice \textbf{tautologia} (o "verità logica") (\( A \in \texttt{TAUT} \)).
    \end{itemize}
\end{gframe}

Introduciamo anche alcune regole che 

\section{Conseguenza logica}

\begin{defframe}{Conseguenza logica}{}
    Sia \( T \) una \textit{teoria}, ossia un insieme  \( \{A_1, \dots, A_n\} \) proposizioni in un dato linguaggio proposizionale, e sia \( A \in \text{PROP}\) .

    Diciamo che \( A \) è \textbf{conseguenza logica} di \( T\) se 
    \[ \forall \alpha,\ \alpha(T)=1 \to \alpha(A)=1 \] 
    ovvero se ogni assegnamento che soddisfa \(T\) soddisfa anche \( A_{n+1} \).

    Scriviamo in tal caso \(  T \vDash A_{n+1} \), oppure \( A_1, \dots, A_n \vDash A \).
\end{defframe}

Si ha che:
\begin{itemize}
    \item \(T \not\vDash A\) \ significa che \ \( \exists \alpha \) \ t.c. \ \( \alpha(T) = 1 \land \alpha(A) = 0 \)
    \item \( \emptyset \vDash A \) \ o, equivalentemente \ \( \vDash A \iff A\) è una tautologia
\end{itemize}

\begin{lemmaframe}{Equivalenze}{}
    \begin{enumerate}
        \item \( T \vDash A \)
        \item \( \vDash (A_1 \land \dots \land A_n) \to A \)
        \item \( (A_1 \land \dots \land A_n) \in \texttt{UNSAT}\) 
    \end{enumerate}

    sono equivalenti.

\end{lemmaframe}

\section{Completezza funzionale}
\textit{Data una tavola di verità arbitraria con \( n \) argomenti, esiste una proposizione \( A \) che ha esattamente quella tavola di verità?}

Una proposizione \( A \) contenente le \( n \) variabili proposizionali \( a_1, a_2, \dots, a_n \) determina una funzione di \( n \) argomenti \( f: \{0, 1\}^n \to \{0,1\} \) ("\textbf{funzione di verità}"), tale che il valore di \( f_A \) su un argomento \ \( (x_1, x_2, \dots, x_n) \in \{0,1\}^n\) \ sia dato da un arbitrario assegnamento \( \alpha \) tale che \( \alpha(p_k) = x_k\) \ per \ \(k \in [1,n] \).

\begin{thmframe}{Teorema}{}
    Sia \( f: \{0, 1\}^n \to \{0,1\} \) una funzione di verità. Esiste una proposizione \( A \) con \( n \) variabili proposizionali tale che, per ogni assegnamento \( \alpha \):
    \[ \alpha(A) = f(\alpha(a_1), \alpha(a_2), \dots, \alpha(a_n)) \]
\end{thmframe}

\begin{proofframe}[title=dimostrazione]           
    Si dimostra per induzione su \( n \).

    \begin{itemize}
        \item \textbf{caso base}: \( n=1 \)
            abbiamo quattro possibili \( f \): 
            \[
                \begin{aligned}
                    f_1(0) &= 0, \quad f_1(1) = 0 \\
                    f_2(0) &= 1, \quad f_2(1) = 1 \\
                    f_3(0) &= 0, \quad f_3(1) = 1 \\
                    f_4(0) &= 1, \quad f_4(1) = 0
                \end{aligned}
            \]

            Alla funzione $f_1$ corrisponde la formula $(p \land \neg p)$, alla funzione $f_2$ la formula $(p \lor \neg p)$, 
            alla funzione $f_3$ la formula $p$, e alla funzione $f_4$ la formula $(\neg p)$.
        \item \textbf{caso induttivo}: (assumiamo che il teorema valga per \( n-1 \) variabili, e dimostriamo che vale per \( n \))

            Se $n > 1$, scriviamo il grafico di 
            \[
                f : \{0,1\}^n \to \{0,1\}
            \]

            in forma di tavola di verità in questo modo:

            \[
                \begin{array}{cccc|c|l}
                    p_1 & p_2 & \cdots & p_n & f(p_1, \ldots, p_n) & \\ \hline
                    0 & \cdots & \cdots & 0 & \cdots &  \\
                    \vdots & & & \vdots & \vdots & \text{grafico di una funzione } f_0\\
                    0 & \cdots & \cdots & 1 & \cdots & \\ \hline
                    1 & \cdots & \cdots & 0 & \cdots &  \\
                    \vdots & & & \vdots & \vdots & \text{grafico di una funzione } f_1\\
                    1 & \cdots & \cdots & 1 & \cdots & 
                \end{array}
            \]

            Se non consideriamo la prima colonna (\( p_1 \)), la tavola di verità descrive il grafico di due funzioni, \( f_0 \) e \( f_1 \), a \( n-1 \) argomenti.

            Sappiamo, quindi, per ipotesi induttiva, che esistono due formule \( A_0 \) e \( A_1 \) a \( n-1 \) variabili tali che, per ogni assegnamento \( \alpha \):
            \[ \alpha(A_0) = f_0(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]
            \[ \alpha(A_1) = f_1(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]

            Dobbiamo ora combinare le due formule considerando anche la colonna \( p_1 \).

            Possiamo farlo tramite la formula \(A= (\neg p_1 \to A_0) \land (p_1 \to A_1) \).

            Dimostriamo che \( A \) soddisfa il teorem: dobbiamo dimostrare che, dato un assegnamento qualsiasi \( \alpha \), si ha:
    \[ \alpha(A) = f(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]

    Distinguiamo i due casi:
    \begin{itemize}
        \item \( \alpha(p_1) = 1 \) 

            in questo caso, si ha:
            \[
                \alpha\!\left(
                    \underset{=1}{(\neg p_1 \to A_0)}
                    \land
                \underset{=1}{(p_1} \to A_1)
                \right)
            \]

            e la formula vale quindi \( 1 \iff \alpha(A_1) = 1 \).

            Ma \( \alpha(A_1) = f_1(\alpha(p_2), \dots, \alpha(p_n)) \), quindi la formula si comporta esattamente come \( f_1 \):
            \[
                f(\alpha(p_1), \alpha(p_2), \ldots, \alpha(p_n))
                = f(1, \alpha(p_2), \ldots, \alpha(p_n))
                = f_1(\alpha(p_2), \ldots, \alpha(p_n)).
            \]

            Quindi, in questo caso, vale 
            \[\alpha(A) = (\alpha(p_1), \alpha(p_2), \ldots, \alpha(p_n))\]

        \item \( \alpha(p_1) = 0 \)            

            in questo caso, si ha:
            \[
                \alpha\!\left(
                    \underset{=1}{(\neg p_1} \to A_0)
                    \land
                    \underset{=1}{(p_1 \to A_1})
            \right)\]

            che vale \( 1 \iff \alpha(A_0)=1\).

            Quindi si può fare lo stesso ragionamento di sopra, ma per \( A_1 \) e \( f_0 \).

            \begin{gframe}{}
                Potremmo anche costruire una funzione \( f \) che rappresenta il comportamento di \( A \):

                \[ f(x_1, x_2, \ldots, x_n) =
                    \begin{cases}
                        f_1(x_2, \ldots, x_n) & \text{se } x_1 = 1, \\
                        f_0(x_2, \ldots, x_n) & \text{se } x_1 = 0.
                    \end{cases}
                \]
            \end{gframe}

    \end{itemize}

\end{itemize}

\end{proofframe}

\section{Forme normali}

\begin{gframe}{notazione}
    Chiamiamo "letterale" una variabile proposizionale o una negazione di una variabile proposizionale
\end{gframe}

È utile individuare alcune forme normali canoniche.

\begin{defframe}{Forma Normale Disgiuntiva}{}
    Diciamo che \( A \) è in Forma Normale Disgiuntiva (\textbf{DNF}, \textit{Disjunctive Normal Form}) se \( A \) è una disgiunzione di congiunzioni di letterali, ossia è nella forma seguente:

    \[ \bigvee_{i\leq n} \bigwedge_{j\leq m_i} A_{ij} = (A_{1,1} \land \dots \land A_{1, m_1}) \lor \dots \lor (A_{n,1} \land \dots \land A_{n, m_n}) \]

\end{defframe}

\begin{defframe}{Forma Normale Congiuntiva}{}
    Diciamo che \( A \) è in Forma Normale Congiuntiva (\textbf{CNF}, \textit{Conjunctive Normal Form}) se \( A \) è una disgiunzione di congiunzioni di letterali, ossia è nella forma seguente:

    \[ \bigwedge_{i\leq n} \bigvee_{j\leq m_i} A_{ij} = (A_{1,1} \lor \dots \lor A_{1, m_1}) \land \dots \land (A_{n,1} \lor \dots \lor A_{n, m_n}) \]

\end{defframe}

\section{Equivalenza Logica}

\begin{cdefframe}{DeepGreenLight}{PineGreen}{Equivalenza logica}{}
    Due formule \( A, B \in \text{PROP} \) sono logicamente equivalenti (\( A \equiv B \)) quando, per ogni assegnamento \( \alpha \) si ha \( \alpha(A) = \alpha(B) \).
\end{cdefframe}


Introduciamo alcune regole utili per verificare l'equivalenza tra proposizioni.

Con un piccolo abuso di notazione, definiamo \( 1 \) e \( 0 \) come le formule per cui \( \forall \alpha, \ \alpha(1)= 1 \) e \( \alpha(0) = 0 \).

In questo modo, abbiamo:

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Involuzione} & $\neg\neg A \equiv A$ \\
        \hline
        \textbf{Assorbimento (con 0 e 1)} &
        $A \lor 0 \equiv A$ \\
                                          & $A \land 1 \equiv A$ \\
                                          \hline
        \textbf{Cancellazione} &
        $A \lor 1 \equiv 1$ \\
                               & $A \land 0 \equiv 0$ \\
                               \hline
        \textbf{Terzo escluso (\textit{tertium non datur})} &
        $A \lor \neg A \equiv 1$ \\
                                                            & $A \land \neg A \equiv 0$ \\
                                                            \hline
        \textbf{Leggi di De Morgan} &
        $\neg(A \lor B) \equiv \neg A \land \neg B$ \\
                                    & $\neg(A \land B) \equiv \neg A \lor \neg B$ \\
                                    \hline
        \textbf{Commutatività} &
        $A \lor B \equiv B \lor A$ \\
                               & $A \land B \equiv B \land A$ \\
                               \hline
        \textbf{Associatività} &
        $A \lor (B \lor C) \equiv (A \lor B) \lor C$ \\
                               & $A \land (B \land C) \equiv (A \land B) \land C$ \\
                               \hline
        \textbf{Distributività} &
        $A \lor (B \land C) \equiv (A \lor B) \land (A \lor C)$ \\
                                & $A \land (B \lor C) \equiv (A \land B) \lor (A \land C)$ \\
                                \hline
        \textbf{I teorema di assorbimento} &
        $A \lor (A \land B) \equiv A$ \\
                                           & $A \land (A \lor B) \equiv A$ \\
                                           \hline
        \textbf{II teorema di assorbimento} &
        $A \lor (\neg A \land B) \equiv A \lor B$ \\
                                            & $A \land (\neg A \lor B) \equiv A \land B$ \\
                                            \hline

    \end{tabular}
    \caption{Principali leggi di equivalenza logica}
\end{table}

\section{Formalizzazioni in logica proposizionale}

Il concetto di soddisfacibilità ci permette di usare insiemi di formule proposizionali per catturare determinate strutture matematiche.

Per esempio: sia \( X \) un insieme. Consideriamo il linguaggio proposizionale composto dalle variabili \(p_{(x, y)}  \) per ogni \( (x,y) \in X \times X\), e consideriamo il seguente insieme \( T \) di proposizioni in questo linguaggio:

\begin{enumerate}
    \item \( \neg p_{x,x} \ \ \forall x \in X\) \ {\color{gray}(antiriflessività)}
    \item \( p_{x, y} \to \neg p_{y,x} \ \   \forall x \in X\) \ {\color{gray}(asimmetria)}
    \item \( (p_{x, y} \land p_{y, z}) \to p_{x, z} \ \ \forall x, y, z \in X\) \ {\color{gray}(transitività)}
\item \( (p_{x, y} \lor p_{y, x}) \  \ \forall x \neq  y \in X\) \ {\color{gray}(ordine totale)}
\end{enumerate}

Usiamo una teoria \( T \) per poter gestire anche casi di insiemi infiniti. Infatti, sappiamo che una teoria infinita è soddisfatta se e solo se lo sono tutte le sue proposizioni.

L'insieme \( T = T_X \) esprime il concetto di \textbf{ordine totale stretto} su \( X \). Infatti, se avessimo un assegnamento \( \alpha \) che soddisfa tutte le proposizioni di \( T \), l'ordine indotto da tutte le variabili vere sotto \( \alpha \) sarebbe un ordine totale stretto di \( X  \).

Se \( \alpha \) è un assegnamento, definiamo la relazione \( \prec_{\alpha} \) su \( X \) come segue:
\[ x \prec_\alpha y \leftrightarrow \alpha(p_{x,y})=1 \]

Si ha che per ogni assegnamento \( \alpha \) che soddisfca \( T_X \), l'ordine \( \prec_\alpha \) indotto da \( \alpha \) è un ordine totale stretto su \( X \).

Dall'altra parte, se \( \prec \) è un ordine totale stretto su \( X \), e \( \alpha_\prec \) è l'assegnamento indotto da \( \prec \) così definito:
\[ \alpha_\prec (p_{x,y}) = 1 \leftrightarrow (x \prec y) \]

Si ha che, per ogni ordine totale stretto \( \prec \) su \(X \), l'assegnamento \( \alpha_\prec \) indotto da \( \prec \) sulle variabili \( p_{x, y} \) soddisfa \( T \).

Ovvero, un assegnamento \( \alpha \) soddisfa la teoria \( T_X \) se e solo se l'ordine indotto da \( \alpha \) su \( X \) è un ordine totale.

\begin{gframe}{Colorabilità}

\end{gframe}

\section{Teorema di compattezza}

\begin{defframe}{Monotonia della conseguenza logica}{}
    Si dice che la nozione di conseguenza logica è \textbf{monotona}, ovvero che \[T' \vDash A \land T' \subseteq T \implies T \vDash A\]
    (se \( A_1, A_2, \dots, A_k \vDash A \), allora \( T \vDash A \) per ogni teoria \( T \) contenente \( A_1, A_2, \dots, A_k \))
\end{defframe}

Nonostante non sembri intuitivamente vero, vale anche il viceversa:

\begin{thmframe}{Teorema di compattezza v.1}{}
    Se \( T \vDash A \), esiste un sottoinsieme finito \( T_0 \) di \( T \) tale che \( T_0 \vDash A \)
\end{thmframe}

Introduciamo il concetto di una teoria finitamente soddisfacibile:

\begin{defframe}{\texttt{FINSAT}}{}
    Una teoria si dice \textbf{finitamente soddisfacibile} (\( \in \texttt{FINSAT} \)) se \textit{ogni} suo sottoinsieme finito è soddisfacibile.
\end{defframe}

Possiamo quindi introdurre una nuova versione del teorema di compattezza:

\begin{thmframe}{Teorema di compattezza v.2}{}
    \( \texttt{FINSAT}\implies \texttt{SAT} \), ovvero se ogni sottoinsieme di \( T \) è soddisfacibile, anche \( T \) è soddisfacibile.
\end{thmframe}

\begin{lemmaframe}{Teorema di compattezza v.1 \( \equiv \) v.2}{}
    I due punti seguenti (le due versioni del teorema di compattezza) sono equivalenti:
    \begin{enumerate}
        \item \( T \vDash A \iff \exists \ T_0 \overset{fin}{\subseteq} T \ t.c. \  T_0 \vDash A\)
        \item \( T \in \texttt{SAT} \iff T \in \texttt{FINSAT} \)
    \end{enumerate}

    \begin{pframe}{}
        \begin{itemize}
            \item \textcircled{1} \( \implies \) \textcircled{2}

                Supponiamo per assurdo che \( T \in \texttt{FINSAT} \implies T \in \texttt{SAT} \), e che \( T \vDash A \) ma che \( \forall T_0 \overset{fin}{\subseteq } T, \ T_0 \not\vDash A \).

                \( T \not\vDash A \) significa \( T \cup \{\neg A\} \in \texttt{SAT} \).
                
                Quindi, visto che \( \texttt{FINSAT} \implies \texttt{SAT} \), \( T \cup \{ \neg A\} \in \texttt{SAT}\), il che va in contraddizione con l'ipotesi \( T \vDash A \).
            \item \textcircled{2} \( \implies \) \textcircled{1}

                Supponiamo per assurdo che \( T\vDash A \implies \exists T_0  \overset{fin}{\subseteq } T \ t.c. \ T_0 \vDash A\), che \( T\in \texttt{FINSAT} \), ma che \( T\not \in \texttt{SAT} \) (\( T\in \texttt{UNSAT} \)).

                Se \( T \in \texttt{UNSAT} \), possiamo dire che \( T \vDash p \land \neg p \) {\small \color{gray} (tutto è conseguenza logica di una teoria insoddisfacibile)}.

                Per \textcircled{2}, quindi, \( \exists T_0 \ t.c, \ T_0 \overset{fin}{\subseteq } T \vDash p \land \neg p \), il che va in contraddizione con \( T \in \texttt{FINSAT} \).\qed
        \end{itemize}

    \end{pframe}

\end{lemmaframe}

\begin{thmframe}{Estendibilità di \texttt{SAT}}{}
    Se \( T \) è soddisfacibile, allora \( T \cup \{A\} \) è soddisfacibile oppure \( T \cup \{\neg A\} \) è soddisfacibile.

    \begin{proofframe}[title=dimostrazione dalle dispense]{}
        Sia \( \alpha \) un assegnamento che soddisfa \( T \). Se \( \alpha(A)=1 \) allora \( T \cup \{A\} \) è soddisfacibile. Se \( \alpha(A) = 0 \),  \( T \cup \{\neg A\} \) è soddisfacibile.
    \end{proofframe}
    \begin{proofframe}[title=dimostrazione vista in classe]{}
        Supponiamo \( T \in \texttt{SAT} \), \ \( T \cup \{A\} \in \texttt{UNSAT}\) \ e \ \( T \cup \{\neg A\} \in \texttt{UNSAT}\). Avremmo entrambi \( T \vDash \{\neg A\}\) e \( T \vDash A \), il che è impossibile se \( T\in \texttt{SAT} \).
    \end{proofframe}
\end{thmframe}

Un concetto analogo vale per \texttt{FINSAT}.

\begin{thmframe}{Estendibilità di \texttt{FINSAT}}{}
    Sia \( T \in \texttt{FINSAT} \). Per ogni formula \( A, \  T \cup \{A\} \in \texttt{FINSAT}\)  \ o \( \ T \cup \{\neg A\} \in \texttt{FINSAT}\)
    \begin{pframe}{}
        Supponiamo per assurdo che \( T \cup \{A\} \not\in \texttt{FINSAT}\) e \( T \cup \{\neg A\} \not\in \texttt{FINSAT}\).

        Vuol dire che esistono \( B \ \overset{fin}{\subseteq} T \cup \{A\}\) \ e \ \( C \ \overset{fin}{\subseteq} T \cup \{\neg A\}\) insoddisfacibili.

        Dato che per ipotesi \( T \in \texttt{FINSAT} \), sappiamo che \( A \in B, C \). Possiamo quindi introdurre \( \hat B = B \setminus \{A\}\) e \( \hat C = C \setminus \{A\}\).

        Sappiamo che l'insieme \( \hat B \cup \hat C  \in \texttt{FINSAT}\), in quanto sottoinsieme finito di \( T \).

        Sia \( \alpha \) un assegnamento che lo soddisfa. Se \( \alpha(A)=1 \), allora soddisfa anche \( B \). Se \( \alpha(A) = 0 \), soddisfa anche \( C \). In entrambi i casi abbiamo una contraddizione.

    \end{pframe}

\end{thmframe}

\subsection{Dimostrazione per i linguaggi numerabili}

\begin{gframe}[colframe=DeepGreen, colback=DeepGreenLight]{}
    Sia \( T\) in un linguaggio numerabile. \( T \in \texttt{FINSAT} \implies T\in \texttt{SAT}\).
\end{gframe}

Supponiamo \( \mathcal{L}=\{p_1, p_2, \dots\}\) numerabile. 

Definiamo una ``catena'' di teorie come segue:
\begin{itemize}
    \item \( T_0 = T \)
    \item \( T_1 = \begin{cases}
            T_0 \cup \{p_1\} & T_0 \cup \{p_1\} \in \texttt{FINSAT} \\
            T_0 \cup \{\neg p_1\} & T_0 \cup \{\neg p_1\} \in \texttt{FINSAT}
        \end{cases} \)

        \hspace{1em}\vdots

    \item \( T_{n+1} = \begin{cases}
            T_n \cup \{p_{n+1}\} & T_0 \cup \{p_{n+1}\} \in \texttt{FINSAT} \\
            T_n \cup \{\neg p_{n+1}\} & T_0 \cup \{\neg p_{n+1}\} \in \texttt{FINSAT}
        \end{cases} \)
\end{itemize}

(aggiungiamo quindi proposizioni una alla volta in modo che \( T_i \) resti \texttt{FINSAT})

\begin{gframe}{}
    (la definizione è ben posta per l'estendibilità di \texttt{FINSAT} )
\end{gframe}

Avremo quindi \( {\color{gray} T = }\ T_0 \subseteq T_1 \subseteq T_2 \subseteq \dots \)

Definiamo \[ T^* = \bigcup_{n\in \mathbb{N}} T_n \]

Sappiamo che \( T^* \in \texttt{FINSAT} \) perché \( \forall X = \{A_1, A_2, \dots, A_k\} \overset{fin}{\subseteq} T^*\), esiste \( n^* \) t.c. \( X \subseteq T_{n^*} \).

(\( T \) è costruito come una catena crescente, quindi ogni suo sottoinsieme finito è un sottoinsieme di uno degli insiemi della catena - quello con ``pedice massimo'';
per esempio, se \( X = \{A_1, A_2\} \) con \( A_1 = \{p_1\}, \ A_2 = \{p_3, p_5\}\), avremo \( X \subseteq T_5 \))

Visto che, per costruzione, \( \forall p_n \) vale \( ( p_n \in T^* \oplus \neg p_n \in T^* )\), possiamo definire un assegnamento:
\[ \alpha^*(p_n) = \begin{cases}
    1 & p_n \in T^* \\
    0 & p_n \not\in T^* \\
\end{cases} \]

\begin{gframe}[colframe=DeepTeal, colback=DeepTealLight]{}
    \textbf{Claim}: \( \alpha^*(T) = 1 \)
    
    {\small\color{gray}(avremmo \( T\in \texttt{SAT} \), quindi avremmo finito)}
\end{gframe}

Dobbiamo quindi dimostrare che \( \forall A \in T, \alpha^*(A) = 1 \).

Abbiamo \( A = \{p_{i1}, \dots, p_{i_k} \}\in T\).

Introduciamo la notazione: \( p_n^* = \begin{cases}
    p_n & p_n \in T^* \  \ {\color{gray} (\alpha^*(p_n)=1)} \\
    \neg p_n & \neg p_n \in T^* \  \ {\color{gray} (\alpha^*(p_n)=0)} \\
\end{cases} \)

Poiché \( A\in T \subseteq T^* \) e \( \{p^*_{i1}, \dots, p^*_{ik}\} \), abbiamo \( A^* = A \cup \{p^*_{i1}, \dots, p^*_{ik}\} {\color{gray}= \{A, p^*_{i1}, \dots, p^*_{ik}\}} \overset{fin}{\subseteq } T^*\).

Dato che \( T^* \in \texttt{FINSAT}, \ \exists \beta \) t.c. \( \beta(A^*)=1 \) (il che può succedere solo se \( \beta(A) = 1 \ \land \ \beta(p^*_{ij}) = 1 \ \forall j \in [k] \)).

Ma, poiché \( \beta(p^*_{ij}) = 1 \ \forall j \in [k]  \), notiamo che necessariamente \( \beta(p_j) = 1  \) se \( p_j \in T^* \) e \( \beta(p_j) = 0  \) se \( p_j \neg\in T^* \). Dunque, notiamo che \( \beta \) e \( \alpha^* \) si comportano allo stesso modo per ogni variabile \( p_{i1}, \dots, p_{ik} \).

Da questo (e dall'osservazione a fine pagina \pageref{asseq}), poiché \( p_{i1}, \dots, p_{ik} \) sono le variabili che compongono \( A \), segue che \( \alpha(A) = \alpha(B) \).

Ma \( \beta(A) = 1 \) per scelta di \( \beta \), quindi \( \alpha^*(A) = 1 \). Visto che possiamo applicare lo stesso ragionamento ad ogni \( A \in T \), si ha che \( \alpha^*(T) = 1 \), ovvero \( T \in \texttt{SAT} \) \qed

{\small \color{gray}(ogni proposizione che va verificata, in quanto finita, riguarda solo un sottoinsieme di \(T  \), e crea quindi un ``bottleneck'')}

\subsection{Dimostrazione per i linguaggi arbitrari}

\begin{lemmaframe}{Lemma di Zorn}{}
    Sia \( X \) un insieme, e \( \leq \ \subseteq X^2 \) una relazione di \textbf{ordine parziale} (riflessiva, antisimmetrica e transitiva) su \( X \). 
    Definiamo, in \( X \), i concetti di:
    \begin{itemize}
        \item catena \( C \) = sottoinsieme di \( X \) i cui elementi sono a due a due confrontabili via \( \leq  \)
        \item maggiorante = elemento \( x \in X \) t.c. \( \forall y \in C, \ y\leq x \)
    \end{itemize}
    Il \textbf{lemma di Zorn} afferma che, se per ogni catena \( C \) in \( X \) esiste un \textbf{maggiorante} in \( X \), allora esiste un elemento \( m \in X \) \textbf{massimale}.
\end{lemmaframe}

Il Lemma di Zorn è una forma dell'Assioma della Scelta (che, informalmente, afferma che quando viene data una collezione di insiemi non vuoti si può sempre costruire un nuovo insieme ``scegliendo'' un singolo elemento da ciascuno di quelli di partenza).

A noi basta considerare come relazione d'ordine l'inclusione insiemistica \( \subseteq \) per la quale l'\textbf{unione è un maggiorante}.

Usiamo il Lemma di Zorn per dimostrare (il verso non banale de) il Teorema di Compattezza.

\begin{lemmaframe}{Lemma di Zorn per famiglie di insiemi}{}

Sia $A$ un insieme e $\mathcal{P}(A)$ il suo insieme delle parti. 

Sia $\mathcal{F} \subseteq \mathcal{P}(A)$ una famiglia di sottinsiemi di $A$. 

Se per ogni \textbf{catena} $\mathcal{C}$ in $\mathcal{F}$ (i.e., per ogni famiglia di sottinsiemi di $A$ appartenenti a $\mathcal{F}$ i cui elementi sono due a due confrontabili via $\subseteq$) esiste un \textbf{maggiorante} in $\mathcal{F}$ (ossia un sottinsieme $S$ di $A$ in $\mathcal{F}$ tale che per ogni $S' \in \mathcal{C}$ vale $S' \subseteq S$), allora esiste un sottinsieme \textbf{massimale} $M$ di $A$ in $\mathcal{F}$ (ossia $M \in \mathcal{F}$ tale che per ogni $S \in \mathcal{F}$, se $M \subseteq S$ allora $S = M$).

\begin{gframe}{}
    Si osserva facilmente che se $\mathcal{F}$ contiene l'\textbf{unione} di ogni sua catena allora soddisfa le condizioni di applicabilità del lemma, in quanto l'unione risulta un maggiorante della catena.

\end{gframe}

\end{lemmaframe}

Data \( T \in \texttt{FINSAT} \), definiamo \( \mathcal{T} = \{\hat T \mid T \subseteq \hat T \ \land \  \hat T \in \texttt{FINSAT}\} \), la famiglia di teorie \texttt{FINSAT} che estendono \( T \). Sappiamo che \( \mathcal{T}\neq \emptyset \), in quanto contiene almeno \( T \).

Vogliamo verificare che \( \mathcal{T} \) verifichi le condizioni per applicare il lemma di Zorn.

Sia \( C = (T_i) \) una catena crescente. È evidente che \( \bigcup_i T_i\) è un maggiorante, e anche che estende \(T\). Sappiamo anche che è \texttt{FINSAT}. Infatti, se consideriamo un qualsiasi sottoinsieme finito di \( \bigcup_i T_i\), ogni sua proposizione sarà un elemento di qualche elemento della catena; questo significa che l'insieme stesso è un sottoinsieme di un elemento della catena, ed è quindi \texttt{FINSAT}.

Applicando quindi il lemma di Zorn, otteniamo che \( \mathcal{T} \) contiene un massimale \( T^* \), ovvero una teoria tale che:
\begin{itemize}
    \item \( T \subseteq T^* \)
    \item \( T^* \in \texttt{FINSAT}\)
    \item \( T^* \) non può essere propriamente esteso mantenendo la condizione di finita soddisfacibilità - ovvero \( \forall T' \in \mathcal{T}, \ \ T^* \subseteq T' \implies T' = T^* \)
\end{itemize}

In quanto massimale, \( T^* \) gode di alcune proprietà:
\begin{enumerate}
    \item data \( A \), non può essere che \( \neg A \in T^* \) e \( A \in T^* \)
    \item se \( A \not\in T^*\), necessariamente \( \neg A \in T^* \) {\color{gray}(altrimenti \( T^* \) potrebbe essere estesa con \( A \) o \( \neg A \) senza perdere la finita soddisfacibilità)}
    \item se \( A \in T^* \) e \( A \vDash B \), si ha \( B \in T^* \) (\( T^* \) è chiuso per conseguenza logica)
        \subitem {\color{gray}(se \( B\not\in T^* \), si avrebbe \( \neg B \in T^* \), ma dato che \( A \vDash B \), si avrebbe \( \{A, B\}\subseteq T^* \in \texttt{UNSAT} \), quindi \( T^* \not\in \texttt{FINSAT}\))}
\end{enumerate}

Come per la dimostrazione precedente, definiamo un assegnamento
\[ \alpha^*(p_n) = \begin{cases}
    1 & p_n \in T^* \\
    0 & \neg p_n \in T^*
\end{cases}  \]

\textbf{Claim}: \( \alpha^*(T)=1 \)

Dimostrare che \( \alpha^* \) soddisfa \( T^* \) basta a dimostrare che soddisfa anche \( T \). 

Possiamo dimostrare una proprietà più forte: che \( \forall A, \ \alpha(A)=1 \iff A \in T^* \)

Lavoriamo per induzione sulla struttura di \( A \):
\begin{itemize}
    \item \textbf{caso base}: \( A = p_n \) \ \ - \ \ si ha \( \alpha^*(p_n) = 1 \iff p_n \in T^* \)
    \item \textbf{casi induttivi}:
        \begin{enumerate}
            \item \( A = \neg B \)
                \subitem 
            \item \( A = B \land C \)
                \subitem
            \item \( A = B \lor C \)
                \subitem
            \item \( A = B \to C\)
                \subitem TODO
        \end{enumerate}
\end{itemize}
\qed

\section{Applicazioni del teorema di compattezza}


\pagebreak

\section{Decidibilità}

Dato il potere espressivo della logica proposizionale, è naturale chiedersi se sia possibile automatizzare la risposta alla domanda ``\( T\vDash A \)''. 

Se \( T = \{A_1, \dots, A_n\} \) è una \textbf{teoria finita}, la risposta è banalmente ``sì'', in quanto sappiamo che \( T\vDash A \iff (A_1 \land \dots \land A_n) \to A \in \texttt{TAUT} \) (il che è facilmente verificabile tramite tavole di verità).

\begin{defframe}{Decidibilità}{}
        Dato uno spazio \( X \) di possibili input, chiamiamo un \textit{problema} un qualsiasi sottoinsieme \( S \subseteq X\). 

    Diciamo che \( S \) è \textbf{algoritmicamente decidibile} se esiste un algoritmo tale che \( \forall \ x \in X \), se \( x \in S \), l'algoritmo su input \( x \) termina in tempo finito e risponde ``sì'', e se \( x \in S \), l'algoritmo su input \( x \) termina in tempo finito e risponde ``no''.
\end{defframe}

Se invece \( T \) è una teoria \textbf{infinita numerabile}, potremmo usare il \textit{teorema di compattezza} per fare un ragionamento del genere:
\begin{itemize}
    \item Sappiamo che \( T \vDash A \iff \exists \ T_0 \overset{fin}{\subseteq} T  \ \ t.c. \ \ T_0 \vDash A\) 
    \item Indicando con \( Fin(T) \) l'insieme dei sottoinsiemi finiti di \( T \), sappiamo che \( Fin(T) \) è numerabile (in quanto \( T \) lo è). 
    \item Se potessimo quindi produrre algoritmicamente un'enumerazione di \( Fin(T) \) del tipo \( S_1, S_2, S_3, \dots \), poiché, grazie al teorema di compattezza, sappiamo che \( \exists i \in \mathbb{N} \ \ t.c. \ \ S_i \vDash A\), potremmo seguire questa procedura:
        \subitem partendo da \( i = 1 \), ci chiediamo se \( S_i \vDash A \). Poiché \( S_i \) è finito, si può rispondere algoritmicamente. Se la risposta è ``sì'', terminiamo la procedura e rispondiamo ``sì''. Altrimenti, ripetiamo con \( i+1 \).
\end{itemize}

Se l'enumerazione di \( Fin(T) \) si può produrre algoritmicamente, allora tutta la procedura è algoritmica. Notiamo però che, mentre nel caso in cui \( T \vDash A \) sicuramente l'algoritmo terminerà e darà la risposta esatta, nel caso in cui \( T \not\vDash A \), esso non terminerà mai (visto che \( T \) è infinita).

Chiamiamo questo tipo di problema semi-decidibile.

\begin{defframe}{Problema semi-decidibile}{}
    Dato uno spazio ambiente \( X \) e un problema \( S \subseteq X\), diciamo che \( S \) è \textbf{semi-decidibile} se esiste un algoritmo tale che \( \forall \ x \in X \), se \( x\in S \), l'algoritmo (su input \( x \)) termina e risponde ``sì''; se invece \( x \not\in S \), l'algoritmo (su input \( x \)) continua all'infinito (\textit{diverge}).
\end{defframe}

\begin{defframe}{Problema computabilmente enumerabile}{}
    Un insieme infinito per cui esiste una procedura algoritmica di enumerazione di tutti e soli i suoi elementi è detto \textbf{computabilmente enumerabile}.
\end{defframe}

(Notiamo che \( \neg(\text{numerabile}\to \text{computabilmente enumerabile}) \))

\begin{thmframe}{}{}
    Se \( T \) è computabilmente enumerabile, allora il problema \( T\vDash A \) è semi-decidibile.
\end{thmframe}

Notiamo quindi che, se lo spazio \( X \) dei possibili input è computabilmente enumerabile, allora:
    \begin{itemize}
        \item ogni problema decidibile è anche semi-decidibile
        \item un problema è semi-decidibile se e solo se è computabilmente numerabile
    \end{itemize}


Possiamo stabilire delle proprietà di \( T \) che ci garantiscano la decidibilità?
La risposta è sì.

Consideriamo la procedura introdutta poco fa ed estendiamola in questo modo: 
\begin{itemize}
    \item ad ogni passo, controlliamo non solo \( S_i \vDash A \), ma anche \( S_i \vDash \neg A \)
    \item se \( S_i \vDash A \), terminiamo e rispondiamo ``sì''; se \( S_i \vDash \neg A \), terminiamo e rispondiamo ``no''
\end{itemize}

Escludiamo le teorie per cui si ha \( T\vDash A \land T \vDash \neg A \), in quanto sono ``\textbf{incoerenti}'' (ed insoddisfacibili).

Ci restano quindi tre casi:

\begin{enumerate}
    \item \textbf{Caso 1}: \(T \models A\) e \(T \not\models \neg A\): la procedura applicata a \(A\) termina e risponde affermativamente mentre la procedura applicata a \(\neg A\) diverge. Possiamo concludere che \(T \models A\).

    \item \textbf{Caso 2}: \(T \not\models A\) e \(T \models \neg A\): la procedura applicata a \(A\) diverge e la procedura applicata a \(\neg A\) termina e risponde affermativamente. Possiamo comunque concludere che \(T \models \neg A\). Se \(T\) non è insoddisfacibile, non può essere che \(T \models A\). Dunque possiamo concludere e rispondere che \(T \models A\).

    \item \textbf{Caso 3}: \(T \not\models A\) e \(T \not\models \neg A\): La procedura diverge quando viene applicata sia ad \(A\) che a \(\neg A\). Questo caso esiste, ma vogliamo escluderlo.
\end{enumerate}

\begin{defframe}{Teoria semanticamente completa}{}
    Una teoria \( T \) è detta \textbf{semanticamente completa} se \( \forall \ A \) nel linguaggio di \( T \), vale esattamente una tra \( T \vDash A \) e \( T \vDash \neg A \).
\end{defframe}

Da questo possiamo derivare che:
\begin{thmframe}{}{}
    Se \( T \) è computabilmente enumerabile e semanticamente completa, allora \( T \vDash A ?\) è decidibile algoritmicamente \( \forall \ A \).
\end{thmframe}

\vspace{1em}

\begin{gframe}{}{}
    Notiamo che le proprietà seguenti sono equivalenti:
    \vspace{-1em}
    \begin{enumerate}
        \item \(T\) è semanticamente completa.
        \item Per ogni formula \(A\), vale \(T \models A \iff T \not\models \neg A\).
        \item \(T\) è soddisfacibile e per ogni formula \(A\) se \(T \not\models A\) allora \(T \models \neg A\).
        \item \(T\) ha un unico modello.
        \item Per ogni formula \(A, B\) vale \(T \models A \lor B\) se e solo se \(T \models A\) oppure \(T \models B\).
        \item Per ogni formula \(A, B\) vale \(T \not\models A \to B\) se e solo se \(T \models A\) e \(T \models \neg B\).
    \end{enumerate}
\end{gframe}

\pagebreak

\section{Calcoli deduttivi formali}
Una dimostrazione rigorosa è una successione ordinata e finita di asserzioni, ognuna delle quali può essere giustificata richiamandosi a una verità assunta come ipotesi (assioma), o a una regola di ragionamento corretta che permette di ottenerla da altre proposizioni.

La regola che utilizziamo nel nostro sistema di dimostrazioni (``alla Hilbert'') è il \textbf{Modus Ponens}: da \( X \land (X\to Y) \) segue \( Y \).

Lo scriviamo in questo modo:
    \AxiomC{X}
    \AxiomC{\( X \to Y \)}
    \BinaryInfC{Y}
    \DisplayProof

\begin{defframe}{Dimostrazione}{}
    Una \textbf{dimostrazione} / deduzione è una \textit{successione finita} \( F_1, \dots, F_k \) di proposizioni t.c., \( \forall \ i \in [k] \):
    \begin{itemize}
        \item \( F_i \) è un'istanza di un assioma, oppure
        \item \( F_i \) si ottiene da due formule precedenti tramite regole di inferenza
    \end{itemize}
\end{defframe}

Nel nostro sistema (in cui limitiamo il linguaggio ai connettivi \( \neg \) e \( \to \)), scegliamo come assiomi:

\begin{gframe}{}
    \label{assprop}
    \begin{enumerate}
        \item \( X \to (Y\to X) \)
        \item \( (X \to (Y \to Z)) \to\)
            \subitem \( ( \ (X \to Y) \to (X\to Z)\ )\)
            \subitem {\color{gray}(se \( X \) implica \( Y \to Z \), allora \( X\to Y \) implica \( X\to Z \) (una sorta di transitività))}
        \item \( (\neg Y \to \neg X) \to (X \to Y) \)
    \end{enumerate}
\end{gframe}

Abbiamo scelto questo sistema perché vogliamo la completezza rispetto alla conseguenza logica.
Vogliamo quindi che \( \vDash A \iff A \) è dimostrabile da queste regole di inferenza e ipotesi in \( T \).

\begin{defframe}{Dimostrazione nel calcolo proposizionale}{}
Una \textbf{dimostrazione} / deduzione di \( A \) da \( T \) nel C.P. è una \textit{successione finita} \( F_1, \dots, F_k \) di proposizioni t.c.:
\begin{itemize}
    \item \( F_k = A\)
    \item  \( \forall \ i \in [k] \):
        \begin{itemize}
            \item \( F_i \) è un'istanza di \textbf{assioma}
            \item \( F_i \in T \)
            \item \( \exists \ p, q < i \ \ \ t.c. \ \ \) 
                \AxiomC{\(F_q\)}
                \AxiomC{\(F_p = F_q \to F_i\)}
                \BinaryInfC{\(F_i\)}
                \DisplayProof
                \subitem (è un'istanza del M.P.)
        \end{itemize}
\end{itemize}
\end{defframe}

\begin{defframe}{Teorema}{}
    \( A \) è un teorema se:
    \[ \vdash A \]
    ovvero \( A \) è dimostrabile a partire ``semplicemente'' dagli assiomi.
\end{defframe}

\begin{thmframe}{Correttezza}{}
    \[ \vdash A \implies \vDash A \]
    \[ T \vdash A \implies T \vDash A \]
\end{thmframe}

La dimostrazione è semplice: \( \vdash A \) significa che \( A \) è dimostrabile a partire dagli assiomi logici (che sono verità logiche), e il Modus Ponens preserva le verità logiche (e il discorso è facilmente estendibile per \( T \vdash A \implies T \vDash A\)).

    Se scriviamo \( Teor(T) = \{A : T\vdash A\}\), la Correttezza si esprime insiemisticamente in questo modo:
    \[ Teor(T) \subseteq Cons(T) \]
ovvero, il nostro sistema permette di derivare formalmente dalle ipotesi di \( T \) solo \textit{conseguenze logiche} di \( T \).

\section{Teorema di completezza}

\begin{thmframe}{Teorema di completezza}{}
    \[ \vdash A \iff \vDash A \]
    \[ T \vdash A \iff T \vDash A \]
\end{thmframe}

\begin{gframe}{}
    \textbf{idea di dimostrazione} (\( T\vDash A \implies T\vdash A \)):

    Dal teorema di compattezza sappiamo che
    \begin{align*}
        T\vDash A &\iff \exists \{A_1, \dots, A_n\} \subseteq T \ \ t.c. \ \ A_1, \dots, A_n \vDash A \\
                  &\iff \vDash (A_1 \to (A_2 \to \dots (A_n \to A)\dots))
    \end{align*}

    Dimostreremo che tutte le tautologie sono teoremi del calcolo proposizionale, e che quindi 
    \[\exists \{A_1, \dots, A_n\} \subseteq T \ \ t.c. \ \  \vdash (A_1 \to (A_2 \to \dots (A_n \to A)\dots)) \]
    Da questo vogliamo ottenere \( T\vdash A \). 

    Lo faremo verificando che \( \vdash (A_1 \to (A_2 \to \dots (A_n \to A)\dots)) \iff  A_1, \dots, A_n \vdash A \).

\end{gframe}

\subsection{Dimostrazione del teorema di completezza (WIP)}
Per dimostrare il teorema, ci saranno utili le seguenti proprietà:

\begin{enumerate}
    \item \( T \vdash A \land T \subseteq S \implies S \vdash A\)
    \item \( T\vdash A \iff \exists S \overset{fin}{\subseteq} T \ \ t.c. \ \ S \vdash A \)
    \item \( T \vdash A \ \land \ (\forall  B \in T, \ \  S \vdash B) \implies S \vdash A \)
\end{enumerate}

\chapter{Logica Predicativa}

\section{Introduzione}

Abbiamo visto come la logica proposizionale ci permette di modellare alcuni tipi di problemi facilmente. Tuttavia, per altri tipi di problemi è necessario un maggiore potere espressivo.

\begin{defframe}{Struttura relazionale}{}
Una struttura relazionale è una tupla \( \mathcal{A} = (A, \ R_1, \dots, R_n, \ f_1, \dots, f_n, \ c_1, \dots, c_n) \), dove:
\begin{itemize}
    \item \( A \) rappresenta un insieme di elementi (tipicamente non vuoto) (\textit{dominio})
    \item \(R_1, \dots, R_n \) sono \textit{relazioni} su \( A \) (anche unarie), ossia suoi sottoinsiemi 
    \item \( f_1, \dots, f_n \) sono \textit{funzioni} su \( A \)
    \item \( c_1, \dots, c_k \) sono \textit{costanti} su \( A \)
\end{itemize}
\end{defframe}

\textbf{Esempio}:
un esempio di struttura è quella di gruppo.

Un gruppo è definito da un insieme $A$ (di elementi del gruppo), un elemento $e \in A$ (l'elemento neutro) e un'operazione binaria $\circ : A \times A \to A$, che soddisfa le seguenti proprietà:
\begin{enumerate}
    \item Per ogni $a \in A$, $a \circ e = e \circ a = a$
    \item Per ogni $a \in A$ esiste un $b \in A$ tale che $a \circ b = b \circ a = e$
    \item Per ogni $a, b, c \in A$: $a \circ (b \circ c) = (a \circ b) \circ c$.
\end{enumerate}
{\small (Un gruppo è inoltre abeliano se soddisfa: per ogni $a, b \in A$ si ha $a \circ b = b \circ a$.)}

\begin{defframe}{Linguaggio predicativo}{}
    Un \textbf{linguagggio predicativo} \( \mathcal{L} \) è una collezione (finita o infinita) di simboli di tre tipi:
    \begin{itemize}
        \item simboli di \textit{relazioni}, con la loro arietà
        \item simboli di \textit{funzioni}, con la loro arietà
        \item simboli di \textit{costanti} (di arietà 0)
    \end{itemize}
    
    Inoltre, assumiamo sempre un insieme numerabile di \textit{variabili} \( v_1, v_2, \dots \)
\end{defframe}

\textbf{Esempio}: per continuare con l'esempio di sopra, un linguaggio adeguato per la teoria dei ruppi è \( \mathcal{L}_G = \{\cdot, e\} \), dove \( \cdot \) è un simbolo di funzione binaria per l'operazione di gruppo, e \( e \) è una costante per l'elemento neutro.

\begin{gframe}{Nota bene}
  Nella logica dei predicati, si può quantificare solo sugli \textit{elementi} delle strutture e non sulle strutture stesse (si chiama, per questo, Logica di Primo Ordine o FOL, First-Order Logic). 

  Per quantificare sulle strutture, esiste la Logica di Secondo Ordine (non trattata in questo corso).
\end{gframe}


\begin{defframe}{Termini}{}
    I \textbf{termini} sono ottenuti partendo dalle variabili e dalle costanti e chiudendo sotto applicazione dei simboli di funzione.

    Un termine che non contiene variabili è un \textbf{termine chiuso}.
\end{defframe}

Per formulare proposizioni nel linguaggio \( \mathcal{L} \), si usano i seguenti simboli logici:
\begin{itemize}
    \item \textbf{connettivi}: \( \land, \lor, \to, \neg \)
    \item \textbf{quantificatori}:  \( \exists, \forall \)
    \item il simbolo di \textbf{eguaglianza}:  \( = \)
\end{itemize}

\vspace{1em}

\begin{defframe}{Formule}{}
    
Una \textbf{formula atomica} è una stringa del tipo \( R(t_1, \dots, t_k) \), dove \( R \) è un simbolo di relazione di arità \( k \) e \( t_1, \dots, t_k \) sono termini, oppure una stringa del tipo \( t = s \), dove \( t \) e \( s \) sono termini.

Le \textbf{formule} sono ottenute partendo dalle formule atomiche e chiudendo sotto connettivi proposizionali e quantificatori universali ed esistenziali. 
\end{defframe}

Nelle formule \( (\forall v)F \) e \((\exists v)F\), \( F \) è detto il \textbf{dominio} (o \textit{scope}) del quantificatore e \( v \) la variabile quantificata. Se \( v \) non occorre in \( F \), possiamo identificare le due formule quantificate con \( F \). 

Un'occorrenza di una variabile \( x \) in una formula \( F \) è \textbf{vincolata} se e solo se:
\begin{itemize}
    \item l'occorrenza di \( x \) è la variabile quantificata di un quantificatore, oppure
    \item l'occorrenza di \( x \) è nel dominio di un quantificatore con variabile quantificata
\end{itemize}

Tutte le altre occorrenze di \( x \) sono dette \textbf{libere}.

Un \textbf{enunciato} è una formula senza variabili libere.

Se \( F \) è una formula e \( x_1, \dots, x_n \) sono variabili distinte, indichiamo con \( F(x_1, \dots, x_n) \) il fatto che le variabili libere di \( F \) sono contenute nell'insieme \( \{x_1, \dots, x_n\} \).

\begin{defframe}{Termine libero}{}
    \label{terlib}
    Un termine \( t \) è \textbf{libero per una variabile} \( v \) in una formula \( F \) se nessuna occorrenza libera di \( v \) in \( F \) è nel dominio di un quantificatore \( \forall y \) o \( \exists y \) con \( y \) una variabile in \( t\).

    (ovvero, se si sostituisce \( v \) con \( t \) nella formula, nessuna delle variabili di \( t \) viene legata da un quantificatore presente in \( F \) )
\end{defframe}

Per esempio, se \( F \) è \( \exists y (x = y + y) \), nessun termine contenente \( y \) è libero per \( x \) in \( F \).


\section{Semantica}
Vogliamo poter definire il concetto di \textbf{verità logica} nella logica dei predicati (analogo a quello di tautologia nella logica proposizionale). A tale scopo, ci serve definire la nozione di verità di una formula della logica predicativa.

La verità di una formula della logica predicativa dipende dalla scelta dell'ambiente in cui decidiamo di interpretare i simboli del linguaggio. Un tale ambiente è detto \textbf{struttura}.

\begin{defframe}{Struttura per un linguaggio \( \Ll \)}{}
    Dato un linguaggio \( \Ll\), una \textbf{struttura} (o interpretazione) \(\mathcal{A}\) per il linguaggio \( \Ll \) consiste di:
    \begin{itemize}
        \item un insieme \( A \) non vuoto, detto \textbf{dominio}
        \item per ogni simbolo \( R_i \) di arietà \( d \), una relazione di arietà \( d \) sul dominio \( A \), che denotiamo con \(\Ra_i \) dove \( \Ra_i \subseteq A^d \)
        \item per ogni simbolo \( f_j \) di arietà \( d \), una funzione a \( d \) argomenti sul dominio \( A \), che denotiamo con \(\fa_i \) dove \( \fa_j : A^d \to A \)
        \item per ogni \( k \in K \), un elemento di \( A \) che denotiamo con \( \ca_k\)
    \end{itemize}
    
\end{defframe}

Un \textbf{assegnamento} \( \alpha \) in \( \Aa \) è una mappa che associa ad ogni variabile un elemento di \( A \), i.e.:
\[ \alpha : \{v_n : n \in \N \} \to A\]

Un assegnamento si estende in modo univoco ai termini ponendo:
\begin{itemize}
    \item \( \alpha(c) = c^{\Aa} \) 
    \item \( \alpha(f(t_1, \dots, t_k)) = f^{\Aa}(\alpha(t_1), \dots, \alpha(t_k))\).
\end{itemize}

\begin{gframe}{}
    Indichiamo con \( \alpha\ass{x}{a} \) l'assegnamento che differisce da \( \alpha \) solo perché associa l'elemento \( a \) alla variabile \( x \).
\end{gframe}

\begin{defframe}{Soddisfazione}{}
    Definiamo la relazione \( \Aa \vDash F[\alpha] \), che significa ``la formula \( F \) è soddisfatta nella struttura \( \Aa \) relativamente all'assegnamento \( \alpha \)''

    La definiamo per induzione sulla complessità di \( F \) (semantica Tarskyana):

    \begin{itemize}
    \item $\Aa \vDash R(t_1, \dots, t_k)[\alpha]$ se e solo se $(\alpha(t_1), \dots, \alpha(t_k)) \in R^{\Aa}$, dove $t_1, \dots, t_k$ sono termini e $R$ è un simbolo di relazione di varietà $k$.
    \item $\Aa \vDash (t = s)[\alpha]$ se e solo se $\alpha(t) = \alpha(s)$, dove $t$ e $s$ sono termini.
    \item $\Aa \vDash \neg G[\alpha]$ se e solo se non vale $\Aa \vDash G[\alpha]$.
    \item $\Aa \vDash (G \land H)[\alpha]$ se e solo se $\Aa \vDash G[\alpha]$ e $\Aa \vDash H[\alpha]$.
    \item $\Aa \vDash (G \lor H)[\alpha]$ se e solo se $\Aa \vDash G[\alpha]$ o $\Aa \vDash H[\alpha]$.
    \item $\Aa \vDash (G \to H)[\alpha]$ se e solo se: se $\Aa \vDash G[\alpha]$ allora $\Aa \vDash H[\alpha]$.
    \item $\Aa \vDash (\exists x G)[\alpha]$ se e solo se esiste $a \in \Aa$ tale che $\Aa \vDash G[\alpha(x/a)]$.
    \item $\Aa \vDash (\forall x G)[\alpha]$ se e solo se per ogni $a \in \Aa$ vale $\Aa \vDash G[\alpha(x/a)]$.
\end{itemize}
\end{defframe}

\begin{gframe}{Osservazione}
    Il fatto che valga \( \Aa \vDash F[\alpha] \) dipende solo dai valori di \( \alpha \) sulle variabili libere che appaiono in \( F \). Quindi, come già visto in maniera simile per la logica proposizionale, se \( \alpha \) e \( \beta \) sono due assegnamenti che coincidono sui valori assegnati alle variabili \( x_1, \dots, x_n \), allora \( \Aa \vDash F[\alpha] \iff \Aa \vDash F[\beta]\).

    Da questo segue che, se \( F \) è un \textbf{enunciato}, allora \( \Aa \vDash F[\alpha]\) vale \textbf{per tutti gli assegnamenti o per nessuno}.
\end{gframe}

\begin{defframe}{Soddisfacibilità, Validità}{}
    Se \( \exists \alpha \ \ t.c. \ \ \Aa \vDash F[\alpha] \), diciamo che \( \alpha \) \textit{soddisfa} un enunciato \( E \) in \( \Aa \). In questo caso, \( E \) è detto \textbf{soddisfacibile} in \( \Aa \).

    Diciamo che una formula \( F \) è \textbf{vera} in una struttura se \textit{è soddisfatta da tutti gli assegnamenti} in quella struttura.

    \begin{gframe}{}
        Una formula \( F \) è vera in una struttura se e solo se l'enunciato
        \[ \forall x_1, \dots \forall x_n \ F(x_1, \dots, x_n) \] 
        (dove \( x_1, \dots, x_n \) sono tutte e sole le variabili libere di \( F \)) è vero nella struttura.
    \end{gframe}

    Un enunciato \( E \) è \textbf{valido} se è vero in tutte le strutture (ossia se \( \forall \Aa, \ \Aa \vDash E \)). In tal caso, scriviamo \( \vDash E \).

    Dualmente, \( E \) è \textit{insoddisfacibile} se non esiste una struttura in cui è vero.
\end{defframe}

\section{Teorie}

Dato un linguaggio \( \Ll \), ci interessa introdurre questi insiemi degni di nota:
\begin{itemize}
    \item \textbf{Teoria} - una teoria è un insieme \( T \) di enunciati in \( \Ll \)
    \item \textbf{Modello} - un modello di una teoria è una struttura per \( \Ll \) che \textit{soddisfa tutti gli elementi di \( T \)}.
        \subitem scriviamo \( \Aa \vDash T \)
        \subitem e definiamo quindi \( Mod(T)=\{\Aa : \Aa \vDash T\} \)
        \subitem (nota: una teoria si dice \textit{soddisfacibile} se ha un modello)
    \item \textbf{Conseguenza logica di una teoria} - \( E \) \ t.c. \(E \) è vero in tutti i modelli di \( T \) (diciamo che \( T \) \textit{implica logicamente} \( E \))
        \subitem definiamo coerentemente \( Conseq(T) = \{E : T\vDash E\} \)
\end{itemize}

\begin{gframe}{Esempio: teoria dei gruppi}
Un esempio è la teoria formata dagli assiomi di gruppo scritti in un linguaggio predicativo\\ \( \Ll_G = \Ll_{\text{Gruppi}}\{\circ, e\} \), dove \( \circ \) è un simbolo di funzione di arietà due ed \( e \) è un simbolo di costante.

Gli assiomi della teoria di gruppo si esprimono con i seguenti enunciati:
\begin{align*}
\forall v_1 \forall v_2 \forall v_3 ((v_1 \circ v_2) \circ v_3 &= v_1 \circ (v_2 \circ v_3)) \\
\forall v_1 ((v_1 \circ e = v_1) &\wedge (e \circ v_1 = v_1)) \\
\forall v_1 \exists v_2 ((v_1 \circ v_2 = e) &\wedge (v_2 \circ v_1 = e))
\end{align*}
che formano la teoria dei gruppi \( T_G \).

I modelli della teoria dei gruppi sono le strutture che chiamiamo gruppi, quindi si ha che \( Mod(T_G)= \) insieme di tutti e soli i gruppi.

Gli enunciati che sono veri in qualunque gruppo formano l'insieme delle conseguenze logiche della teoria \(T_{\text{Gruppi}}\), ossia \(\{E : T_{\text{Gruppi}} \models E\}\). Le proprietà di un singolo gruppo \( G \) formano la ``teoria di \( G \)'' \(\{E : G \models E\}\).

Si osserva facilmente che la teoria di una singola struttura \(\mathcal{M}\) è sempre completa. 

D'altra parte, l'insieme delle conseguenze logiche di una teoria $T$ non è necessariamente completo (nel senso di contenere \(E$ o $\neg E\) per ogni possibile enunciato $E$). Per esempio, le conseguenze degli assiomi di gruppo (ossia la teoria $T_{\text{Gruppi}}$) non formano un insieme completo: dato che esistono gruppi abeliani e gruppi non-abeliani e dato che la proprietà di essere abeliano è esprimibile nel linguaggio dei gruppi con un enunciato predicativo ($C = \forall v_1 \forall v_2 (v_1 \circ v_2 = v_2 \circ v_1)$), esistono modelli di $T_{\text{Gruppi}}$ che soddisfano $C$ e modelli di $T_{\text{Gruppi}}$ che non soddisfano $C$ (ossia soddisfano $\neg C$). Dunque né $C$ né $\neg C$ sono in $\text{Conseq}(T_{\text{Gruppi}})$ (né l'essere abeliano né l'essere non abeliano sono conseguenze degli assiomi di gruppo). 

La teoria $T_{\text{Gruppi}}$ è dunque incompleta.
\end{gframe}

\section{Isomorfismi tra strutture}
Se esiste un isomorfismo tra due strutture \( \Aa \) e \( \Bb \), significa che queste sono ``indistinguibili'', ovvero che hanno le stesse proprietà. È dunque vero che \( \Aa \iso \Bb \implies \Aa \text{ e } \Bb \) soddisfano gli stessi enunciati? La risposta è sì (nel linguaggio per cui sono isomorfe).

\begin{thmframe}{Isomorfismo tra due strutture}{}
    \( \Aa \iso \Bb \implies \Aa \text{ e } \Bb \) \textbf{soddisfano le stesse formule}.

    Sia \( h \) l'isomorfismo. Si ha quindi \( \forall F(x_1, \dots, x_n), \ \forall (a_1, \dots, a_n) \in A^n \)
    \[ \Aa \vDash F(x_1, \dots, x_n)[a_1, \dots, a_n] \iff  \Bb \vDash F(x_1, \dots, x_n)[h(a_1), \dots, h(a_n)]\]
\end{thmframe}

Lo dimostriamo per le formule, che sono una struttura induttiva (così che valga anche per gli enunciati).

\begin{pframe}
    \begin{itemize}
        \item \textbf{caso base}:
            \begin{enumerate}
                \item \( t_1 \leq t_2 \)
                    \begin{align*}
                        \Aa \vDash (x \leq y)[a_1, a_2] &\iff \Bb \vDash (x\leq y)[h(a_1), h(a_2)]\\
                        (a_1, a_2)\in \leq_A &\iff (h(a_1), h(a_2)) \in \leq_B \\
                    \text{vero per }& \text{def. di isomorfismo}
                    \end{align*}

                \item \( t_1 = t_2 \)
                    \begin{align*}
                        \Aa \vDash (x = y)[a_1, a_2] &\iff \Bb \vDash (x = y)[h(a_1), h(a_2)]\\
                        a_1 = a_2 &\iff h(a_1) = h(a_2) \\
                    \text{vero per }& \text{def. di isomorfismo}
                    \end{align*}

    \end{enumerate}
                    \item \textbf{passo induttivo:}
    Assumiamo che la proprietà valga per le formule \(\phi\) e \(\psi\). 

    Sia \(\vec{a} = (a_1, \ldots, a_n)\) la sequenza degli elementi in \(A\) e \(h(\vec{a}) = (h(a_1), \ldots, h(a_n))\) la sequenza in \(B\).

    \begin{enumerate}
        \item \textbf{negazione ($\neg$)}:
        \[ \mathcal{A} \models \neg \phi[\vec{a}] \]
        \[ \iff \mathcal{A} \not\models \phi[\vec{a}] \quad \text{(def. di } \neg) \]
        \[ \iff \mathcal{B} \not\models \phi[h(\vec{a})] \quad \text{(ip. ind. su } \phi) \]
        \[ \iff \mathcal{B} \models \neg \phi[h(\vec{a})] \quad \text{(def. di } \neg) \]

        \item \textbf{congiunzione ($\wedge$)}:
        \[ \mathcal{A} \models (\phi \wedge \psi)[\vec{a}] \]
        \[ \iff \mathcal{A} \models \phi[\vec{a}] \text{ e } \mathcal{A} \models \psi[\vec{a}] \quad \text{(def. di } \wedge) \]
        \[ \iff \mathcal{B} \models \phi[h(\vec{a})] \text{ e } \mathcal{B} \models \psi[h(\vec{a})] \quad \text{(ip. ind. su } \phi \text{ e } \psi) \]
        \[ \iff \mathcal{B} \models (\phi \wedge \psi)[h(\vec{a})] \quad \text{(def. di } \wedge) \]

        \item \textbf{quantificazione ($\exists$)}:
        Sia \(\phi\) con variabile libera \(y\) in aggiunta a \(x_1, \ldots, x_n\).
        \[ \mathcal{A} \models (\exists y \phi)[\vec{a}] \]
        \[ \iff \exists c \in A \text{ tale che } \mathcal{A} \models \phi[\vec{a}, c] \quad \text{(def. di } \exists) \]
        \[ \iff \exists c \in A \text{ tale che } \mathcal{B} \models \phi[h(\vec{a}), h(c)] \quad \text{(ip. ind. su } \phi) \]
        Poiché \(h\) è suriettiva, l'insieme \(\{h(c) \mid c \in A\}\) è uguale all'insieme base \(B\). Posto \(b = h(c)\):
        \[ \iff \exists b \in B \text{ tale che } \mathcal{B} \models \phi[h(\vec{a}), b] \]
        \[ \iff \mathcal{B} \models (\exists y \phi)[h(\vec{a})] \quad \text{(def. di } \exists) \]
        (Il caso per \(\forall\) segue da \(\forall y \phi \equiv \neg \exists y \neg \phi\)).
            \end{enumerate}
    \end{itemize} \qed
\end{pframe}

Passiamo ad un caso ancora più generale. Vogliamo mostrare che un isomorfismo tra due strutture 
\begin{align*}
    \Aa &= (A, \{R_i^A\}_{i\in I}, \{f_j^A\}_{j\in J},\{c_k^A\}_{k\in K} ) \\
    \Bb &= (B, \{R_i^B\}_{i\in I}, \{f_j^B\}_{j\in J},\{c_k^B\}_{k\in K} ) 
\end{align*}
preserva \textit{l'intera struttura}.

Quindi
\begin{align*}
    \Aa \iso \Bb &\iff \exists h: A \bij B \text{ t.c. } \\
    \color{gray}\forall i \in I, j \in J &, \color{gray}\ \ \forall (a_1, \dots, a_t)\in A^t \\
    \forall (a_1, \dots, a_t)\in A^t, \ \ (a_1, \dots, a_t) \in R_i^A &\iff (h(a_1), \dots, h(a_t)) \in R_i^B \\
    h(f_j^A(a_1, \dots, a_t &)) = f_j^B(h(a_1), \dots, h(a_t))
\end{align*}


Vogliamo dimostrare che, per ogni termine $t$ e ogni assegnazione $\alpha$,
il valore del termine \(t\) in \(\Aa\) con assegnazione \(\alpha\), quando mappato dall'isomorfismo \(h\), è uguale
al valore del termine \(t\) in \(\Bb\) con assegnazione \(h(\alpha)\):
\[ h(t^{\Aa, \alpha}) = t^{\Bb, h(\alpha)} \]
Si dimostra per induzione sulla struttura del termine \(t\).

\begin{proofframe}
    
\begin{enumerate}
    \item \textbf{Caso 1: $t$ è una variabile ($t = x$)}
    \begin{align*}
    h(x^{\Aa, \alpha}) &= h(\alpha(x)) & \text{(per def. di valutazione: } x^{\Aa, \alpha} = \alpha(x)\text{)} \\
    x^{\Bb, h(\alpha)} &= h(\alpha)(x) & \text{(per def. di valutazione in } \Bb \text{ con assegnazione } h(\alpha)\text{)}
    \end{align*}
    Per definizione dell'assegnazione $h(\alpha)$, si ha $h(\alpha)(x) = h(\alpha(x))$.
    Quindi, l'uguaglianza è soddisfatta:
    \[ h(x^{\Aa, \alpha}) = h(\alpha(x)) = h(\alpha)(x) = x^{\Bb, h(\alpha)} \]

    \item \textbf{Caso 2: $t$ è una costante ($t = c$)}

        (in questo caso \( \alpha \) non ha impatto - non ci sono assegnazioni) 
    \begin{align*}
    h(c^{\Aa, \alpha}) &= h(c^\Aa) & \text{(la valutazione di } c \text{ è l'interpretazione } c^\Aa \text{)} \\
    &= c^\Bb & \text{(poiché } h \text{ è un isomorfismo, preserva le costanti)} \\
    c^{\Bb, h(\alpha)} &= c^\Bb & \text{(la valutazione di } c \text{ è l'interpretazione } c^\Bb \text{)}
    \end{align*}
    Quindi, l'uguaglianza è soddisfatta:
    \[ h(c^{\Aa, \alpha}) = c^\Bb = c^{\Bb, h(\alpha)} \]

\item \textbf{Caso 3: $t$ è una funzione ($t = f(t_1, \ldots, t_p)$)}
\begin{align*}
h(t^{\Aa, \alpha}) &= h(f(t_1, \ldots, t_p)^{\Aa, \alpha}) \\
&= h(f^\Aa(t_1^{\Aa, \alpha}, \ldots, t_p^{\Aa, \alpha})) & \text{(def. di valutazione di termine funzione)} \\
&= f^\Bb(h(t_1^{\Aa, \alpha}), \ldots, h(t_p^{\Aa, \alpha})) & (h \text{ isomorfismo, preserva la funzione } f) \\
&= f^\Bb(t_1^{\Bb, h(\alpha)}, \ldots, t_p^{\Bb, h(\alpha)})\\
&= f(t_1, \ldots, t_p)^{\Bb, h(\alpha)} & \text{(def. di valutazione di termine funzione in } \Bb) \\
&= t^{\Bb, h(\alpha)}
\end{align*}

\end{enumerate}
La proprietà è dimostrata per tutti i termini. \qed
\end{proofframe}


\begin{corframe}{Equivalenza elementare}
    Si ha quindi che \( \Aa \iso \Bb \implies \Aa \equiv \Bb \) (``elementarmente equivalenti'')

    ovvero, \( \Aa \) e \( \Bb \) soddisfano gli stessi enunciati.

\end{corframe}

\begin{thmframe}{Equivalenza elementare su domini finiti}{}
    In generale, non vale \( \Aa \equiv \Bb \implies \Aa \iso \Bb \). Vale però se \( \Aa \) e \( \Bb \) finite e \( \Ll \) ha solo simboli di relazione.
\end{thmframe}

\todo{dim grafi}

\section{La teoria DLO}

\subsection{Numeri razionali}
Prendiamo la struttura \( \Qq = (\Q, \leq ) \). Le proprietà di questa struttura si possono esprimere in enunciati predicativi nel linguaggio \( \Ll = \{\leq (x,y)\}\), per il quale, per comodità, usiamo la notazione infissa \( x \leq y \). 

Aggiungiamo anche \( x < y \) come abbreviazione di \( (x \leq y) \land \neg(x = y)\). 

Le proprietà di \( Q, \leq \) sono le seguenti:

\begin{mdframed}
\begin{enumerate}
    \item (A1 - Riflessività) $\forall x\ (x \leq x),$
    \item (A2 - Transitività) $\forall x\forall y\forall z \ ((x \leq y \land y \leq z \to x \leq z),$
    \item (A3 - Antisimmmetria) $\forall x\forall y\ ((x \leq y \land y \leq x) \to y = x),$
    \item (A4 - Totalità) $\forall x\forall y\ (x \leq y \lor x \leq y),$
    \item (A4 - Illimitato a destra) $\forall x\exists y\ (x < y),$
    \item (A5 - Illimitato a sinistra) $\forall x\exists y\ (y < x),$
    \item (A6 - Densità) $\forall x\forall y(x < y \to \exists z(x < z \land z < y)).$
\end{enumerate}
\end{mdframed}

Chiamiamo questa teoria \textbf{DLO} (\textit{Dense Linear Order}).

\begin{thmframe}{\( Q \) e DLO}{}
    \( \Q \) è l'\textit{unico ordine lineare denso numerabile senza estremi} a meno di isomorfismi.
\end{thmframe}

\subsubsection{Isomorfismo: caso numerabile}

\begin{thmframe}{Isomorfismo: caso numerabile}{}
    Sia \( \Bb = (B, \leq_B) \) una struttura con dominio \( B \) numerabile e \( \leq_B \) un ordine totale denso senza estremi su \( B \). Allora esiste un isomorfismo tra \( \Bb\) e \(\Qq \).
\end{thmframe}

Vogliamo dimostrare che \textit{ogni struttura} dove \( B \) è numerabile e \( \preceq \) è un ordine totale denso senza estremi su \( A \) è isomorfa a \( (\Q, \leq)  \).

\begin{gframe}{}
    È naturale definire l'isomorfismo così: \(\Bb \cong \Qq \iff \exists h : \Q \bij B \ \text{ t.c. } \ \forall q, q' \in \Q\)
    \[ q \leq q' \iff h(q) \leq_B h(q')\]
    \[ q = q' \iff h(q) = h(q')\]
\end{gframe}

La dimostrazione usa un metodo chiamato \textit{Back-and-Forth}.

\begin{proofframe}
    Vogliamo costruire un isomorfismo tra \( \Bb \) e \( \Qq \). 
    
    Entrambe hanno un dominio numerabile, quindi fissiamo una enumerazione di \( B \) \( (b_0, b_1, b_2, \dots) \) e una enumerazione di \( \Q \) \( (q_0, q_1, q_2, \dots) \).

    Definiremo ricorsivamente una enumerazione \( p_1, p_2, p_3, \dots \) e una enumerazione \( d_1, d_2, d_3, \dots \) in modo tale che la mappa \( p_i \mapsto d_i \) sia un isomorfismo tra \( \Bb \) e \( \Qq \).

    Per induzione:
    \begin{itemize}
        \item Poniamo \( p_0 = b_0 \) e \( d_0 = q_0 \).
        \item Consideriamo un \( n \) generico e assumiamo che \( p_0, \dots, p_n \) e \( d_0, \dots, d_n \) siano definiti.

            Distinguiamo due casi:

            \begin{enumerate}
                \item Caso \textbf{pari}: scegliamo un elemento \(p_{n+1}\) in \(B \setminus \{p_0, \dots, p_n\}\) con indice minimo in \((b_0, b_1, b_2, \dots)\). Compariamo questo elemento agli elementi già scelti. 

                    Abbiamo tre casi:

                    \begin{itemize}
                        \item {\color{gray}(Prima di tutti gli altri elementi)}

                            Per ogni \(m \le n\), \(p_{n+1} < p_m\). In questo caso scelgo un \(q_{n+1}\) in \( \Q\) tale che per ogni \(m \le n\) abbiamo \(d_{n+1} < d_m\). Questo elemento esiste perché \( \Q \) soddisfa gli assiomi che asseriscono la \textit{non esistenza di estremi} nell'ordine. 

                            {\color{gray}(Scelgo un elemento da \( \Q \) che sia anch'esso prima di tutti gli altri)}

                        \item {\color{gray}(Dopo tutti gli altri elementi)}

                            Per ogni \(m \le n\), \(d_{n+1} > d_m\). In questo caso scelgo un \(q_{n+1}\) in \(\Q \) tale che per ogni \(m \le n\) valga \(d_{n+1} > d_m\). Questo elemento esiste perché \( \Q \) soddisfa l'assioma che \textit{esclude l'esistenza di un estremo destro} nell'ordine.
                            
                            {\color{gray}(Scelgo un elemento da \( \Q \) che sia anch'esso dopo tutti gli altri)}

                        \item {\color{gray}(Da qualche parte nel mezzo)}

                            Nessuno dei primi due casi. Allora esistono \(m_0, m_1 \le n\) tali che \(p_{m_0} < p_{n+1} < p_{m_1}\) e nessun altro elemento di \(\{p_0, p_1, \dots, p_n\}\) è nell'intervallo \([p_{m_0}, d_{m_1}]\). In questo caso scelgo un elemento \(d_{n+1}\) in \(\Q\) tale che \(d_{m_0} < d_{n+1} < d_{m_1}\). Questo elemento esiste perché \(\Q\) soddisfa l'assioma di \textit{densità}.
                            
                            {\color{gray}(Scelgo un elemento da \( \Q \) che sia anch'esso in mezzo agli altri)}

                    \end{itemize}

                \item Caso \textbf{dispari}: procediamo allo stesso modo, ma partendo da un elemento \(q_{n+1} \in \Q \setminus \{q_0, \dots, q_n\}\).

            \end{enumerate}

    \end{itemize}

    Grazie alla separazione in passi pari e dispari (poiché scegliamo sia a partire da \( B \) che da \( \Q\)), non ci saranno ``buchi'' nelle nostre scelte di elementi. 
\end{proofframe}

Notiamo che nella dimostrazione non servono proprietà di \( \Q \) se non quelle di DLO (e l'ipotesi di numerabilità del dominio). Il teorema si può quindi generalizzare.

\begin{thmframe}{Teorema di isomorfismo di Cantor}{}
        \label{thm:Cantor}
    Siano \( \Aa = (A, \leq_A) \) e \( \Bb = (B, \leq_B) \) t.c. \( A, B \) sono entrambi numerabili e \( \Aa \vDash \text{DLO} \) e \( \Bb \vDash \text{DLO} \). Allora, \( \Aa \iso \Bb \).
\end{thmframe}


\section{DLO: caso generale}
Ci chiediamo: data una struttura \( \Dd = (D, \leq_D) \vDash \text{DLO}\) con \( D \) più che numerabile, \( \Dd \isit{\equiv} \Qq \) - ovvero, per esempio, esiste un enunciato nel linguaggio degli ordini vero in \( \Q \) e falso in \( \R \)? (Se potessimo scrivere la completezza di \( \R \) in linguaggio degli ordini, allora questo sarebbe sicuramente vero (in quanto \(\Q\) non è completo) - ma non è possibile farlo).

Vogliamo quindi individuare un \textbf{criterio sufficiente} a concludere \( \Qq \equiv \Rr\).

\subsection{Sottostrutture, proprietà del testimone}

Introduciamo come prima cosa il concetto di sottostruttura:

\begin{defframe}{Sottostruttura}{}
    Date due strutture \( \Aa \) e \( \Bb \), \( \Aa \) si dice \textbf{sottostruttura} di \( \Bb \) (\( \Aa \subseteq  \Bb \)) se e solo se si ha:
    \begin{itemize}
        \item \( A \subseteq B \)
        \item per ogni simbolo \( R \) di relazione, \( R^\Aa = R^\Bb \cap A^n \) (dove \( n \) arità di \( R \))
        \item per ogni simbolo di costante, \( c^\Bb \in A \) e \( c^\Aa = c^\Bb \)
        \item per ogni simbolo di funzione, \(f^\Aa = f^\Bb \vert_A^n \) (con \( n \) arietà di \( f \))
    \end{itemize}

\end{defframe}


\begin{defframe}{Sottostruttura elementare}{}
    Date due strutture \( \Aa \) e \( \Bb \), \( \Aa \) si dice \textbf{sottostruttura elementare} di \( \Bb \) (\( \Aa \prec \Bb \)) se e solo se si ha:
    \[ A \subseteq B \  \land \ \forall F, \ \forall \vec{a}\in A, \ \ \Aa \vDash F[\vec{a}] \iff \Bb \vDash F[\vec{a}] \]

    (ovvero \( \Aa \subseteq \Bb \) e \( \Aa \equiv \Bb \)).
    
\end{defframe}

Notiamo che \( \Qq \subseteq \Rr \).

Data una formula \( F \), è naturale che se \( \alpha \)  è un assegnamento in \( \Q \) e \( \Qq \vDash \exists x F[\alpha] \), allora \( \Rr \vDash \exists x F[\alpha] \).

Non è però detto che valga l'inverso, ossia:
\begin{thmframe}{Proprietà del testimone tra \( \Rr \) e \( \Qq \)}{}
    Per ogni formula \( F \) con \( x \) variabile libera, \textit{per ogni assegnamento} \( \alpha \) in \( \Q \), se
    \[ \Rr \vDash \exists x \ F(x)[\alpha] \]
allora \( \exists q \in \Q \) tale che:
\[ \Rr \vDash F(x)[\alpha \ass{x}{q}] \]

(quindi, abbiamo una formula \( F \) con tutte le variabili in \( \Q \) tranne una; presumiamo che sia vera con l'ultima variabile assegnata in \( \R \) - allora vogliamo che \(\exists q \in \Q \) (da assegnare all'ultima variabile) che la soddisfi)
\end{thmframe}

La proprietà del testimone è la condizione sufficiente per dedurre \( \Qq \equiv \Rr \).

Come già visto, conviene dimostrare la proprietà per le formule (così che valga anche per gli enunciati).

\begin{corframe}{Conseguenza della proprietà del testimone}{}
    Se vale la proprietà del testimone tra \( \Rr \) e \( \Qq \), allora \( \forall F, \forall \alpha \) su \( Q \),
    \[ \Qq \vDash F[\alpha] \iff \Rr \vDash F[\alpha] \]
\end{corframe}

\begin{proofframe}{}{}
    Si dimostra per induzione su \( F \).

    \begin{itemize}
        \item \textbf{caso base}: \( F \) è di tipo \( (x \leq y) \).
            \begin{align*}
                \Qq \vDash (x\leq y)[\alpha] &\iff \Rr \vDash (x\leq y)[\alpha] \\
                 \alpha(x) \leq_\Q \alpha(y) &\iff \alpha(x) \leq_\R \alpha(y) 
            \end{align*}

            (argomento analogo per \( (x = y) \))

        \item \textbf{booleani}:
            \begin{align*}
                \Qq \vDash A \land B [\alpha] &\iff \Rr \vDash A \land B[\alpha] \\
                \Qq \vDash A[\alpha] \land \Qq \vDash B[\alpha] &\iff \Rr \vDash A[\alpha] \land \Rr \vDash B[\alpha]
            \end{align*}
            Vero per ipotesi induttiva su $A$ e $B$:
\[
\Q \models A[\alpha] \iff \R \models A[\alpha] \quad \text{e} \quad \Q \models B[\alpha] \iff \R \models B[\alpha]
\]

(argomento analogo per gli altri connettivi booleani)

\item \textbf{esistenziale}:

Sia \(F \equiv \exists x \, F(x)\). Assumiamo che la tesi valga per la formula \(F(x)\) (I.I.). Dobbiamo mostrare che:
\[
\Q \vDash \exists x \, F(x)[\alpha] \iff \R \vDash \exists x \, F(x)[\alpha]
\]

\textit{Direzione \(\implies\):}
Assumiamo \(\Q \vDash \exists x \, F(x)[\alpha]\).
Per definizione, vale sse esiste un elemento \(q \in \Q\) tale che \(\Q \vDash F(x)[\alpha\ass{x}{q}]\).
Poiché l'assegnazione \(\alpha\ass{x}{q}\) è in \(\Q\), per I.I. applicata a \(F(x)\):
\[
    \Q \vDash F(x)[\alpha \ass{x}{q}] \iff \R \vDash F(x)[\alpha \ass{x}{q}]
\]
 Poiché \(q \in \Q\) e \(\Q \subseteq \R\), \(q\) è un elemento di \(\R\).
Per definizione di soddisfacibilità in \(\R\):
\[
    \R \vDash \exists x \, F(x)[\alpha]
\]

\textit{Direzione \(\impliedby\):}
Assumiamo \(\R \vDash \exists x \, F(x)[\alpha]\), con \( \alpha \) assegnamento in \( \Q \). Per definizione, vale sse \( \exists r \in \R \) t.c. \( \Rr\vDash F(x)\ass{x}{r} \)
Per la \textit{proprietà del testimone}, se \(\R \vDash \exists x \, F(x)[\alpha]\), allora esiste un testimone \(q \in \Q\) tale che \(\R \vDash F(x)[\alpha \ass{x}{q}]\).
Per ipotesi induttiva su \( F \), questo vale sse \( \exists q \in \Q \) t.c. \( \Qq \vDash F(x)[\alpha\ass{x}{q}] \).
Ovvero:
\[
    \R \vDash F(x)[\alpha\ass{x}{q}] \iff \Q \vDash F(x)[\alpha\ass{x}{q}]
\]
Quindi \(\Q \vDash F(x)[\alpha\ass{x}{q}]\). Poiché esiste un \(q \in \Q\) che soddisfa \(F(x)\) in \(\Q\), per definizione (di soddisfacibilità):
\[
    \Q \vDash \exists x \, F(x)[\alpha]
\]

    \end{itemize}
    \qed
\end{proofframe}

\begin{corframe}{Altra conseguenza della proprietà del testimone}
    Quindi, se vale la proprietà del testimone tra \( \Qq \) e \( \Rr \), per ogni enunciato \( E \) nel linguaggio degli ordini si ha:
    \[ \Qq \vDash E \iff \Rr \vDash E \]

    ovvero \( \Qq \equiv \Rr \), e quindi \( \Qq \prec \Rr \).
\end{corframe}

\subsection{Equivalenza tra \( \Rr \) e \( \Qq \)}

Per dimostrare \( \Qq \equiv \Rr \), definiamo \( \Aa = (A, \leq_A) \) t.c. \( \Qq \subseteq \Aa \subseteq \Rr \) e \( A \) numerabile. 

Seguiremo quindi questi passi:
\vspace{-0.5em}
\begin{enumerate}
    \item dimostreremo la proprietà del testimone tra \( \Aa \) e \( \Rr \), ottenendo \( \Aa \equiv \Rr \)
    \item visto che \( \Rr \vDash\) DLO e (1), si ha \( \Aa \vDash \) DLO
    \item da (2) e \( A \) numerabile, applicando il Teorema di Cantor (p.\pageref{thm:Cantor}) si ottiene \( \Aa \iso \Qq \)
    \item visto che \( \iso \implies \equiv \), si ha \( \Aa \equiv \Qq \)
    \item per transitività, \( \Rr \equiv \Qq \).
\end{enumerate}

Costruiamo quindi \( \Aa \) partendo da \( \Qq \).

Sia \( F \) una formula del linguaggio DLO e siano \( x_1, x_2, y \) le sue variabili libere.

Se \( \Rr \vDash \exists y F(x_1, x_2, y) \tworowmatrix{x_1 & x_2}{q_1 & q_2} \), per definizione di soddisfacibilità sappiamo che 
\\\( \exists r \in \R\) \ t.c. \ \( \Rr \vDash F(x_1, x_2, y) \tworowmatrix{x_1 & x_2 & y}{q_1 & q_2 & r} \). Ne scegliamo uno in modo canonico {\color{gray}(usiamo implicitamente l'assioma della scelta)}.

\begin{defframe}{Funzione di Skolem}{}
    Chiamiamo \textbf{funzione di Skolem} (da \href{https://en.wikipedia.org/wiki/Thoralf_Skolem}{Thoralf Skolem}) della formula \( F \) relativamente ad \( y \) la funzione 
    \[ f_{F, y} : \Qq^n \to \Rr \]
    che associa ad ogni scelta di \( (q_1, \dots, q_n) \) un tale \( r \in \R \) in modo canonico.
\end{defframe}

Dato \( \Ff = \{ \text{funzioni di Skolem}\} \), chiudiamo \( \Q \) sotto \( \Ff \).

Otteniamo \( A_1 = \Q \cup \{b \in \R \mid b = f(q_1, \dots, q_n) \text{ con } f\in \Ff, \ (q_1, \dots, q_n) \in Q^n\} \).

Sappiamo che \( \Qq \subseteq \Aa_1 = (A_1, \leq_A) \subseteq \Rr\).

È però vero che se \( x_1, x_2 \) sono assegnati in \( A_1 \) come \( a_1, a_2 \) allora esiste un \( a \in A_1\) t.c. \\ \( \Rr \vDash F(x_1, x_2, y) \tworowmatrix{x_1 & x_2 & y}{a_1 & a_2 & a}  \)? Non necessariamente. Infatti, se \( a_1, a_2 \in \Q \), sicuramente sì. 

Ma, se \( a_1, a_2 \in \Aa_1 \setminus \Qq \), non possiamo saperlo per certo. Dobbiamo quindi chiudere nuovamente sotto \( \Ff \).

Non ci basta però chiudere un'altra volta, in quanto il problema si ripropone. Dobbiamo ripetere l'operazione \( \forall i \geq 0\).

Abbiamo quindi
\[ A_{i+1} = A_i \cup \Ff(A_i) \]
{\color{gray}(utilizziamo la notazione \( \Ff(A) \) per indicare la chiusura di \( A \) su \( F \))}

Definiamo 
\[ A = \bigcup_{i\in \N} A_i \]

Si vede che \( A \) è chiuso sotto funzione di Skolem. \\Infatti, se \( a_1, \dots, a_n \in A_k \) e \( f\in \Ff \) allora \( f(a_1, \dots, a_n) \in A_{k+1} \).

\( \Aa = ( A =\bigcup_{i\in \N} A_i, \leq_A) \) ha anche la Proprietà del Testimone relativamente ad \( \Rr \).

Ovvero, se 
\[ \Rr \vDash \exists y F(x_1, x_2, y)\tworowmatrix{x1 & x2}{a_1 & a_2} \quad a_1, a_2 \in A\]
allora \( \exists a \in A \) t.c.
\[ \Rr \vDash F(x_1, x_2, y)\tworowmatrix{x1 & x2 & y}{a_1 & a_2 & a} \]

{\color{CadetBlue}[caso generale: \( \forall F, \forall \alpha \in A \), se:
    \[ \Rr\vDash \exists x F(x)[a] \]
    allora \( \exists a \in A \) t.c.:
    \[ \Aa \vDash F(x)\left[\alpha \ass{x}{a}\right] \]
]}

Possiamo quindi concludere che \( \Aa \equiv \Rr \).

Possiamo anche verificare che \( \Aa \) è numerabile:
\begin{itemize}
    \item \( \Ff \) è numerabile (perché esiste una funzione per ogni scelta di formula del linguaggio e di variabile libera, entrambe da insiemi numerabili)
    \item ogni \( A_k \) è numerabile (\( A_1 = \Q \) è numerabile, e ogni \( A_{k+1} \) è l'unione di un \( A_k \) numerabile con la sua chiusura sotto un altro insieme numerabile)
\end{itemize}

Abbiamo quindi dimostrato la seguente proposizione
\begin{propframe}{}{}
    Esiste una sottostruttura numerabile \( \Aa \) di \( \Rr \) che contiene \( \Q \) e soddisfa esattamente gli stessi enunciati di \( \Rr \) nel linguaggio degli ordini.
\end{propframe}

\( \Aa \) è anche un modello numerabile di DLO, perché \( \Rr \vDash  \)DLO.

Dunque \( \Aa \iso \Qq \). Dunque \( \Qq \equiv \Rr \) (nel linguaggio degli ordini).

\subsection{Generalizzazione della dimostrazione}
    La dimostrazione è generale - si può ricostruire in maniera equivalente partendo non da \( \Rr \) ma da un qualunque \( \Bb \) modello non-numerabile di DLO.

    La Proprietà del Testimone si esprime non relativamente a \( \Qq \) ma ad una sottostruttura numerabile \( \Xx \) di \( \Bb \) del tipo \( (X, \leq^\Xx ) \) con \( X \subseteq B \) e \( \leq^\Aa = \leq^\Bb \cap (A \times A)\).

    Si parte da un sottoinsieme numerabile \( X \) di \( \Bb \) (che ha sicuramente), e si procede per chiusura sotto funzioni di Skolem allo stesso modo.

    Si costruisce così \( \Xx = \bigcup_{i\in \N} X_i \). Si ha \( \Xx \vDash  \)DLO, e quindi \( \iso  \) e \( \equiv \Qq\).

    \begin{thmframe}{}{}
        Si ha quindi che \textbf{tutti i modelli di DLO} (numerabili o meno) soddisfano esattamente gli stessi enunciati di \( \Qq \).

        i.e. \( \Bb \vDash \text{DLO} \implies \Bb \equiv \Qq \)
    
        DLO ``identifica'' quindi \( (\Qq, \leq ): Th(\Qq) = Th(\Bb) \)
    \end{thmframe}

    \begin{corframe}{}
        DLO è una teoria completa.

        (ossia, \( \forall \text{ enunciato } E, \text{DLO}\vDash E \text{ oppure DLO} \vDash \neg E \) {\color{gray}(e DLO ha almeno un modello)}).

        \begin{pframe}{}{}
            Un modello di DLO soddisfa esattamente gli stessi enunciati di \( \Qq \). Dunque, \( Cons(\text{DLO}) \) sono esattamente gli enunciati veri nella singola struttura di \( \Qq \), che è una teoria completa.
        \end{pframe}
    \end{corframe}


\section{Criterio di Tarski-Vaught}

Per stabilire se una sottostruttura è anche una \textbf{sottostruttura elementare} (\(\mathcal{A} \preceq \mathcal{B}\)), possiamo quindi utilizzare la \textit{Proprietà del Testimone}, che chiamiamo anche ``criterio di Tarski-Vaught''.

\begin{defframe}{Proprietà del Testimone (generale)}{}
    
Sia \(\mathcal{A} \subseteq \mathcal{B}\). Diciamo che \(\mathcal{A}\) soddisfa la \textbf{Proprietà del Testimone} rispetto a \(\mathcal{B}\) se, per ogni formula del tipo \(\exists x F(x)\) e per ogni assegnamento \(\alpha\) in \(A\), se
\[
\mathcal{B} \models \exists x F(x)[\alpha]
\]
allora  \(\exists a \in A\) tale che:
\[
    \mathcal{B} \models F(x)\left[\alpha\ass{x}{a}\right]
\]

{\color{gray}\small(se in \(\mathcal{B}\) esiste una soluzione (un testimone) per una certa proprietà parametrizzata da elementi di \(A\), dobbiamo essere in grado di trovare quel testimone già dentro \(A\))}
\end{defframe}

\begin{thmframe}{}{}
    
    Sa \(\mathcal{A}\) è una sottostruttura di \(\mathcal{B}\) che \textbf{soddisfa la Proprietà del Testimone} rispetto a \(\mathcal{B}\), allora \(\mathcal{A}\) è una \textbf{sottostruttura elementare} di \(\mathcal{B}\).
\[
    \mathcal{A} \subseteq \mathcal{B} \text{ e Testimone} \implies \mathcal{A} \preceq \mathcal{B} \ \color{gray}(\implies \mathcal{A} \equiv \mathcal{B})
\]
\end{thmframe}


Quindi, iniziamo a vedere che partendo da un arbitrario modello \(\mathcal{B}\) infinito, ne esiste sempre uno numerabile (purché il linguaggio sia numerabile).

\begin{pframe}
Prendiamo \(\mathcal{B} \models T\) con \(|\mathcal{B}| = \infty\) e \(X \subseteq B\) con \(X\) numerabile.

Facciamo la solita chiusura per funzioni di Skolem. 

Immaginiamo una successione di insiemi \(X_0 \subseteq  X_1 \subseteq X_2 \dots\).

Definiamo:
\[
A = \bigcup_{i \in \mathbb{N}} X_i
\]

Definiamo la struttura \(\mathcal{A}\) in questo modo:
\begin{itemize}
    \item Per ogni simbolo di relazione: \(R^\mathcal{A} = R^\mathcal{B} \cap A^n\)
    \item Per ogni funzione: \(f^\mathcal{A} = f^\mathcal{B} \big|_{A^n}\)
\end{itemize}

\textbf{NB:} Ci manca la proprietà sulle costanti. Dobbiamo avere \(c^\mathcal{B} \in A\). Potremmo far sì che le costanti siano ``teste'' di funzioni 0-arie di Skolem, garantendo la loro inclusione nella chiusura.

La struttura risultante è:
\[
\mathcal{A} = \left( \bigcup_{i \in \mathbb{N}} X_i, \{c_i^\mathcal{A}\}, \{R_j^\mathcal{A}\}, \{f_k^\mathcal{A}\} \right)
\]
\(\mathcal{A}\) è una sottostruttura per definizione e ha la proprietà del test (Tarski-Vaught).
\[
\implies \mathcal{A} \equiv \mathcal{B} \quad (\text{elementarmente equivalenti})
\]
Quindi, \(\mathcal{A} \models T\).
\end{pframe}


\section{Teorema di Löwenheim-Skolem (All'in giù)}

\begin{thmframe}{Teorema di Löwenheim-Skolem all'in giù}{}
Sia \(\mathcal{B}\) una struttura infinita adeguata per un linguaggio numerabile \(\mathcal{L}\). Sia \(X \subseteq B\) un sottoinsieme del suo dominio. Esiste una struttura \(\mathcal{A}\) tale che:
\begin{enumerate}
    \item \(X \subseteq A\)
    \item \(\mathcal{A} \preceq \mathcal{B}\) (è sottostruttura elementare)
    \item Se il linguaggio \(\mathcal{L}\) e l'insieme \(X\) sono numerabili, allora \(\textbf{A}\) è numerabile.
\end{enumerate}

Essenzialmente, \textbf{ogni teoria in un linguaggio numerabile che ammette un modello infinito (\(\mathcal{B}\)), ammette un ``sotto-modello'' numerabile} (\(\mathcal{A}\)) che è una sottostruttura elementare di \(\mathcal{B}\).

\end{thmframe}

La dimostrazione procede quasi analogamente a quella vista sopra.

\begin{corframe}{}{}
Non esiste una teoria \(T\) in un linguaggio \(\mathcal{L}\) numerabile (predicativo) che possa forzare i suoi modelli ad essere ``più che numerabili''.
\[
\mathcal{B} \models T \implies |B| > \aleph_0 \quad \text{(Falso in generale)}
\]
\end{corframe}

\begin{corframe}{``Paradosso'' di Skolem}
    La teoria assiomatica degli insiemi (ZFC) (se ha un modello) ha modelli numerabili.

    (Il linguaggio ha un solo simbolo di relazione binaria (\(\in\)) ed è numerabile).

    Il ``paradosso'' (non un vero paradosso) nasce dal fatto che:
\begin{itemize}
    \item In ZFC si dimostra l'esistenza di insiemi non numerabili (es. l'insieme dei reali \(\mathbb{R}\)). Formalmente:
    \[
    \text{ZFC} \vdash \exists x (\text{``}x \text{ è non numerabile''})
    \]
    \item Se ZFC ha un modello \(\mathcal{V}\), allora per il Teorema di Löwenheim-Skolem deve averne anche un modello numerabile \(\mathcal{M}\).
    \item Quindi esiste una struttura numerabile in cui è soddisfatto l'enunciato ``esiste un insieme non-numerabile''.
\end{itemize}

\end{corframe}

\section{Teorie categoriche (\(\omega\)-categoricità)}

L'argomento usato per dimostrare la completezza di DLO si può generalizzare.

\begin{defframe}{\(\omega\)-categoricità)}{}
Una teoria \(T\) si dice \textbf{\(\omega\)-categorica} se tutti i suoi modelli \textbf{numerabili} sono isomorfi tra loro.

\textit{(ricordiamo che se due modelli sono isomorfi, allora sono necessariamente elementarmente equivalenti)}
\end{defframe}

Sia \(T\) una teoria in un linguaggio numerabile che soddisfa le seguenti tre proprietà:
\begin{enumerate}
    \item \(T\) è \textbf{soddisfacibile} (ha almeno un modello).
    \item \(T\) \textbf{non ha modelli finiti} (ha solo modelli infiniti).
    \item \(T\) è \textbf{\(\omega\)-categorica} (ha un solo modello numerabile a meno di isomorfismo).
\end{enumerate}
Possiamo concludere che \(T\) è una teoria \textbf{completa}.

\begin{proofframe}{}{}
Supponiamo che \(T\) non sia completa.

1.  Se \(T\) non è completa, esiste un enunciato \(E\) nel linguaggio tale che \(T\) non dimostra né \(E\) né \(\neg E\).    
\[
    T \not\vdash E \quad \text{e} \quad T \not\vdash \neg E
    \]
    
2.  Questo implica che esistono due modelli \(\mathcal{B}\) e \(\mathcal{C}\) tali che:
    \[
    \mathcal{B} \models T \cup \{\neg E\} \quad \text{e} \quad \mathcal{C} \models T \cup \{E\}
    \]
    
3.  Per l'ipotesi (2), \(T\) non ha modelli finiti, quindi \(\mathcal{B}\) e \(\mathcal{C}\) sono entrambi infiniti.

4.  Applichiamo il Teorema di Löwenheim-Skolem a entrambi i modelli:
    \begin{itemize}
        \item Esiste \(\mathcal{B}_0 \preceq \mathcal{B}\) con \(\mathcal{B}_0\) numerabile. Poiché \(\mathcal{B} \models \neg E\), allora \(\mathcal{B}_0 \models \neg E\).
        \item Esiste \(\mathcal{C}_0 \preceq \mathcal{C}\) con \(\mathcal{C}_0\) numerabile. Poiché \(\mathcal{C} \models E\), allora \(\mathcal{C}_0 \models E\).
    \end{itemize}

5.  Ora abbiamo due modelli numerabili di \(T\), \(\mathcal{B}_0\) e \(\mathcal{C}_0\).
    Per l'ipotesi (3) di \textbf{\(\omega\)-categoricità}, tutti i modelli numerabili sono isomorfi:
    \[
    \mathcal{B}_0 \cong \mathcal{C}_0
    \]

6.  Se due strutture sono isomorfe, soddisfano gli stessi enunciati:
    \[
    \mathcal{B}_0 \equiv \mathcal{C}_0
    \]
    Tuttavia, abbiamo stabilito al punto 4 che \(\mathcal{B}_0 \models \neg E\) e \(\mathcal{C}_0 \models E\) (contraddizione) \qed
\end{proofframe}

\section{Calcolo dei Predicati}
Introduciamo ora il calcolo dei predicati (con identità) ``alla Hilbert''. Ad ogni linguaggio \( \Ll \) possiamo associare un calcolo dei predicati del I ordine.

\begin{defframe}{Dimostrabilità}{}
    Si ha \( T\vdash A \) se e solo se esiste una sequenza \( (A_1, A_2, \dots, A_n) \) di formule tali che:
    \begin{itemize}
        \item \( A_n = A \)
        \item \( \forall 1\leq i \leq n \):
            \begin{itemize}
                \item \( A_i \in T \), oppure
                \item \( A_i \) assioma, oppure
                \item \( A_i \) segue dai precedenti per regole di inferenza
            \end{itemize}
    \end{itemize}
\end{defframe}

Gli assiomi logici sono i seguenti:
\begin{gframe}{}
    \begin{enumerate}
        \item Tutti gli assiomi proposizionali (illustrati a p.\pageref{assprop})\\[1em]
            Gli assiomi predicativi:
        \item \( \forall x F\to F [x/t] \) con \( t \) termine libero per \( x \) in \( F \) {\small \color{gray} (per ``libero'' vedi p.\pageref{terlib})}
            \subitem da questa regola deriva anche:
            \AxiomC{\( F[x/t] \)}
            \UnaryInfC{\( \exists x \ F\)}
            \DisplayProof
        \item \( \forall x (F\to G)\to (F \to \forall x \ G) \), con \( F \) senza occorrenze libere di \( x \) {\small \color{gray} (si dice ``\( F \) non parla di \( x \)'')}\\[1em]
            Gli assiomi dell'identità:
        \item Per ogni simbolo di relazione \( R \):
            \[ \forall x_1 \dots x_n, \ \forall y_1, \dots y_n, \ \left(\bigwedge_{i=1}^{n} (x_i = y_i)\right) \to \bigl(R(x_1, \dots, x_n)\leftrightarrow R(y_1, \dots, y_n)\bigr) \]
        \item Per ogni simbolo di funzione \( f \):
            \[ \forall x_1 \dots x_n, \ \forall y_1, \dots y_n, \ \left(\bigwedge_{i=1}^{n} (x_i = y_i)\right) \to \bigl(f(x_1, \dots, x_n) = f(y_1, \dots, y_n)\bigr) \]
        \item (uguaglianza e transitività)
            \[ \forall x \ y \ z \Bigl( (x = x) \land \bigl((x = y) \to (y = x)\bigr) \land \bigl( (\left(x = y) \land (y = z) \right) \to (x = z)\bigr) \Bigr)\]
            {\small \color{gray}(valgono \( (x = x) \) e \( (x = y \to y = x) \) e \( ((x = y \land y = z) \to x = z) \))}
    \end{enumerate}
\end{gframe}

Le \textbf{regole di inferenza} che utilizziamo nel calcolo predicativo sono:
\begin{enumerate}
    \item \textit{Modus Ponens}:
        \AxiomC{\( X \)}
        \AxiomC{\( X \to Y \)}
        \BinaryInfC{\( Y \)}
        \DisplayProof
    \item \textit{Generalizzazione}:
        {\large \AxiomC{\( F \)}
        \UnaryInfC{\( \forall x \ F \)}
        \DisplayProof}
        \subitem {\small \color{gray}(attenzione ! non è come dire che se una formula \( F\) vale in un caso, allora vale \( \forall x \) - stiamo dicendo che, se ho \textit{dimostrato in maniera generica} \( F \), allora essa è vera \( \forall x \))}
\end{enumerate}

\subsection{Proprietà fondamentali del Calcolo dei Predicati}

Il calcolo dei predicati mantiene molte delle proprietà del calcolo proposizionale, come:
\begin{itemize}
    \item il \textbf{teorema di correttezza}: \( T \vdash A \implies T \vDash A \) (anche qui tutti gli assiomi sono verità logiche e le regole di inferenza preservano le verità logiche)
    \item \( T\vdash A \land T \subseteq S \implies S \vdash A  \)
    \item se \( \vdash A \), \( A \) è detto ``teorema''
    \item 
        \AxiomC{\( T \vdash A \)}
        \AxiomC{\( A \vdash B \)}
        \BinaryInfC{\( T \vdash B \)}
        \DisplayProof
    \item         
        \AxiomC{\( T \vdash A \)}
        \AxiomC{\( S \vdash B \)}
        \BinaryInfC{\( T \cup S \vdash A \land B \)}
        \DisplayProof
\end{itemize}

\vspace{1em}

\begin{thmframe}{Teorema di deduzione per il calcolo predicativo}{}
    Sia \( E \) un enunciato, \( A \) una formula e \( \Gamma \) un insieme di formule.
    Vale:
    \[ \Gamma, E \vdash A \iff T\vdash (E \to A) \]
\end{thmframe}

\textbf{Altre proprietà}:
\begin{itemize}
    \item  Ogni istanza di tautologia proposizionale è una verità nel Calcolo dei Predicati
\end{itemize}

\subsection{Teorema di completezza per la logica predicativa}
Come per la logica proposizionale, vogliamo dimostrare \( T\vDash A \iff T \vdash A \).

Esiste però un'altra definizione equivalente per il teorema di completezza.

\begin{defframe}{Coerenza}{}
    Una teoria \( T \) è \textbf{coerente} (o non-contraddittoria) \(\iff \neg \exists \) enunciato \( A \) t.c. \( T \vdash A \land T\vdash \neg A \)
\end{defframe}

\begin{gframe}{}
    Il Calcolo dei Predicati è coerente, ossia per nessuna formula vale \( \vdash F \land \vdash \neg F \).
\end{gframe}

\begin{defframe}{Teorema di completezza v.2}{}
    \vspace{-1em}
    \[ T \text{ coerente } \iff T \text{ ha un modello } (\in \texttt{SAT}) \]
\end{defframe}

Notiamo facilmente che \( T \) incoerente come testimoniato da \( A \) (ovvero \( T \vdash A \land T \vdash \neg A \)) implica necessariamente \( T \) insoddisfacibile.

Infatti, \( T\vdash A \implies T\vDash A \) \ e \ \( T\vdash \neg A \implies T\vDash \neg A \), e se valgono sia \( T \vDash A\) che \(T \vDash \neg A \) sappiamo che \( T \) è insoddisfacibile (\( Mod(T) = \emptyset \)).

Ci manca da dimostrare \( T \) coerente \( \implies Mod(T) \neq \emptyset\).

\begin{thmframe}{Equivalenza tra le due forme di teorema di completezza}{}
    Si ha che {\color{Blue}(1)} \ \( T \vDash A \iff T \vdash A \ \equiv \ T \text{ coerente} \iff T \text{ ha un modello } (\in \SAT)\) {\color{purple}(2)}
    
\end{thmframe}

\begin{proofframe}
\begin{enumerate}
    \item Assumiamo {\color{purple}(2)} e dimostriamo \( T \vDash A \implies T \vdash A \) 

    Sappiamo che \( T \vDash A \). Ci sono due opzioni:
    \begin{itemize}
        \item \( T \in \UNSAT \): \( T\vDash A \) è vera \( \forall A \), quindi \( T \) incoerente 

            \subitem(se \( \exists B \ \text{ t.c. } \ T\vdash B \ \land \ T \vdash \neg B \), possiamo dimostrare una qualsiasi affermazione \( A \) in questo modo: \( \vdash B\to(\neg B \to A) \))

            quindi \( T \vdash A \)

        \item \( T \in \texttt{SAT} \): se \( T\in \SAT \) e \( T\vDash A \), sappiamo che \( T \cup \neg A \in \UNSAT \). 
            \subitem Per (2), quindi, \( T \cup \neg A \) è incoerente, quindi \( T \vdash A \)

            {\color{CadetBlue}\( T\cup \neg A  \) incoerente significa \( T \cup \neg A \vdash \bot\), quindi (x deduzione) \( T \vdash \neg A \to \bot \); \\
            per reductio ad absurdum ( \((\neg A \to \bot) \vdash A \)), si ha quindi \( T \vdash A \).}
    \end{itemize}

\item Assumiamo {\color{blue}(1)} e dimostriamo \( T \) coerente \(\implies T \) ha un modello

    Presumiamo che \( T \) non abbia un modello. Questo implica logicamente qualsiasi cosa (\( T \vdash A \) e \( T\vdash \neg A \)). Per {\color{blue}(1)}, quindi, \( T\vDash A \) e \(  T\vDash \neg A\), quindi \( T \) incoerente (per contrapposizione, otteniamo l'implicazione originale).

\end{enumerate}
\end{proofframe}

\subsection{Estensioni di teorie}
Vogliamo dimostrare coerenza \( \implies \) soddisfacibilità. Per farlo, introduciamo il concetto di \textit{estensione}.

\begin{defframe}{Estensione}{}
    Diciamo che una teoria \( T' \) \textbf{estende} una teoria \( T \) se \( T \subseteq T' \).
\end{defframe}

\begin{defframe}{Teoria sintatticamente completa}{}
        Una teoria \( T \) si dice \textbf{sintatticamente completa} se per ogni enunciato \( E \) nel linguaggio di \( T \), vale \( T \vdash E \) oppure \( T \vdash \neg E \).
\end{defframe}

\begin{lemmaframe}{Lemma di  Lindenbaum}{}
    Ogni teoria coerente (in un linguaggio numerabile) ammette un'estensione coerente e completa.

    (Sia \( T \) coerente. Allora \( \exists S\) teoria nel linguaggio di \( T \) t.c.:
\begin{itemize}
    \item \( T \subseteq S \)
    \item \(S  \) è coerente
    \item \( S \) è sintatticamente completa
\end{itemize}
    )
\end{lemmaframe}

\begin{proofframe}{}{}
Fissiamo un'enumerazione \( \{ E_1, E_2, \dots \} \) di tutti gli enunciati di \( T \).

Definiamo una successione di teorie in quessto modo:
\begin{itemize}
    \item \( S_0 = T \)
    \item \( S_{n+1} = \begin{cases}
            S_n \cup \{ E_{n+1}\} & \text{se } S_n \cup \{E_{n+1}\} \text{ coerente (ovvero } S_n \not\vdash \neg E_{n+1} \text{)} \\
            S_n  & \text{altrimenti (ovvero } S_n \vdash \neg E_{n+1} \text{)} 

    \end{cases} \)

    {\color{gray} \small nel secondo caso non serve aggiungere \( \{\neg E_{n+1}\} \) perché si ha già \( S_n \vdash \neg E_{n+1} \) (sarebbe superfluo)}
\end{itemize}
Sia \( S = \bigcup_{n\in \N} S_n \).
\begin{enumerate}
    \item \( S \) è \textbf{coerente}

        \( S \) è coerente significa che \( \not \exists E \) per cui \( \exists \{A_1, A_2, \dots, A_t\} , \{B_1, B_2, \dots, B_t\} \subseteq S\) t.c.\\ \(  A_1, A_2, \dots, A_t\vdash E\) e \(  B_1, B_2, \dots, B_t\vdash \neg E\).

        Si nota facilmente che questo è impossibile, in quanto, per costruzione, entrambi gli insiemi di enunciati apparterrebbero a un \( S_m \) per qualche \( m \) (vista la costruzione ``a catena'' di \( S \)), e si avrebbe \( S_m \vdash E \) e \( S_m \vdash \neg E \), quindi \( S_m \) incoerente (ma per costruzione, \( \forall i\ S_i \) è coerente).
        

    \item \( S \) è sintatticamente \textbf{completa}

        Scegliamo di dimostrarlo nella forma \( S\not\vdash \neg E \implies S \vdash E \)

        Sia \( E = E_{n+1} \) per un qualche \( n \). Sappiamo che \( \forall i\) e in particolare per \( n, \ S_n\not\vdash \neg E_{n+1}\). 

        Quindi, per costruzione \( S_{n+1} = S_n \cup \{E_{n+1}\} \implies S_{n+1} \vdash E_{n+1} \overset{{\color{gray}S_{n+1}\subseteq S}}{\implies}  S \vdash E_{n+1} \).
\end{enumerate}

\end{proofframe}

Se invece di \( T \) coerente avessimo ipotizzato \( T \) soddisfacibile, la conclusione sarebbe stata banale perché si sarebbe definita \( S \) facilmente come (dato \( \Aa \) modello di \( T \)) \( S = Th(\Aa) = \{E \mid \Aa \vDash E\}\), evidentemente coerente e completo.

Il teorema di completezza mostra che le due cose sono equivalenti.

Abbiamo quindi dimostrato che \( T \) coerente \( \implies \exists S \supseteq T\) coerente e completa. \\Vogliamo però \( T \) coerente \( \implies T \) soddisfacibile.

Il passo successivo è dimostrare che \( S \) è già quasi un modello.

Cerchiamo quindi un modello \( \Mm = (M, \Rr^\Mm, f_j^\Mm, c_i^\Mm) \)

Per definirlo, facciamo alcune assunzioni.

Assumiamo di lavorare con un linguaggio \( \Ll = \{R_i, f_j, c_k\} \) che contenga almeno una costante e una funzione (nota bene: se ci sono una costante e una funzione, ci sono infiniti termini chiusi).

Definiamo \( \Mm \) (detto \textbf{modello di Henkin} dei termini di \( S \)):
\begin{itemize}
    \item \( M = \{\text{termini chiusi di } \Ll \}\)
        \subitem {\color{gray}es. \( \Ll_1 = \{0, 1, +\}, \ M = \{0, 1, 0+0, 0+1, 1+0, \dots\} \)} 
    \item \( c_k^\Mm = c_k \in M \) 
        \subitem l'interpretazione della costante \( c \) è data dalla costante \( c \) stessa
        \subitem {\color{gray} es. \( \Ll_2 = \{e, *\}, M_2 = \{e, e*e, \dots\} \) - come interpretazione di \( c_0 = e \) prendo \( e\in M_2 \)}
    \item l'interpretazione di un simbolo di relazione \( \Rr \) è data dall'insieme dei termini chiusi di cui \( S \) dimostra che soddisfano la relazione - ovvero \( (\Mm_1, \dots, \Mm_n) \in \Rr^\Mm_i \iff  S \vdash \Rr_i(t_1, \dots, t_n)\)
    \item l'interpretazione di un simbolo di funzione \( f \) è l'associazione \( t_1, \dots, t_n \mapsto f(t_1, \dots, t_n) \) - \( f^\Mm_j : M^n \to M \) è t.c. \( f^\Mm_j (t_1, \dots, t_n) := f_j(t_1, \dots, t_n) \)
        \subitem {\color{gray}es. \( +^\Mm(0,1) = \underbracket{+(0,1)}_{t} \)}

\end{itemize}

Osserviamo che l'interpretazione in \( \Mm \) di un termine chiuso \( t \) coincide con il termine stesso (\( t^\Mm = t \)).

Vogliamo dimostrare \( \Mm \vDash S \). Per farlo (come spesso accade) ci è più comodo dimostrare un'affermazione più forte: \( \forall E \ \Mm \vDash E \iff S \vdash E \).

\begin{proofframe}{}
    Dimostriamo per casi (su \( E \)):
    \begin{itemize}
        \item \( E \)  è \( \neg G \)

            \subitem se \(\Mm \not \vDash E\), per ipotesi induttiva si ha \( S \not \vdash G \) e da \( S \) completa segue \( S \vdash \neg G \).

            \subitem se \( \Mm \vDash E \), allora per ipotesi induttiva \( S \vdash G \) e da \( S \) coerente segue \( S \not\vdash \neg G \)


        \item \( \Mm \vDash G \land H \) {\color{CadetBlue}\( \iff S\vdash G \land H \)}

            (\( \implies \)) {\color{CadetBlue}supponiamo \( \Mm \vDash G\land H \);}
            \subitem allora, \( \Mm \vDash G \ \land \Mm \vDash H\) 

            \subitem per ipotesi induttiva, abbiamo \( S \vdash G \ \land S \vdash H \), e usando la tautologia \( G\to (H \to (G \land H)) \) ottengo \( S\vdash G\land H \) 

            (\( \impliedby \)) {\color{CadetBlue}supponiamo \( S \vdash G \land H \);}
            \subitem per la tautologia \( G\land H \to G \), otteniamo \( S\vdash G \ \land \ S \vdash H \)

            \subitem per ipotesi induttiva, segue \( S\vDash G \ \land \ S \vDash H \), da cui \( S\vDash G \land H \)
            
        \item se \(E\) è un enunciato atomico \( R(t_1, \dots, t_k) \), abbiamo che \( \Mm \vDash R(t_1, \dots, t_n) \) per definizione \(\iff (t^\Mm_1, \dots t^\Mm_n)\in \R^\Mm \) e, per l'osservazione sui termini, \( \iff (t, \dots, t_n)\in R^\Mm \), il che per definizione equivale a \( S\vdash R(t_1, \dots, t_n) \)

        \item se \( E \) è del tipo \( \forall x F \)

            sappiamo \( \iff \forall m \in M \Mm \vDash F \tworowmatrix{x}{m}\)

            {\color{CadetBlue}e qui vale \( \Mm \vDash F \tworowmatrix{x}{m} \iff \Mm \vDash F[x/m]\)}

            \subitem per ipotesi induttiva, abbiamo che \( \forall m \in M, \ S\vdash F[x/m] \), ma non abbiamo il \( \iff \). 

            sappiamo \( S \vdash \forall x F \implies S\vdash F[x/t] \), ma non l'altro verso {\color{gray}\small (è come dire che sappiamo che per ogni numero c'è una dimostrazione, ma vogliamo che ci sia una dimostrazione per ogni numero)}
    \end{itemize}
\end{proofframe}

Possiamo definire una teoria che ci aiuta nella dimostrazione.

\begin{defframe}{Teoria con testimoni}{}
    Una \textbf{teoria con testimoni}, o \textbf{teoria di Henkin} (o ``scapegoat theory'')  soddisfa la seguente proprietà:
    \begin{itemize}
        \item \( \forall \) formula \( F \) con un'unica variabile libera \( x \), \( \exists \) un  termine chiuso \( t \) t.c.
            \[ T \vdash \exists x \neg F(x) \to \neg F(t) \]

            \subitem (\( t \) è un testimone dell'enunciato \( \exists x \neg F(x) \))
    \end{itemize}

    {\color{CadetBlue}(un testimone è un termine specifico (\( t \)) che la teoria ``nomina'' per concretizzare un'affermazione esistenziale - normalmente, se diciamo \( \exists x P(x) \), non sappiamo chi sia \( x \) per cui \( P \) vale; se siamo in una teoria con testimoni, invece, abbiamo \( \exists x P(x) \to P(t) \), sappiamo esattamente chi sia \( t \))}
\end{defframe}

Vediamo come una teoria con testimoni ci aiuta a dimostrare il caso \( \forall x F(x) \) con \( F(x) \) aperta.

\begin{pframe}
(Dimostriamo che, se \( \Mm \vDash \forall x F \) allora \(T \vdash \forall x F\))

Per assurdo, supponiamo \( \Mm \vDash \forall x F \) e \( T \not\vdash \forall x F \).

Per completezza di \( T \) vale \( T \vdash \neg E \), ovvero \( T \vdash \exists x \neg F(x) \). Dato che \( T \) è una teoria con testimoni, esiste un termine chiuso \( t \) tale che \( T \vdash \exists x \neg F(x) \to \neg F (t) \). 

Dunque \( T\vdash \neg F(t) \).

Per ipotesi induttiva, \( \Mm \vDash \neg F(t)\). Ma da \( \Mm \vDash \forall x F(x) \), e da \( \Mm \vDash \forall x F(x)\), vale, per qualsiasi termine chiuso \( \Mm \vDash F(x) \to F(t)\).

Dunque, \( \Mm \vDash F(t)\), il che contraddice \( \Mm \vDash \neg F(t) \). \qed

\end{pframe}

Se \( T \) coerente, \( T \) si può estendere a \( T^* \supseteq T\) che sia coerente e con testimoni (in un \( \Ll \) che estende \( \Ll_T \) con un insieme numerabile di costanti.

\begin{thmframe}{}{}
    Per ogni teoria \( T \) coerente esiste una teoria  \( T' \) tale che:
    \begin{itemize}
        \item \( T' \) è un'estensione di \( T \)
        \item \( T' \) è una teoria con testimoni
        \item il linguaggio di \( T' \) è numerabile ed estende quello di \( T \)
        \item \( T' \) è coerente
    \end{itemize}
    
\end{thmframe}

\begin{proofframe}{}{}
    Sia \( T \) coerente. 

    Sia \( T_0  = T \ \cup \ \{\text{istanze degli assiomi logici nel linguaggio esteso}\}\).

    Fissiamo un'enumerazione delle formule in \( \Ll \) con una variabile libera: \( F_1(x_1), F_2(x_2), \dots \)

    Sia \( B = \{b_1, b_2, b_3, \dots\} \) un insieme di nuovi simboli di costante. Fissiamone un'enumerazione \( b_{j1}, b_{j2}, \dots \), in cui \( b_{jk} \) è il primo (per indice) t.c.
    \begin{itemize}
        \item \( b_{jk} \) non appare in \( F_1(x_1), \dots, F_k(x_k) \)
        \item \( b_{jk} \) è diverso da \( b_{j1}, \dots, b_{j_{k-1}} \)
    \end{itemize}

    {\small \color{gray} quindi \( b_{j1} \) è la prima costante \( \not \in F_1\), \( b_{j2} \) la prima che non compare in \( F_2 \) e non è già stata usata (quindi \( \neq b_{j1} \)), ecc}

    Sia \( W_k \) il seguente enunciato:
    \[ \exists x_k \neg F_k(x_k) \to \neg F_k(b_{jk})\]

    Sia \( T_n = T_0 \cup \{W_1, \dots, W_n\} \), e sia \( T_{\infty} = \bigcup_n T_n \).

\textbf{claim}: \( T^* = \bigcup_{n\in \N} T \) è di Henkin, coerente ed estende \( T \).

{\color{CadetBlue} di Henkin: \( \forall n \exists t = b_{j_n} \) t.c. \( T^* \ni \exists x_n \neg F_n(x_n) \to \neg F_n (b_{j_n})\) è vero per costruzione}

    \begin{itemize}
        \item Dimostriamo che \( T_\infty \) è coerente (basta dimostrare che \( \forall n \ T_n \) coerente)
    \end{itemize}

    per induzione:

    \begin{itemize}
        \item \textbf{C.B.}: \( T_0 \) è coerente
            \subitem {\color{gray} ``banale'', \( T \) coerente e abbiamo aggiunto a \( T \) solo assiomi}

            \subitem {\color{gray}\( T_0 \vdash \bot \implies T \cup \underset{\text{assiomi}}{A = \{A_1, \dots, A_t\}} \vdash \bot \implies T \vdash A \to \bot\) - visto che \( A \) assiomi, \( T \vdash  A \) e per MP, \( T\vdash \bot \) - ma questo è impossibile perché \( T \) coerente)}

        \item \textbf{P.I.}: assumiamo \( T_{n-1} \) coerente

            per assurdo, sia \( T_n \) incoerente;

            allora, si ha \( T_n \vdash \bot \), e \( \bot \to B \implies T_n \vdash B \ \forall B \); quindi \( T_n \vdash \neg W_n \);

            ma \( T_n = T_{n-1} \cup \{W_n\} \), quindi (per deduzione) \( T_{n-1} \vdash W_n \to \neg W_n \);

            {\color{gray}\small \( \neg W_n \) è una negazione di un'implicazione (quindi verifica la premessa \( \exists x_n \neg F_n (x_n) \) e falsifica la conseguenza \( \neg F_n (b_{j_n}) \))} quindi \( T_{n-1} \vdash \exists x_n \neg F)n (x_n)\) e \( T_{n-1} \vdash F_n (b_{j_n})  \).

        Per costruzione, sappiamo che \( T_{n-1} = T_0 \) {\color{gray}\small \( (= T \ \cup\ \) assiomi) } \( \cup \ \{W_1, \dots, W_{n-1}\} \); abbiamo scelto \( b_{j_n} \) e quindi sappiamo che:
        \begin{itemize}
            \item esso non compare in \( W_1, \dots, W_{n-1} \);
            \item per definizione, non compare in \( T \);
        \end{itemize}
            Dovrà quindi far parte degli assiomi logici.

            Notiamo che quindi, sostituendo \( b_{j_n} \) con una nuova variabile, la formula restante rimarrà un assioma logico.

            Sia quindi \( y \) una variabile che non compare nella dimostrazione \( \delta \) (di \( F_n(b_{j_n}) \)). 

            \textbf{claim}: \( \delta^y = \delta [b_{j_n}/y] = (D^y_1, \dots, D^y_n) \) è ancora una dimostrazione.

            Infatti:
            \begin{itemize}
                \item gli assiomi rimangono tali (o non dicono niente su \( b_{j_n} \)) o dicono cose sempre vere, quindi sostituendo non cambia nulla
                \item le ipotesi \( T_{n-1}, W_1, \dots, W_n \) non cambiano, in quanto \( \not \ni b_{j_n} \)
                \item il Modus Ponens è preservato
                \item la Generalizzazione non viene mai applicata su \( b_{j_n} \) (vorrebbe dire che una formula \( \forall y H(y) \) sarebbe stata ottenuta da una formula \( H(b_{j_n}) \) (ricordiamo che \( b_{j_n} \) è una costante specifica), il che è impossibile)
            \end{itemize}

            Ora - se è vero \( T_{n-1} \vdash F_n(y) \), per Generalizzazione si ha anche \( T_{n-1} \vdash \forall y F_n(y) \). Ma abbiamo anche \( T_{n-1} \vdash \exists x \neg F_n(x) \). Le due cose sono chiaramente contraddittorie, quindi \( T_{n-1} \) è incoerente. \qed
    \end{itemize}
\end{proofframe}

Quindi, possiamo formalizzare i seguenti teoremi:

\begin{thmframe}{}{}
    Sia \( T \) una teoria con testimoni e coerente in un linguaggio numerabile. Allora, \( T \) ha un modello numerabile.
\end{thmframe}

\begin{thmframe}{Esistenza del modello}{}
    Ogni teoria coerente (in un linguaggio numerabile) ha un modello numerabile.
\end{thmframe}

\begin{proofframe}
    Partiamo da \( T \) coerente \  {\color{CadetBlue}(in \( \Ll) \)}
    \begin{itemize}
        \item \( \overset{\text{Henkin}}{\implies} \ T^* \supseteq T \) coerente con testimoni \  {\color{CadetBlue}(in \( \Ll^* \text{ numerabile } \supseteq \Ll) \)}

        \item \( \overset{\text{Lindenbaum}}{\implies} \ \hat T \supseteq T^*\) coerente e completa con testimoni \ {\color{CadetBlue}(in \( \Ll^*)\)
            \subitem (la proprietà di essere con testimoni è preservata perché il lemma di Lindenbaum non cambia il linguaggio)}
        \item \( \implies \ \Mm_{\hat T} \vDash  T \)  (il modello dei termini di \( \hat T \) è un modello numerabile di \( T \))

    \end{itemize}
    
\end{proofframe}

\textbf{nota bene} ! 

\textbf{logica con identità}

La dimostrazione sopra descritta si limita alla logica di primo ordine senza identità.

Per il modello sopra definito, \( \Mm \vDash (t_1 = t_2) \iff \) \( t \) ed \( s \) sono esattamente lo stesso termine {\color{gray}(quindi, per esempio, \( (1+1) \neq 2 \))}.

Per risolvere questo problema, basta quozientare sulla seguente relazione:
\[ t \sim s \iff T\vdash(t = s) \]

\begin{itemize}
    \item notiamo che \( \sim \) è una relazione di equivalenza
\end{itemize}

Definiamo quindi il modello dei termini \( \Mm/\sim \) in questo modo:
\begin{itemize}
    \item il dominio è \( M/\sim = \{[t]_\sim \mid t \text{ termine chiuso}\}\)
    \item \( c^{\Mm/\sim} = [c]_\sim\)
    \item \( f^{\Mm/\sim}([t_1]_{\sim}, \dots, [t_n]_{\sim}) = [f(t_1, \dots, t_n)]_{\sim} \)
    \item \(([t_1]_{\sim}, \dots, [t_n]_{\sim}) \in R^{\Mm/\sim}\) se e solo se \(T \vdash R(t_1, \dots, t_n)\)
\end{itemize}

La dimostrazione \( \Mm/\sim \vDash E \iff T\vdash E \) procede esattamente come quella di \( \Mm \). Inoltre, se \( \Mm \) ha cardinalità numerabile, anche \( \Mm/\sim \) ha cardinalità numerabile.

\section{Teorema di compattezza}
Il teorema di compattezza si può riformulare in diversi modi:

\begin{thmframe}{Teorema di compattezza, versioni equivalenti}{}

    \begin{itemize}
        \item Un insieme di enunciati è coerente se e solo se ogni suo sottinsieme finito è coerente.

        \item Un insieme di enunciati ha un modello se e soltanto se ogni suo sottoinsieme finito ha un modello.

        \item \( T\vDash E \) se e solo se esiste un sottoinsieme finito \( T_0 \subseteq T \) tale che \( T_0 \vDash E \).
    \end{itemize}
    
\end{thmframe}

\subsection{Applicazione: (non) assiomatizzabilità}

Data una proprietà \( P \) di strutture, è utile chiedersi se possa essere espressa da enunciati del primo ordine, ovvero se esista un insieme di enunciati \( T \) che soddisfa, per ogni struttura \( \Aa \), la seguente equivalenza:
\[ \Aa \vDash T \iff \Aa \text{ ha la proprietà }  P \]

Se un tale \( T \) esiste, diciamo che \textbf{assiomatizza} o \textit{definisce} la proprietà \( P \).

Ha ancora più senso chiedersi, nello specifico, data una classe di strutture \( \Cc \) e un linguaggio predicativo \( \Ll \), se esista una teoria in \(\Ll \) tale che la proprietà s opra sia soddisfatta.

Se esiste una teoria \( T \) che assiomatizza una proprietà \( P \), ci si può chiedere se esiste un \textit{insieme finito di enunciati} che assiomatizza \( P \). Questo è equivalente a chiedersi se esiste un singolo enunciato \( E \) {\color{gray} (l'AND tra tutti gli enunciati)} tale che, per ogni struttura \( \Aa \) nella classe \( \Cc \),
\[ A \vDash E \iff \Aa \text{ ha la proprietà } P\]


In questo caso, diciamo che \( P \) è \textbf{finitamente assiomatizzabile} relativamente alla classe \( \Cc \).

\textbf{Esempio 1: finitezza}

\begin{itemize}
    \item \( P = \) ``avere dominio finito'';
    \item \( \Cc =  \) tutte le strutture;
\end{itemize}


Partiamo da \( P_n = \) ``avere dominio di cardinalità \( \geq n \)''.

Possiamo assiomatizzare questa proposizione con un linguaggio \( \Ll \) ``vuoto'' (senza relazioni specifiche) in questo modo:
\[ 
    \exists x_1, \dots, x_n \left( \ \bigwedge_{i \neq j, \ 1\leq i\leq n} \neg (x_i = x_j)\ \right)
\]


{\color{CadetBlue}Possiamo assiomatizzare anche la proprietà ``avere dominio di cardinalità \( n \)'' in questo modo:
\[  
    \exists x_1, \dots, x_n \left( \ \bigwedge_{i \neq j, \ 1\leq i\leq n} \neg (x_i = x_j) \land \forall y \left( \bigvee_{i=1}^n (y = x_i)\right)\ \right)
\]
}

\begin{propframe}{Assiomatizzazione di ``avere un dominio finito / infinito''}{}
    La proprietà ``avere dominio infinito'' è assiomatizzabile ma non finitamente assiomatizzabile.

    La proprietà ``avere dominio finito'' non è assiomatizzabile.
\end{propframe}

\begin{pframe}
Consideriamo \( T = \{P_n \mid n \in \N\} \) (``avere dominio di cardinalità almeno \( n \)'' per ogni \( n \)). La teoria \( T \) assiomatizza ``avere un dominio infinito'' {\color{gray}\small (se si ha dominio almeno \( n \) per ogni \( n \))}

Sia per assurdo \( F \) una teoria che assiomatizza \( P = \) ``avere dominio finito''.

Consideriamo \( F \cup T \). \( F\cup T \) non può avere modelli (in quanto parla di essere finito e infinito allo stesso tempo).

Se ne prendo un qualsiasi pezzo finito \( T_0 \subseteq F \cup T \), noto però che esso ha un modello (in quanto descrive, ``alla peggio'', l'avere dominio finito (da \( F \)) e l'avere almeno \( n \) elementi (da \( T \))).

Visto che \( T_0 \) ha un modello, per compattezza tutta la teoria dovrebbe avere un modello \( (\texttt{FINSAT}\implies \texttt{SAT}) \), il che è impossibile. \qed

Vediamo anche che è impossibile che ``avere dominio infinito'' sia \textit{finitamente} assiomatizzabile.

Infatti, se esistesse \( S \) finita t.c. \( \Aa \vDash S \iff \Aa  \) ha dominio infinito, avremmo che \( \neg S \) assiomatizzerebbe ``avere dominio finito'' (impossibile). \qed
\end{pframe}

\begin{lemmaframe}{}{}
    Sia \( P \) assiomatizzabile. Se \( \neg P \) non è assiomatizzabile, allora \( P \) non è finitamente assiomatizzabile.

    Per contrapposizione, se \( P, \neg P \) sono assiomatizzabili, allora P è finitamente assiomatizzabile.
\end{lemmaframe}

\begin{lemmaframe}{}{}
    Se \( P \) è assiomatizzabile da \( T \) e \( P \) è finitamente assiomatizzabile, allora \( \exists T_0 \subseteq T \) che assiomatizza \( P \).
\end{lemmaframe}

\begin{lemmaframe}{}{}
    Se \( T \) ha modelli finiti arbitrariamente grandi (per ogni \( n \) c'è un modello con almeno \( n \) elementi), allora \( T \) ha anche modelli infiniti.
\end{lemmaframe}

\begin{gframe}{(Non) assiomatizzazione di ``essere un grafo connesso``}
    Consideriamo i grafi, con linguaggio \( \Ll = \{E(x,y)\} \), e la proprietà \( P = \) ``essere un grafo connesso''.

    Possiamo scrivere la proprietà \( D_n = \) ``essere a distanza \( \geq n \)'' in questo modo:
    \[ \neg (\exists x_1, \dots, x_n \left(\bigwedge_{i \neq j}\neg (x_i = x_j) \land E(c, x_1)\land E(x_1, x_2) \land \dots \land E(x_n, d)\right))\]

    Supponiamo che \( P \) sia assiomatizzabile da una teoria \( C \).

    Consideriamo \( C \cup \{D_n \mid n\geq 0\} \) - questa teoria non può avere un modello.

    Come prima, consideriamo un pezzo finito \( T_0 \subseteq C \cup \{D_n \mid n\geq 0\} \). 

    Come prima, questo sottoinsieme ha un modello (un grafo connesso con vertici a distanza \( > \) del massimo \( n \)). Come prima, avremmo \(\texttt{FINSAT} \implies \texttt{SAT} \), e per questo si ha che \( P \) non è assiomatizzabile. \qed
\end{gframe}

\subsection{Modelli non standard dell'aritmetica}

Dato \( \Nn = (\N, 0, 1, +, *, \leq ) \), possiamo definire la sua teoria \( T = Th(\Nn) = \{E \mid \N \vDash E\} \).

Sia \( \Aa \vDash Th(\Nn) \). Quanto assomiglia \( \Aa \) ad \( \N \)?

Noi vorremmo \( \Aa \iso \Nn \), ma in realtà esistono molti modelli di \( \Nn \) molto differenti dai numeri naturali che conosciamo.

Consideriamo per esempio una nuova costante \( c \) e la teoria:
\[ T \cup \{A_n \mid n\in \N\} \]
con \( A_n = \underbracket{1 + \dots + 1}_{n} < c \).

Un sottooinsieme qualsiasi \( T_0 \subseteq T \cup \{A_n \mid n\in \N\} \) ha un modello - basta dare un'interpretazione alla costante \( c \).

Per esempio, \( \Aa = (\N, +^\Nn, x^\Nn, 0^\Nn, 1^\Nn, c^\Aa = max(a_1, \dots, a_k)+1)\) è un modello di \( T_0 \).

Per compattezza, quindi, \(T\cup \{A_n \mid n \in \N\}  \) ha un modello.

Ma come interpretiamo \( c^\Aa \) in questo modello? Deve esserci un unico \( c \) tale che, \( \forall n, \underbracket{1 + \dots + 1}_{n} <^\Aa c^\Aa  \).

Deve quindi esserci un \( c \) maggior di tutti gli elementi di \( \N \). 

Questo modello è molto diverso da \( \N \).\( \Aa \) è quello che si dice \textbf{modello non-standard} dell'aritmetica, e \( c^\Aa \) è un \textit{naturale non-standard}.

Inizia infatti con \( \N \), ma contiene almeno un elemento maggiore di tutti i numeri standard. Inoltre, se \( a\in \Aa \)  è un numero non-standard, allora anche il suo predecessore è un numero non-standard. Un elemento non-standard ha quindi infiniti predecessori e successori, nessuno dei quali può essere standard. 

Intorno a \( c^\Aa \) si sviluppa quindi una copia isomorfa a \( \Z \).

Si esclude quindi che si possa definire una teoria \( T \) che assiomatizzi \( Th(\Nn) \) in modo che valga, come per DLO< che tutti i modelli numerabili di \( T \) sono isomorfi. Resta aperta però la possibilità di trovare un insieme di assiomi \( T \) con insieme di teoremi computabilmente enumerabili che coincida con la ``vera'' Teoria dei Numeri \( Th(\Nn) \).Una tale teoria sarebbe completa e dunque decidibile e fornirebbe un algoritmo per decidere automaticamente se un enunciato \( E \) è un teorema della Teoria dei Numeri o no.

\chapter{I teoremi di Gödel}
\section{Funzioni calcolabili (algoritmiche)}
Esistono diverse definizioni di algoritmo. Le principali ci vengono date da Gödel, Herbrand e Kleene (in chiave matematica), da Turing (attraverso le TM), e da Church (nel \( \lambda \)-calcolo).

\begin{defframe}{Funzioni calcolabili}{}
    La classe \( \Cc \) delle funzioni parziali calcolabili è la minima classe di funzioni del tipo \( \N^k \to \N \) (con \( k\in N \)) t.c.:
    \begin{itemize}
        \item \( +, * \in \Cc \)
        \item \( i(x, y) = \begin{cases}
                1 & \text{se } x = y\\
                0 & \text{se } x \neq y
        \end{cases} \)
    \item \( \prod_i^n (x_1, \dots, x_n) = x_i \) \ {\color{CadetBlue}(proiezione)}
    \end{itemize}
    e \( \Cc \) chiusa sotto composizione -
    date \( \theta_1, \dots, \theta_n: \N^k \to \N, \psi:\N^m \to \N \), la composta \( \phi \) è definita come segue:
    \[ \phi(x_1, \dots, x_n) = \psi(\theta_1(x_1, \dots, x_n), \dots, \theta_n(x_1, \dots, x_k)) \]

    \( \Cc \) è chiusa anche sotto \textit{minimalizzazione}:
    data \( g(\vec{x}, y)\), la funzione \( h(\vec{x}) \) è definita come \( h(\vec{x}) = min \ z\) t.c. 
\begin{itemize}
    \item i valori \( g(\vec{x}, 0 ), g(\vec{x}, 1), \dots, g(\vec{x}, z-1)\) sono definiti e \( \neq 0 \)
    \item \(g(\vec{x}, z ) = 0 \)
    \item (se un tale \( z \) non esiste, la funzione non è definita)
\end{itemize}

\end{defframe}

\begin{propframe}{}{}
    Si ha che \( f\in \Cc \implies f  \) calcolabile.
\end{propframe}

\begin{itemize}
    \item Nella composizione di funzioni $h(g_1, \dots, g_m)$:
    \begin{itemize}
        \item Se tutte le $g_i$ e $h$ fossero totali, si applicherebbero semplicemente le $g_i$ e poi $h$ sul risultato.
        \item Se una delle $g_i$ è indefinita, il calcolo procede comunque secondo la logica algoritmica: il programma semplicemente non termina (non si arriva mai ad applicare $h$).
            \subitem (anche se il risultato è indefinito, il processo rimane algoritmico).
    \end{itemize}
\end{itemize}

Per calcolare una composizione come $h(g_1(\vec{x}), g_2(\vec{x}), \dots)$, è necessario stabilire un ordine di esecuzione:
\begin{itemize}
    \item Non si possono far partire le funzioni in parallelo; devono essere eseguite in ordine sequenziale.
    \subitem se si procedesse in parallelo, si potrebbe trovare un risultato per $g_2$ mentre $g_1$ sta ancora calcolando (o è in loop infinito).
    \item Per definizione, se un argomento è indefinito, l'intera composizione deve esserlo. Procedendo in ordine, se ci si ``ferma'' su $g_1$, il calcolo si arresta correttamente senza produrre risultati parziali o errati basati sugli altri argomenti.
\end{itemize}

(Anche \( g(\vec{x}, y) \) è algoritmica perché lo è \( h(\vec{x}) \))

\begin{propframe}{Calcolabilità}{}
    

\begin{itemize}
    \item Una funzione $\varphi: \mathbb{N}^k \rightarrow \mathbb{N}$ è calcolabile $\iff \varphi \in \mathcal{C}$.
    \item  $R \subseteq \mathbb{N}^k$ si dice calcolabile se la sua \textbf{funzione caratteristica} $\chi_R$ è calcolabile.
    \subitem 
    \(
    \chi_R(\vec{x}) = \begin{cases} 
    1 & \text{se } \vec{x} \in R \\ 
    0 & \text{se } \vec{x} \notin R 
    \end{cases}
    \)
\end{itemize}
\end{propframe}

\section{Teorema di Definibilità}
\begin{defframe}{Definibilità}{}
    Diciamo che \( \varphi \) è \textbf{rappresentabile} in \( \Nn \) da una formula \( F(x_1, \dots, x_k, y) \) se per ogni tupla di numeri naturali \((a_1, \dots, a_k, b) \subseteq \mathbb{N}^{k+1}\), vale l'equivalenza:
    \[
        \varphi(a_1, \dots, a_k) = b \iff \Nn \models F \left[\ass{x_1, \dots, x_k, y}{a_1, \dots, a_k, b}\right]
    \]
i.e. se le k+1-ple \( (a_1, \dots, a_k, b) \) appartententi al grafo di \( \varphi \) sono esattamente quelle che soddisfano in \( \Nn \) la formula \( F(x_1, \dots, x_k, y) \) assegnando \( a_i \) a \( x_i \) e \( b \) a \( y \).

{\color{Gray}\small(la formula è vera nel modello standard \(\mathcal{N}\) se e solo se la funzione, calcolata sugli input \(a_i\), restituisce \(b\)).}

Nel linguaggio dell'aritmetica, ogni numero naturale \( n\in \N \) ha un nome canonico (\textbf{numerale}) costituito dalla somma di \( n \) volte la costante \( 1 \).

Quindi, vale che:
\[  \Nn \models F \left[\ass{x_1, \dots, x_k, y}{a_1, \dots, a_k, b}\right] \iff \Nn \vDash F(\bar{a_1}, \dots, \bar{a_k}, \bar{b})\]
\end{defframe}

\begin{thmframe}{Teorema di Definibilità}{}
    Le funzioni calcolabili sono definibili in \( \Nn \).
\end{thmframe}

\begin{proofframe}[title=per induzione]
    \begin{itemize}
        \item \textbf{C.B.}: le funzioni di base sono definibili in \( \Nn \)

            \subitem L'addizione è definita dalla formula \( F(x, y, z) := ((x + y) = z) \), la moltiplicazione dalla formula \( G(x, y, z) := ((x \times y) = z) \), la proiezione \( \pi_{i}^{n}(x_1, \dots, x_n) = x_i \) (dove \( i \in [1, n] \)) è definibile dalla formula \( H(x_1, \dots, x_n, z) := (x_1 = x_1 \wedge \dots \wedge x_i = z \wedge \dots \wedge x_n = x_n) \), la funzione caratteristica dell'uguaglianza dalla formula \( I(x, y, z) := (x = y \wedge z = 1) \vee (x \neq y \wedge z = 0) \). \hfill \(\square\)

        \item \textbf{chiusura per composizione}: le funzioni definibili in \( \Nn \) sono chiuse per composizione

Siano:
\begin{align*}
    H_1(x_1, \dots, x_k, y_1) & \quad \text{che rappresenta } \vartheta_1 \\
    H_2(x_1, \dots, x_k, y_2) & \quad \text{che rappresenta } \vartheta_2 \\
    \vdots & \\
    H_m(x_1, \dots, x_k, y_m) & \quad \text{che rappresenta } \vartheta_m
\end{align*}

E sia:
\[
G(y_1, \dots, y_m, z) \quad \text{che rappresenta } \Psi
\]

Voglio una formula $F(x_1, \dots, x_k, w)$ che rappresenti la funzione composta $\Psi(\vartheta_1, \dots, \vartheta_m)$.

Quand'è che \((x_1, \dots, x_k, w) \in \text{grafico composta}(\Psi, \vartheta_1, \dots, \vartheta_m)$? Se $W$ è il valore di $\Psi$ con argomenti = $m$ valori di $\vartheta_1, \dots, \vartheta_m$ applicate a $(x_1, \dots, x_k)\).

La formula è:
\[
\exists y_1 \dots y_m \quad (\text{se esistono gli } m \text{ valori intermedi})
\]
tale che:
\[
H_1(x_1 \dots x_k, y_1) \land H_2(x_1 \dots x_k, y_2) \land \dots \land H_m(x_1 \dots x_k, y_m)
\]
\[
\land \quad G(y_1, \dots, y_m, W) \quad (\text{valore } G(y_1 \dots y_m))
\]

\textit{NB:} Questo finisce nel grafico della composta se \(\exists y_1 \dots\) (se le intermedie sono indefinite, anche la composta lo è).

Si vede che questa formula è soddisfatta $\iff$ l'elemento appartiene al grafico della composta.
        \subitem siano 
        
        \item \textbf{chiusura per minimo}: le funzioni definibili in \( \Nn \) sono chiuse per minimo

Sia \(H(x_1, \dots, x_k, y, z)\) una formula che rappresenta \(\vartheta(x_1, \dots, x_k, y)\).

Voglio \(G\) con variabili \((x_1, \dots, x_k, S)\) dove \(S\) è il minimo tale che:
\[
\vartheta(x_1, \dots, x_k, S) \downarrow = 0 \quad
\land \quad \forall w \ (0 \le w < S, \ \vartheta(x_1, \dots, x_k, w) \downarrow \neq 0)
\]

La formula risultante è:
\[
H(x_1, \dots, x_k, S, 0) \land \forall w (w < S \to \exists z (H(x_1, \dots, x_k, w, z) \land z \neq 0))
\]
    \end{itemize}
\end{proofframe}

\begin{defframe}{Calcolabilità e rappresentabilità di una relazione}{}
    Una relazione \( R \subseteq N^n \) è calcolabile se e solo se la sua funzione caratteristica è calcolabile.

    Una relazione \( R \) è rappresentabile in \( \Nn \) se e solo se \( \exists F(x_1, \dots, x_k) \) t.c. \( \forall n_1, \dots, n_k \in \N\):
    \begin{align*}
        (n_1, \dots, n_k) \in R &\implies \Nn \vDash F(\bar{n_1}, \dots, \bar{n_k}) \\
        (n_1, \dots, n_k) \not\in R &\implies \Nn \vDash \neg F(\bar{n_1}, \dots, \bar{n_k})
    \end{align*}
\end{defframe}
\begin{thmframe}{Rappresentabilità di relazioni}{}
     Tutte le relazioni calcolabili sono rappresentabili in \( \Nn \)
\end{thmframe}
\begin{pframe}
    \( R \) è calcolabile se e solo se \( \chi_R \in \Cc \).

    Sia \( F(x_1, \dots, x_k, y) \) che rappresenta \( \chi_R \).

    Questo significa che \( \chi_R(n_1, \dots, n_k)=b \iff \Nn \vDash F(\bar{n_1}, \dots, \bar{n_k}, \bar{b}) \). Abbiamo che \( b\in \{0,1\} \).

    I vettori che appartengono a \( R \) sono quelli che danno \( 1 \) (per come definiamo \( \chi_R \)), quindi \( F(x_1, \dots, x_k, 1)\) rappresenta \( R \).

    Ovvero, presi \((n_1, \dots, n_k) \in R, \ \ \chi_R(n_1, \dots, n_k) = 1  \implies \mathcal{N} \models F(\bar{n}_1, \dots, \bar{n}_k, 1) \)

Se invece $(n_1, \dots, n_k) \notin R, \ \ \chi_R(n_1, \dots, n_k) = 0 \implies \mathcal{N} \models F(\bar{n}_1, \dots, \bar{n}_k, 0)  \implies \mathcal{N} \models \neg F(\bar{n}_1, \dots, \bar{n}_k, 1)$

\begin{gframe}{}
L'implicazione finale vale perché:
\begin{itemize}
    \item \(\mathcal{N} \models \neg(0=1)\)

    \item \(\mathcal{N} \models \text{``}F \text{ è funzionale''}\)
    \subitem (dato che \(F\) rappresenta una funzione, non ci possono essere 2 valori diversi per cui sia vera sullo stesso parametro)
\end{itemize}

\end{gframe}
\end{pframe}


\textbf{Osservazione}: notiamo che tutte le funzioni calcolabili hanno una simile struttuta sintattica: sono formate da quantificatori esistenziali seguiti da una formula in cui non compaiono quantificatori o essi appaiono solo "limitati" ( es. \( \forall x (x\leq 7 \to \dots) \)) - queste formule vengono dette \( \sum_1^0 \).

\section{I numeri di Gödel}
{\color{gray} \small Vogliamo mostrare che \( Th(\Nn) \) non è calcolabile mostrando che non è rappresentabile in \( \Nn \).}

Funzioni e relazioni calcolabili hanno come argomenti numeri naturali. Ci serve quindi poter codificare funzioni e relazioni su altri tipi di oggetti.

Gödel inventa una codifica \( code: \{\text{enunciati aritmetici}\} \to \N \) tale che:
\begin{itemize}
    \item ad ogni simbolo di base del linguaggio (parentesi, connettivi, variabili, simboli di funzione/relazione, costanti) viene associato un \textbf{intero positivo dispari}
    \item ogni formula ben formata è una sequenza \( u_0, u_1, \dots, u_n \) di simboli di base, che viene codificata in questo modo:
        \subitem \( code(u_0, u_1, \dots, u_n) = 2^{code(u_0)} \cdot 3^{code(u_1)} \cdot \ldots \cdot p_n^{code(u_n)} \)
    \item ogni derivazione è una sequenza \( e_0, e_1, \dots, e_n \) di formule, che viene codificata in questo modo:
        \subitem \( code(e_0, e_1, \dots, e_n) = 2^{code(e_0)} \cdot 3^{code(e_1)} \cdot \ldots \cdot p_n^{code(e_n)} \)
\end{itemize}

La funzione \( code \) è iniettiva e permette di distinguere algoritmicamente tra codici di simboli di base (pari), ``formule'' (pari con primo esponene dispari) e ``derivazioni'' (pari con primo esponente pari).

Quando si parla dell'esprimibilità di un insieme di enunciati in una teoria, si intende l'esprimibilità dell'insieme dei codici numerici enunciati.

Ci chiediamo quindi se \( \{cod(E) \mid \Nn \vDash E\} \) sia rappresentabile in \( \Nn \) {\color{gray}\small (non lo è)}.

\subsection{Indecidibilità algoritmica dell'aritmetica (Tarski)}

\begin{thmframe}{Teorema di indefinibilità di Tarski}{}
\textit{La verità aritmetica non può essere definita all'interno dell'aritmetica.}

(L'insieme delle verità aritmetiche \( Th(\Nn) = \{E \mid \Nn \vDash E\} \) non è rappresentabile in \( \Nn \).)
\end{thmframe}

Supponiamo per assurdo che \( Th(\Nn) \) sia rappresentabile.
Si tratta di un insieme, quindi è descritto da una formula con una variabile libera.

Sia \( T(x) \) la formula che lo rappresenta.
\begin{itemize}
    \item \( E \in Th(\Nn) \implies \Nn \vDash T(\overline{code(E)})\)
    \item \( E \not\in Th(\Nn) \implies \Nn \vDash \neg T(\overline{code(E)})\)
\end{itemize}

Introduciamo una nuova funzione \( \delta : \N \to \N \).
Dato \( p\in \N \), \( \delta \) controlla se \( p \) è il codice numerico di una formula \( A(x) \) una variabile libera. Se lo è, \( \delta(p) =  \) codice di \( A(x/\bar{p}) \).

{\color{CadetBlue}(dato \( p\), controllo se codifica una FML \( A(x) \) - se sì, scrivo \( A(p) \) (metto il numerale \( p \) al posto della variabile {\small(quindi do alla formula il suo stesso codice)}), codifico la nuova stringa e restituisco il suo codice numerico \( q \))}

\( \delta \) è evidentemente calcolabile (uso la tesi di Church-Turing {\color{gray} - ogni funzione descrivibile tramite un algoritmo è calcolabile da una TM - } per non doverlo dimostrare esplicitamente). In quanto calcolabile, \( \delta\in\Cc \), e quindi \( \delta \) rappresentabile.

Quindi, sia \( D(x, y) \) una formula che rappresenta \( \delta \) in \( \Nn \), ovvero tale che:
\[ \delta(a) = b \iff \Nn \vDash D(\bar{a}, \bar{b})\]

Consideriamo la formula
\[ \forall y (D(x, y)\to \neg T(y)) \]
(che dichiara ``per ogni \( y \) valore di \( \delta(x) \) {\color{gray}\small(quindi formula \( A(y/\bar{x}) \) in cui \( x = code(A)\))}, \( y \) non è un enunciato vero in \( \Nn \))

Questa formula è una formula con una variabile libera \( x \) (chiamiamola \( A(x) \)). (In quanto tale può essere codificata). 

Sia \( p \) il codice di \( A(x) \).

Consideriamo \( A(x/\bar{p}) \), ovvero
\[ \forall y (D(\bar{p}, y)\to \neg T(y)) \]
(che dichiara che ogni \( y \) valore di \( \delta(p)\) non è un enunciato vero in \(\Nn \))

Sia \( q \) il suo codice (quindi \( \delta(p) = q  \)).

Notiamo subito che la formula genera una contraddizione: la formula dichiara che ogni numero che sia \( = \delta(p) \) non è vero in \( \Nn \), ma essa stessa è uno di quei numeri (quindi sta dichiarando di ``mentire'' (di non essere vera)).










\end{document}
