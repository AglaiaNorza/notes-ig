%! TEX program = xelatex
\documentclass[a4paper,11pt]{report}

\usepackage{./../packages/mainstyle}
\usepackage{./../packages/newboxes}
\usepackage{./../packages/titleITA}

\usepackage{float}
\usepackage{enumitem}

\newcommand*\xor{\oplus}

\setcoursename{Logica Matematica}
\setcoursebook{tbd}
\setauthorname{aglaia norza}
\setauthoremail{thisisaglaia@gmail.com}
\setauthorgithub{AglaiaNorza}

\settitlecolor{teal!30}

\begin{document}

\makefrontpage

\tableofcontents

\chapter{Logica Proposizionale}

\section{Introduzione}

La logica proposizionale è un linguaggio formale con una semplice struttura sintattica basata su proposizioni elementari (atomiche) e sui seguenti connettivi logici:


\begin{itemize}
    \item \textit{Negazione} ($\neg$): inverte il valore di verità di un enunciato: se un enunciato è vero, la sua negazione è falsa, e viceversa.

    \item \textit{Congiunzione} ($\land$): il risultato è vero se e solo se entrambi i componenti sono veri.

    \item \textit{Disgiunzione} ($\lor$): il risultato è vero se almeno uno dei componenti è vero.

    \item \textit{Implicazione} ($\to$): rappresenta l’enunciato logico “se ... allora”. Il risultato è falso solo se il primo componente è vero e il secondo è falso. 

    \item \textit{Equivalenza} ($\leftrightarrow$): rappresenta l’enunciato logico “se e solo se”. 
        Il risultato è vero quando entrambi i componenti hanno lo stesso valore di verità, cioè sono entrambi veri o entrambi falsi.
\end{itemize}

Introduciamo anche il concetto di disgiunzione esclusiva o "XOR" (\( \oplus \)), il cui risultato è vero solo se gli operandi sono diversi tra di loro (uno vero e uno falso).

\begin{defbox}{Linguaggio proposizionale}{}
    Un linguaggio proposizionale è un insieme infinito \( \mathcal{L} \) di simboli detti \textbf{variabili proposizionali}, tipicamente denotato come \( \{p_i : i \in I\} \) {\color{gray} (con \( I \) "insieme di indici")}.
\end{defbox}

\begin{defbox}{Proposizione}{}
    Una \textbf{proposizione} in un linguaggio proposizionale è un elemento dell'insieme PROP così definito:
    \begin{enumerate}
        \item tutte le variabili appartengono a PROP
        \item se \( A \in \) PROP, allora \( \neg A \in \) PROP
        \item se \( A, B \in \) PROP, allora \( (A \land B), (A \lor B), (A \to B) \in \) PROP
        \item nient'altro appartiene a PROP {\color{gray}(PROP è il più piccolo insieme che contiene le variabili e soddisfa le proprietà di chiusura sui connettivi 1 e 2)}
    \end{enumerate}
\end{defbox}

Per facilitare la leggibilità delle formule, definiamo le seguenti regole di \textit{precedenza}: \( \neg \) ha precedenza su \( \land, \lor \), e questi ultimi hanno precedenza su \( \to \).

\section{Assegnamenti, tavole di verità}

Per un linguaggio \( \mathcal{L} \), un \textbf{assegnamento} è una funzione 
\[
    \alpha : \mathcal{L} \to \{0, 1\}
\]

Estendiamo \( \alpha \) ad \( \hat{\alpha} : \text{PROP} \to \{0,1\} \) in questo modo:
\vspace{0.5em}
\begin{itemize}
    \item \( \hat{\alpha}(\neg A) = \begin{cases}
            1 &  A = 0 \\
            0 & A = 1
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \land B) = \begin{cases}
            1 & \hat{\alpha}(A) = \hat{\alpha}(B)  = 1 \\
            0 & altrimenti
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \lor B) = \begin{cases}
            0 & \hat{\alpha}(A) = \hat{\alpha}(B)  = 0 \\
            1 & altrimenti
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \to B) = \begin{cases}
            0 & \hat{\alpha}(A) = 1 \land \hat{\alpha}(B)  = 0 \\
            1 & altrimenti
        \end{cases}\)

\end{itemize}

\begin{gbox}{notazione}
    Utilizzeremo \( \alpha \) al posto di \( \hat{\alpha} \) per comodità di notazione.
\end{gbox}

Osserviamo che è possibile rappresentare gli assegnamenti in modo compatto utilizzando le \textbf{tavole di verità}, una presentazione tabulare della funzione di assegnamento.

Per esempio, possiamo riscrivere la definizione di \( \alpha(\neg A) \) come segue:

\[  
    \begin{array}{c | c}
        A & \neg A \\
        \hline
        0 & 1 \\
        1 & 0

    \end{array}
\]

Ogni riga di una tavola di verità corrisponde ad un assegnamento \( \alpha \).

Si noti anche che dalla definizione di \( \alpha \) segue che un'implicazione può essere vera senza che ci sia connessione causale o di significato tra antecedente e conseguente (per esempio, "se tutti i quadrati sono pari allora \( \pi \) è irrazionale"). 

In secondo luogo, segue anche che una proposizione è sempre vera se il suo antecedente è falso (il che rispecchia la pratica matematica di considerare vera a vuoto una proposizione ipotetica la cui premessa non si applica).


{\color{CadetBlue} Questo è giustificabile come segue:
    \begin{itemize}
        \item vogliamo che \( (A \land B) \to B \) sia sempre vera
        \item il caso \( 1 \to 1 \) deve essere vero, perché corrisponde al caso in cui \( A \) e \( B \) sono vere; 

            il caso \( 0 \to 0  \) deve essere vero, perché corrisponde al caso in cui \( A\land B \) è falso perché \( B \) è falso; il caso \( 0 \to 0 \) deve essere vero perché corrisponde al caso in cui \( A \land B \) è falso perché \( B \) è falso; 

            il caso \( 0 \to 1 \) deve essere vero perché corrisponde al caso in cui \( A \land B \) è falso perché \( A \) è falso ma \( B \) è vero; 

            resta dunque soltanto il caso \( 1 \to 0 \), che non corrisponde a nessun caso di \( A \land B \to B \).
    \end{itemize}

In più, si vuole che valga, per contrapposizione \( (A \to B)\to(\neg B \to \neg A) \).}

\label{asseq}
Osserviamo che, data \( A = p_1, p_2, \dots, p_k \) e due assegnamenti \( \alpha \) e \( \beta \) t.c.:
\begin{align*}
    \alpha(p_1) &= \beta(p_1) \\
                &\dots \\
    \alpha(p_k) &= \beta(p_k)
\end{align*}

allora necessariamente \( \alpha(A) = \alpha(B) \). 

\begin{gbox}[colframe=PineGreen]{soddisfacibilità}
    Se per una formula \( A \) e un assegnamento \( \alpha \) si ha \( \alpha (A) = 1 \), si dice che ``\(A \) soddisfa \( \alpha \)'' (o ``\( A \) è vera sotto \( \alpha \)'').
    \begin{itemize}
        \item Se \( A \) ha almeno un assegnamento che la soddisfa, si dice \textbf{soddisfacibile} (\( A \in \texttt{SAT} \)).
        \item Se non esiste un assegnamento che la soddisfa, \( A \) si dice \textbf{insoddisfacibile} (\( A \in \texttt{UNSAT} \)).
        \item Se \( A \) è soddisfatta da tutti i possibili assegnamenti, si dice \textbf{tautologia} (o "verità logica") (\( A \in \texttt{TAUT} \)).
    \end{itemize}
\end{gbox}

Introduciamo anche alcune regole che 

\section{Conseguenza logica}

\begin{defbox}{Conseguenza logica}{}
    Sia \( T \) una \textit{teoria}, ossia un insieme  \( \{A_1, \dots, A_n\} \) proposizioni in un dato linguaggio proposizionale, e sia \( A \in \text{PROP}\) .

    Diciamo che \( A \) è \textbf{conseguenza logica} di \( T\) se 
    \[ \forall \alpha,\ \alpha(T)=1 \to \alpha(A)=1 \] 
    ovvero se ogni assegnamento che soddisfa \(T\) soddisfa anche \( A_{n+1} \).

    Scriviamo in tal caso \(  T \vDash A_{n+1} \), oppure \( A_1, \dots, A_n \vDash A \).
\end{defbox}

Si ha che:
\begin{itemize}
    \item \(T \not\vDash A\) \ significa che \ \( \exists \alpha \) \ t.c. \ \( \alpha(T) = 1 \land \alpha(A) = 0 \)
    \item \( \emptyset \vDash A \) \ o, equivalentemente \ \( \vDash A \iff A\) è una tautologia
\end{itemize}

\begin{lemmabox}{Equivalenze}{}
    \begin{enumerate}
        \item \( T \vDash A \)
        \item \( \vDash (A_1 \land \dots \land A_n) \to A \)
        \item \( (A_1 \land \dots \land A_n) \in \texttt{UNSAT}\) 
    \end{enumerate}

    sono equivalenti.

\end{lemmabox}

\section{Completezza funzionale}
\textit{Data una tavola di verità arbitraria con \( n \) argomenti, esiste una proposizione \( A \) che ha esattamente quella tavola di verità?}

Una proposizione \( A \) contenente le \( n \) variabili proposizionali \( a_1, a_2, \dots, a_n \) determina una funzione di \( n \) argomenti \( f: \{0, 1\}^n \to \{0,1\} \) ("\textbf{funzione di verità}"), tale che il valore di \( f_A \) su un argomento \ \( (x_1, x_2, \dots, x_n) \in \{0,1\}^n\) \ sia dato da un arbitrario assegnamento \( \alpha \) tale che \( \alpha(p_k) = x_k\) \ per \ \(k \in [1,n] \).

\begin{thmbox}{Teorema}{}
    Sia \( f: \{0, 1\}^n \to \{0,1\} \) una funzione di verità. Esiste una proposizione \( A \) con \( n \) variabili proposizionali tale che, per ogni assegnamento \( \alpha \):
    \[ \alpha(A) = f(\alpha(a_1), \alpha(a_2), \dots, \alpha(a_n)) \]
\end{thmbox}

\begin{proofbox}[title=dimostrazione]           
    Si dimostra per induzione su \( n \).

    \begin{itemize}
        \item \textbf{caso base}: \( n=1 \)
            abbiamo quattro possibili \( f \): 
            \[
                \begin{aligned}
                    f_1(0) &= 0, \quad f_1(1) = 0 \\
                    f_2(0) &= 1, \quad f_2(1) = 1 \\
                    f_3(0) &= 0, \quad f_3(1) = 1 \\
                    f_4(0) &= 1, \quad f_4(1) = 0
                \end{aligned}
            \]

            Alla funzione $f_1$ corrisponde la formula $(p \land \neg p)$, alla funzione $f_2$ la formula $(p \lor \neg p)$, 
            alla funzione $f_3$ la formula $p$, e alla funzione $f_4$ la formula $(\neg p)$.
        \item \textbf{caso induttivo}: (assumiamo che il teorema valga per \( n-1 \) variabili, e dimostriamo che vale per \( n \))

            Se $n > 1$, scriviamo il grafico di 
            \[
                f : \{0,1\}^n \to \{0,1\}
            \]

            in forma di tavola di verità in questo modo:

            \[
                \begin{array}{cccc|c|l}
                    p_1 & p_2 & \cdots & p_n & f(p_1, \ldots, p_n) & \\ \hline
                    0 & \cdots & \cdots & 0 & \cdots &  \\
                    \vdots & & & \vdots & \vdots & \text{grafico di una funzione } f_0\\
                    0 & \cdots & \cdots & 1 & \cdots & \\ \hline
                    1 & \cdots & \cdots & 0 & \cdots &  \\
                    \vdots & & & \vdots & \vdots & \text{grafico di una funzione } f_1\\
                    1 & \cdots & \cdots & 1 & \cdots & 
                \end{array}
            \]

            Se non consideriamo la prima colonna (\( p_1 \)), la tavola di verità descrive il grafico di due funzioni, \( f_0 \) e \( f_1 \), a \( n-1 \) argomenti.

            Sappiamo, quindi, per ipotesi induttiva, che esistono due formule \( A_0 \) e \( A_1 \) a \( n-1 \) variabili tali che, per ogni assegnamento \( \alpha \):
            \[ \alpha(A_0) = f_0(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]
            \[ \alpha(A_1) = f_1(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]

            Dobbiamo ora combinare le due formule considerando anche la colonna \( p_1 \).

            Possiamo farlo tramite la formula \(A= (\neg p_1 \to A_0) \land (p_1 \to A_1) \).

            Dimostriamo che \( A \) soddisfa il teorem: dobbiamo dimostrare che, dato un assegnamento qualsiasi \( \alpha \), si ha:
    \[ \alpha(A) = f(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]

    Distinguiamo i due casi:
    \begin{itemize}
        \item \( \alpha(p_1) = 1 \) 

            in questo caso, si ha:
            \[
                \alpha\!\left(
                    \underset{=1}{(\neg p_1 \to A_0)}
                    \land
                \underset{=1}{(p_1} \to A_1)
                \right)
            \]

            e la formula vale quindi \( 1 \iff \alpha(A_1) = 1 \).

            Ma \( \alpha(A_1) = f_1(\alpha(p_2), \dots, \alpha(p_n)) \), quindi la formula si comporta esattamente come \( f_1 \):
            \[
                f(\alpha(p_1), \alpha(p_2), \ldots, \alpha(p_n))
                = f(1, \alpha(p_2), \ldots, \alpha(p_n))
                = f_1(\alpha(p_2), \ldots, \alpha(p_n)).
            \]

            Quindi, in questo caso, vale 
            \[\alpha(A) = (\alpha(p_1), \alpha(p_2), \ldots, \alpha(p_n))\]

        \item \( \alpha(p_1) = 0 \)            

            in questo caso, si ha:
            \[
                \alpha\!\left(
                    \underset{=1}{(\neg p_1} \to A_0)
                    \land
                    \underset{=1}{(p_1 \to A_1})
            \right)\]

            che vale \( 1 \iff \alpha(A_0)=1\).

            Quindi si può fare lo stesso ragionamento di sopra, ma per \( A_1 \) e \( f_0 \).

            \begin{gbox}{}
                Potremmo anche costruire una funzione \( f \) che rappresenta il comportamento di \( A \):

                \[ f(x_1, x_2, \ldots, x_n) =
                    \begin{cases}
                        f_1(x_2, \ldots, x_n) & \text{se } x_1 = 1, \\
                        f_0(x_2, \ldots, x_n) & \text{se } x_1 = 0.
                    \end{cases}
                \]
            \end{gbox}

    \end{itemize}

\end{itemize}

\end{proofbox}

\section{Forme normali}

\begin{gbox}{notazione}
    Chiamiamo "letterale" una variabile proposizionale o una negazione di una variabile proposizionale
\end{gbox}

È utile individuare alcune forme normali canoniche.

\begin{defbox}{Forma Normale Disgiuntiva}{}
    Diciamo che \( A \) è in Forma Normale Disgiuntiva (\textbf{DNF}, \textit{Disjunctive Normal Form}) se \( A \) è una disgiunzione di congiunzioni di letterali, ossia è nella forma seguente:

    \[ \bigvee_{i\leq n} \bigwedge_{j\leq m_i} A_{ij} = (A_{1,1} \land \dots \land A_{1, m_1}) \lor \dots \lor (A_{n,1} \land \dots \land A_{n, m_n}) \]

\end{defbox}

\begin{defbox}{Forma Normale Congiuntiva}{}
    Diciamo che \( A \) è in Forma Normale Congiuntiva (\textbf{CNF}, \textit{Conjunctive Normal Form}) se \( A \) è una disgiunzione di congiunzioni di letterali, ossia è nella forma seguente:

    \[ \bigwedge_{i\leq n} \bigvee_{j\leq m_i} A_{ij} = (A_{1,1} \lor \dots \lor A_{1, m_1}) \land \dots \land (A_{n,1} \lor \dots \lor A_{n, m_n}) \]

\end{defbox}

\section{Equivalenza Logica}

\begin{defbox}[colframe=PineGreen, colback=DeepGreenLight]{Equivalenza logica}{}
    Due formule \( A, B \in \text{PROP} \) sono logicamente equivalenti (\( A \equiv B \)) quando, per ogni assegnamento \( \alpha \) si ha \( \alpha(A) = \alpha(B) \).
\end{defbox}


Introduciamo alcune regole utili per verificare l'equivalenza tra proposizioni.

Con un piccolo abuso di notazione, definiamo \( 1 \) e \( 0 \) come le formule per cui \( \forall \alpha, \ \alpha(1)= 1 \) e \( \alpha(0) = 0 \).

In questo modo, abbiamo:

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Involuzione} & $\neg\neg A \equiv A$ \\
        \hline
        \textbf{Assorbimento (con 0 e 1)} &
        $A \lor 0 \equiv A$ \\
                                          & $A \land 1 \equiv A$ \\
                                          \hline
        \textbf{Cancellazione} &
        $A \lor 1 \equiv 1$ \\
                               & $A \land 0 \equiv 0$ \\
                               \hline
        \textbf{Terzo escluso (\textit{tertium non datur})} &
        $A \lor \neg A \equiv 1$ \\
                                                            & $A \land \neg A \equiv 0$ \\
                                                            \hline
        \textbf{Leggi di De Morgan} &
        $\neg(A \lor B) \equiv \neg A \land \neg B$ \\
                                    & $\neg(A \land B) \equiv \neg A \lor \neg B$ \\
                                    \hline
        \textbf{Commutatività} &
        $A \lor B \equiv B \lor A$ \\
                               & $A \land B \equiv B \land A$ \\
                               \hline
        \textbf{Associatività} &
        $A \lor (B \lor C) \equiv (A \lor B) \lor C$ \\
                               & $A \land (B \land C) \equiv (A \land B) \land C$ \\
                               \hline
        \textbf{Distributività} &
        $A \lor (B \land C) \equiv (A \lor B) \land (A \lor C)$ \\
                                & $A \land (B \lor C) \equiv (A \land B) \lor (A \land C)$ \\
                                \hline
        \textbf{I teorema di assorbimento} &
        $A \lor (A \land B) \equiv A$ \\
                                           & $A \land (A \lor B) \equiv A$ \\
                                           \hline
        \textbf{II teorema di assorbimento} &
        $A \lor (\neg A \land B) \equiv A \lor B$ \\
                                            & $A \land (\neg A \lor B) \equiv A \land B$ \\
                                            \hline

    \end{tabular}
    \caption{Principali leggi di equivalenza logica}
\end{table}

\section{Formalizzazioni in logica proposizionale}

Il concetto di soddisfacibilità ci permette di usare insiemi di formule proposizionali per catturare determinate strutture matematiche.

Per esempio: sia \( X \) un insieme. Consideriamo il linguaggio proposizionale composto dalle variabili \(p_{(x, y)}  \) per ogni \( (x,y) \in X \times X\), e consideriamo il seguente insieme \( T \) di proposizioni in questo linguaggio:

\begin{enumerate}
    \item \( \neg p_{x,x} \ \ \forall x \in X\) \ {\color{gray}(antiriflessività)}
    \item \( p_{x, y} \to \neg p_{y,x} \ \   \forall x \in X\) \ {\color{gray}(asimmetria)}
    \item \( (p_{x, y} \land p_{y, z}) \to p_{x, z} \ \ \forall x, y, z \in X\) \ {\color{gray}(transitività)}
\item \( (p_{x, y} \lor p_{y, x}) \  \ \forall x \neq  y \in X\) \ {\color{gray}(ordine totale)}
\end{enumerate}

Usiamo una teoria \( T \) per poter gestire anche casi di insiemi infiniti. Infatti, sappiamo che una teoria infinita è soddisfatta se e solo se lo sono tutte le sue proposizioni.

L'insieme \( T = T_X \) esprime il concetto di \textbf{ordine totale stretto} su \( X \). Infatti, se avessimo un assegnamento \( \alpha \) che soddisfa tutte le proposizioni di \( T \), l'ordine indotto da tutte le variabili vere sotto \( \alpha \) sarebbe un ordine totale stretto di \( X  \).

Se \( \alpha \) è un assegnamento, definiamo la relazione \( \prec_{\alpha} \) su \( X \) come segue:
\[ x \prec_\alpha y \leftrightarrow \alpha(p_{x,y})=1 \]

Si ha che per ogni assegnamento \( \alpha \) che soddisfca \( T_X \), l'ordine \( \prec_\alpha \) indotto da \( \alpha \) è un ordine totale stretto su \( X \).

Dall'altra parte, se \( \prec \) è un ordine totale stretto su \( X \), e \( \alpha_\prec \) è l'assegnamento indotto da \( \prec \) così definito:
\[ \alpha_\prec (p_{x,y}) = 1 \leftrightarrow (x \prec y) \]

Si ha che, per ogni ordine totale stretto \( \prec \) su \(X \), l'assegnamento \( \alpha_\prec \) indotto da \( \prec \) sulle variabili \( p_{x, y} \) soddisfa \( T \).

Ovvero, un assegnamento \( \alpha \) soddisfa la teoria \( T_X \) se e solo se l'ordine indotto da \( \alpha \) su \( X \) è un ordine totale.

\begin{gbox}{Colorabilità}

\end{gbox}

\section{Teorema di compattezza}

\begin{defbox}{Monotonia della conseguenza logica}{}
    Si dice che la nozione di conseguenza logica è \textbf{monotona}, ovvero che \[T' \vDash A \land T' \subseteq T \implies T \vDash A\]
    (se \( A_1, A_2, \dots, A_k \vDash A \), allora \( T \vDash A \) per ogni teoria \( T \) contenente \( A_1, A_2, \dots, A_k \))
\end{defbox}

Nonostante non sembri intuitivamente vero, vale anche il viceversa:

\begin{thmbox}{Teorema di compattezza v.1}{}
    Se \( T \vDash A \), esiste un sottoinsieme finito \( T_0 \) di \( T \) tale che \( T_0 \vDash A \)
\end{thmbox}

Introduciamo il concetto di una teoria finitamente soddisfacibile:

\begin{defbox}{\texttt{FINSAT}}{}
    Una teoria si dice \textbf{finitamente soddisfacibile} (\( \in \texttt{FINSAT} \)) se \textit{ogni} suo sottoinsieme finito è soddisfacibile.
\end{defbox}

Possiamo quindi introdurre una nuova versione del teorema di compattezza:

\begin{thmbox}{Teorema di compattezza v.2}{}
    \( \texttt{FINSAT}\implies \texttt{SAT} \), ovvero se ogni sottoinsieme di \( T \) è soddisfacibile, anche \( T \) è soddisfacibile.
\end{thmbox}

\begin{lemmabox}{Teorema di compattezza v.1 \( \equiv \) v.2}{}
    I due punti seguenti (le due versioni del teorema di compattezza) sono equivalenti:
    \begin{enumerate}
        \item \( T \vDash A \iff \exists \ T_0 \overset{fin}{\subseteq} T \ t.c. \  T_0 \vDash A\)
        \item \( T \in \texttt{SAT} \iff T \in \texttt{FINSAT} \)
    \end{enumerate}

    \begin{pbox}{}
        \begin{itemize}
            \item \textcircled{1} \( \implies \) \textcircled{2}

                Supponiamo per assurdo che \( T \in \texttt{FINSAT} \implies T \in \texttt{SAT} \), e che \( T \vDash A \) ma che \( \forall T_0 \overset{fin}{\subseteq } T, \ T_0 \not\vDash A \).

                \( T \not\vDash A \) significa \( T \cup \{\neg A\} \in \texttt{SAT} \).
                
                Quindi, visto che \( \texttt{FINSAT} \implies \texttt{SAT} \), \( T \cup \{ \neg A\} \in \texttt{SAT}\), il che va in contraddizione con l'ipotesi \( T \vDash A \).
            \item \textcircled{2} \( \implies \) \textcircled{1}

                Supponiamo per assurdo che \( T\vDash A \implies \exists T_0  \overset{fin}{\subseteq } T \ t.c. \ T_0 \vDash A\), che \( T\in \texttt{FINSAT} \), ma che \( T\not \in \texttt{SAT} \) (\( T\in \texttt{UNSAT} \)).

                Se \( T \in \texttt{UNSAT} \), possiamo dire che \( T \vDash p \land \neg p \) {\small \color{gray} (tutto è conseguenza logica di una teoria insoddisfacibile)}.

                Per \textcircled{2}, quindi, \( \exists T_0 \ t.c, \ T_0 \overset{fin}{\subseteq } T \vDash p \land \neg p \), il che va in contraddizione con \( T \in \texttt{FINSAT} \).\qed
        \end{itemize}

    \end{pbox}

\end{lemmabox}

\begin{thmbox}{Estendibilità di \texttt{SAT}}{}
    Se \( T \) è soddisfacibile, allora \( T \cup \{A\} \) è soddisfacibile oppure \( T \cup \{\neg A\} \) è soddisfacibile.

    \begin{proofbox}[title=dimostrazione dalle dispense]{}
        Sia \( \alpha \) un assegnamento che soddisfa \( T \). Se \( \alpha(A)=1 \) allora \( T \cup \{A\} \) è soddisfacibile. Se \( \alpha(A) = 0 \),  \( T \cup \{\neg A\} \) è soddisfacibile.
    \end{proofbox}
    \begin{proofbox}[title=dimostrazione vista in classe]{}
        Supponiamo \( T \in \texttt{SAT} \), \ \( T \cup \{A\} \in \texttt{UNSAT}\) \ e \ \( T \cup \{\neg A\} \in \texttt{UNSAT}\). Avremmo entrambi \( T \vDash \{\neg A\}\) e \( T \vDash A \), il che è impossibile se \( T\in \texttt{SAT} \).
    \end{proofbox}
\end{thmbox}

Un concetto analogo vale per \texttt{FINSAT}.

\begin{thmbox}{Estendibilità di \texttt{FINSAT}}{}
    Sia \( T \in \texttt{FINSAT} \). Per ogni formula \( A, \  T \cup \{A\} \in \texttt{FINSAT}\)  \ o \( \ T \cup \{\neg A\} \in \texttt{FINSAT}\)
    \begin{pbox}{}
        Supponiamo per assurdo che \( T \cup \{A\} \not\in \texttt{FINSAT}\) e \( T \cup \{\neg A\} \not\in \texttt{FINSAT}\).

        Vuol dire che esistono \( B \ \overset{fin}{\subseteq} T \cup \{A\}\) \ e \ \( C \ \overset{fin}{\subseteq} T \cup \{\neg A\}\) insoddisfacibili.

        Dato che per ipotesi \( T \in \texttt{FINSAT} \), sappiamo che \( A \in B, C \). Possiamo quindi introdurre \( \hat B = B \setminus \{A\}\) e \( \hat C = C \setminus \{A\}\).

        Sappiamo che l'insieme \( \hat B \cup \hat C  \in \texttt{FINSAT}\), in quanto sottoinsieme finito di \( T \).

        Sia \( \alpha \) un assegnamento che lo soddisfa. Se \( \alpha(A)=1 \), allora soddisfa anche \( B \). Se \( \alpha(A) = 0 \), soddisfa anche \( C \). In entrambi i casi abbiamo una contraddizione.

    \end{pbox}

\end{thmbox}

\subsection{Dimostrazione per i linguaggi numerabili}

\begin{gbox}[colframe=DeepGreen, colback=DeepGreenLight]{}
    Sia \( T\) in un linguaggio numerabile. \( T \in \texttt{FINSAT} \implies T\in \texttt{SAT}\).
\end{gbox}

Supponiamo \( \mathcal{L}=\{p_1, p_2, \dots\}\) numerabile. 

Definiamo una ``catena'' di teorie come segue:
\begin{itemize}
    \item \( T_0 = T \)
    \item \( T_1 = \begin{cases}
            T_0 \cup \{p_1\} & T_0 \cup \{p_1\} \in \texttt{FINSAT} \\
            T_0 \cup \{\neg p_1\} & T_0 \cup \{\neg p_1\} \in \texttt{FINSAT}
        \end{cases} \)

        \hspace{1em}\vdots

    \item \( T_{n+1} = \begin{cases}
            T_n \cup \{p_{n+1}\} & T_0 \cup \{p_{n+1}\} \in \texttt{FINSAT} \\
            T_n \cup \{\neg p_{n+1}\} & T_0 \cup \{\neg p_{n+1}\} \in \texttt{FINSAT}
        \end{cases} \)
\end{itemize}

(aggiungiamo quindi proposizioni una alla volta in modo che \( T_i \) resti \texttt{FINSAT})

\begin{gbox}{}
    (la definizione è ben posta per l'estendibilità di \texttt{FINSAT} )
\end{gbox}

Avremo quindi \( {\color{gray} T = }\ T_0 \subseteq T_1 \subseteq T_2 \subseteq \dots \)

Definiamo \[ T^* = \bigcup_{n\in \mathbb{N}} T_n \]

Sappiamo che \( T^* \in \texttt{FINSAT} \) perché \( \forall X = \{A_1, A_2, \dots, A_k\} \overset{fin}{\subseteq} T^*\), esiste \( n^* \) t.c. \( X \subseteq T_{n^*} \).

(\( T \) è costruito come una catena crescente, quindi ogni suo sottoinsieme finito è un sottoinsieme di uno degli insiemi della catena - quello con ``pedice massimo'';
per esempio, se \( X = \{A_1, A_2\} \) con \( A_1 = \{p_1\}, \ A_2 = \{p_3, p_5\}\), avremo \( X \subseteq T_5 \))

Visto che, per costruzione, \( \forall p_n \) vale \( ( p_n \in T^* \oplus \neg p_n \in T^* )\), possiamo definire un assegnamento:
\[ \alpha^*(p_n) = \begin{cases}
    1 & p_n \in T^* \\
    0 & p_n \not\in T^* \\
\end{cases} \]

\begin{gbox}[colframe=DeepTeal, colback=DeepTealLight]{}
    \textbf{Claim}: \( \alpha^*(T) = 1 \)
    
    {\small\color{gray}(avremmo \( T\in \texttt{SAT} \), quindi avremmo finito)}
\end{gbox}

Dobbiamo quindi dimostrare che \( \forall A \in T, \alpha^*(A) = 1 \).

Abbiamo \( A = \{p_{i1}, \dots, p_{i_k} \}\in T\).

Introduciamo la notazione: \( p_n^* = \begin{cases}
    p_n & p_n \in T^* \  \ {\color{gray} (\alpha^*(p_n)=1)} \\
    \neg p_n & \neg p_n \in T^* \  \ {\color{gray} (\alpha^*(p_n)=0)} \\
\end{cases} \)

Poiché \( A\in T \subseteq T^* \) e \( \{p^*_{i1}, \dots, p^*_{ik}\} \), abbiamo \( A^* = A \cup \{p^*_{i1}, \dots, p^*_{ik}\} {\color{gray}= \{A, p^*_{i1}, \dots, p^*_{ik}\}} \overset{fin}{\subseteq } T^*\).

Dato che \( T^* \in \texttt{FINSAT}, \ \exists \beta \) t.c. \( \beta(A^*)=1 \) (il che può succedere solo se \( \beta(A) = 1 \ \land \ \beta(p^*_{ij}) = 1 \ \forall j \in [k] \)).

Ma, poiché \( \beta(p^*_{ij}) = 1 \ \forall j \in [k]  \), notiamo che necessariamente \( \beta(p_j) = 1  \) se \( p_j \in T^* \) e \( \beta(p_j) = 0  \) se \( p_j \neg\in T^* \). Dunque, notiamo che \( \beta \) e \( \alpha^* \) si comportano allo stesso modo per ogni variabile \( p_{i1}, \dots, p_{ik} \).

Da questo (e dall'osservazione a fine pagina \pageref{asseq}), poiché \( p_{i1}, \dots, p_{ik} \) sono le variabili che compongono \( A \), segue che \( \alpha(A) = \alpha(B) \).

Ma \( \beta(A) = 1 \) per scelta di \( \beta \), quindi \( \alpha^*(A) = 1 \). Visto che possiamo applicare lo stesso ragionamento ad ogni \( A \in T \), si ha che \( \alpha^*(T) = 1 \), ovvero \( T \in \texttt{SAT} \) \qed

{\small \color{gray}(ogni proposizione che va verificata, in quanto finita, riguarda solo un sottoinsieme di \(T  \), e crea quindi un ``bottleneck'')}

\subsection{Dimostrazione per i linguaggi arbitrari}

\begin{lemmabox}{Lemma di Zorn}{}
    Sia \( X \) un insieme, e \( \leq \ \subseteq X^2 \) una relazione di \textbf{ordine parziale} (riflessiva, antisimmetrica e transitiva) su \( X \). 
    Definiamo, in \( X \), i concetti di:
    \begin{itemize}
        \item catena \( C \) = sottoinsieme di \( X \) i cui elementi sono a due a due confrontabili via \( \leq  \)
        \item maggiorante = elemento \( x \in X \) t.c. \( \forall y \in C, \ y\leq x \)
    \end{itemize}
    Il \textbf{lemma di Zorn} afferma che, se per ogni catena \( C \) in \( X \) esiste un \textbf{maggiorante} in \( X \), allora esiste un elemento \( m \in X \) \textbf{massimale}.
\end{lemmabox}

Il Lemma di Zorn è una forma dell'Assioma della Scelta (che, informalmente, afferma che quando viene data una collezione di insiemi non vuoti si può sempre costruire un nuovo insieme ``scegliendo'' un singolo elemento da ciascuno di quelli di partenza).

A noi basta considerare come relazione d'ordine l'inclusione insiemistica \( \subseteq \) per la quale l'\textbf{unione è un maggiorante}.

Usiamo il Lemma di Zorn per dimostrare (il verso non banale de) il Teorema di Compattezza.

\begin{lemmabox}{Lemma di Zorn per famiglie di insiemi}{}

Sia $A$ un insieme e $\mathcal{P}(A)$ il suo insieme delle parti. 

Sia $\mathcal{F} \subseteq \mathcal{P}(A)$ una famiglia di sottinsiemi di $A$. 

Se per ogni \textbf{catena} $\mathcal{C}$ in $\mathcal{F}$ (i.e., per ogni famiglia di sottinsiemi di $A$ appartenenti a $\mathcal{F}$ i cui elementi sono due a due confrontabili via $\subseteq$) esiste un \textbf{maggiorante} in $\mathcal{F}$ (ossia un sottinsieme $S$ di $A$ in $\mathcal{F}$ tale che per ogni $S' \in \mathcal{C}$ vale $S' \subseteq S$), allora esiste un sottinsieme \textbf{massimale} $M$ di $A$ in $\mathcal{F}$ (ossia $M \in \mathcal{F}$ tale che per ogni $S \in \mathcal{F}$, se $M \subseteq S$ allora $S = M$).

\begin{gbox}{}
    Si osserva facilmente che se $\mathcal{F}$ contiene l'\textbf{unione} di ogni sua catena allora soddisfa le condizioni di applicabilità del lemma, in quanto l'unione risulta un maggiorante della catena.

\end{gbox}

\end{lemmabox}

Data \( T \in \texttt{FINSAT} \), definiamo \( \mathcal{T} = \{\hat T \mid T \subseteq \hat T \ \land \  \hat T \in \texttt{FINSAT}\} \), la famiglia di teorie \texttt{FINSAT} che estendono \( T \). Sappiamo che \( \mathcal{T}\neq \emptyset \), in quanto contiene almeno \( T \).

Vogliamo verificare che \( \mathcal{T} \) verifichi le condizioni per applicare il lemma di Zorn.

Sia \( C = (T_i) \) una catena crescente. È evidente che \( \bigcup_i T_i\) è un maggiorante, e anche che estende \(T\). Sappiamo anche che è \texttt{FINSAT}. Infatti, se consideriamo un qualsiasi sottoinsieme finito di \( \bigcup_i T_i\), ogni sua proposizione sarà un elemento di qualche elemento della catena; questo significa che l'insieme stesso è un sottoinsieme di un elemento della catena, ed è quindi \texttt{FINSAT}.

Applicando quindi il lemma di Zorn, otteniamo che \( \mathcal{T} \) contiene un massimale \( T^* \), ovvero una teoria tale che:
\begin{itemize}
    \item \( T \subseteq T^* \)
    \item \( T^* \in \texttt{FINSAT}\)
    \item \( T^* \) non può essere propriamente esteso mantenendo la condizione di finita soddisfacibilità - ovvero \( \forall T' \in \mathcal{T}, \ \ T^* \subseteq T' \implies T' = T^* \)
\end{itemize}

In quanto massimale, \( T^* \) gode di alcune proprietà:
\begin{enumerate}
    \item data \( A \), non può essere che \( \neg A \in T^* \) e \( A \in T^* \)
    \item se \( A \not\in T^*\), necessariamente \( \neg A \in T^* \) {\color{gray}(altrimenti \( T^* \) potrebbe essere estesa con \( A \) o \( \neg A \) senza perdere la finita soddisfacibilità)}
    \item se \( A \in T^* \) e \( A \vDash B \), si ha \( B \in T^* \) (\( T^* \) è chiuso per conseguenza logica)
        \subitem {\color{gray}(se \( B\not\in T^* \), si avrebbe \( \neg B \in T^* \), ma dato che \( A \vDash B \), si avrebbe \( \{A, B\}\subseteq T^* \in \texttt{UNSAT} \), quindi \( T^* \not\in \texttt{FINSAT}\))}
\end{enumerate}

Come per la dimostrazione precedente, definiamo un assegnamento
\[ \alpha^*(p_n) = \begin{cases}
    1 & p_n \in T^* \\
    0 & \neg p_n \in T^*
\end{cases}  \]

\textbf{Claim}: \( \alpha^*(T)=1 \)

Dimostrare che \( \alpha^* \) soddisfa \( T^* \) basta a dimostrare che soddisfa anche \( T \). 

Possiamo dimostrare una proprietà più forte: che \( \forall A, \ \alpha(A)=1 \iff A \in T^* \)

Lavoriamo per induzione sulla struttura di \( A \):
\begin{itemize}
    \item \textbf{caso base}: \( A = p_n \) \ \ - \ \ si ha \( \alpha^*(p_n) = 1 \iff p_n \in T^* \)
    \item \textbf{casi induttivi}:
        \begin{enumerate}
            \item \( A = \neg B \)
                \subitem 
            \item \( A = B \land C \)
                \subitem
            \item \( A = B \lor C \)
                \subitem
            \item \( A = B \to C\)
                \subitem TODO
        \end{enumerate}
\end{itemize}
\qed

\section{Applicazioni del teorema di compattezza}






\end{document}

