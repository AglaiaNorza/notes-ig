%! TEX program = xelatex
\documentclass[a4paper,11pt]{report}

\usepackage{./../packages/mainstyle}
\usepackage{./../packages/colors}
\usepackage{./../packages/frameboxes}
\usepackage{./../packages/title}
\usepackage{./../packages/packs}
\usepackage{./../packages/macros}

\usepackage[italian]{babel}

\usepackage[autostyle=false]{csquotes}
\MakeOuterQuote{"}

\usepackage{float}
\usepackage{enumitem}
\usepackage{bussproofs}
\usepackage{mdframed}

\newcommand{\Ra}{R^{\mathcal{A}}}
\newcommand{\fa}{f^{\mathcal{A}}}
\newcommand{\ca}{c^{\mathcal{A}}}

\newcommand{\SAT}{\texttt{SAT}}
\newcommand{\FINSAT}{\texttt{FINSAT}}
\newcommand{\UNSAT}{\texttt{UNSAT}}
\newcommand{\TAUT}{\texttt{TAUT}}

\newcommand{\ass}[2]{%
    \left( \begin{smallmatrix} #1 \\ #2 \end{smallmatrix} \right)
}

% usage: \tworowmatrix{a & b & c}{1 & 2 & 3}
\NewDocumentCommand{\tworowmatrix}{ m m }{
    \begin{bmatrix}
        #1 \\
        #2
    \end{bmatrix}
}

\setcoursename{Logica Matematica}
\setcoursebook{tbd}
\setauthorname{aglaia norza}
\setauthoremail{thisisaglaia@gmail.com}
\setauthorgithub{AglaiaNorza}

\begin{document}

\maketitle

\tableofcontents

\chapter{Logica Proposizionale}

\section{Introduzione}

La logica proposizionale è un linguaggio formale con una semplice struttura sintattica basata su proposizioni elementari (atomiche) e sui seguenti connettivi logici:


\begin{itemize}
    \item \textit{Negazione} ($\neg$): inverte il valore di verità di un enunciato: se un enunciato è vero, la sua negazione è falsa, e viceversa.

    \item \textit{Congiunzione} ($\land$): il risultato è vero se e solo se entrambi i componenti sono veri.

    \item \textit{Disgiunzione} ($\lor$): il risultato è vero se almeno uno dei componenti è vero.

    \item \textit{Implicazione} ($\to$): rappresenta l’enunciato logico “se ... allora”. Il risultato è falso solo se il primo componente è vero e il secondo è falso. 

    \item \textit{Equivalenza} ($\leftrightarrow$): rappresenta l’enunciato logico “se e solo se”. 
        Il risultato è vero quando entrambi i componenti hanno lo stesso valore di verità, cioè sono entrambi veri o entrambi falsi.
\end{itemize}

Introduciamo anche il concetto di disgiunzione esclusiva o "XOR" (\( \oplus \)), il cui risultato è vero solo se gli operandi sono diversi tra di loro (uno vero e uno falso).

\begin{defframe}{Linguaggio proposizionale}{}
    Un linguaggio proposizionale è un insieme infinito \( \mathcal{L} \) di simboli detti \textbf{variabili proposizionali}, tipicamente denotato come \( \{p_i : i \in I\} \) {\color{gray} (con \( I \) "insieme di indici")}.
\end{defframe}

\begin{defframe}{Proposizione}{}
    Una \textbf{proposizione} in un linguaggio proposizionale è un elemento dell'insieme PROP così definito:
    \begin{enumerate}
        \item tutte le variabili appartengono a PROP
        \item se \( A \in \) PROP, allora \( \neg A \in \) PROP
        \item se \( A, B \in \) PROP, allora \( (A \land B), (A \lor B), (A \to B) \in \) PROP
        \item nient'altro appartiene a PROP {\color{gray}(PROP è il più piccolo insieme che contiene le variabili e soddisfa le proprietà di chiusura sui connettivi 1 e 2)}
    \end{enumerate}
\end{defframe}

Per facilitare la leggibilità delle formule, definiamo le seguenti regole di \textit{precedenza}: \( \neg \) ha precedenza su \( \land, \lor \), e questi ultimi hanno precedenza su \( \to \).

\section{Assegnamenti, tavole di verità}

Per un linguaggio \( \mathcal{L} \), un \textbf{assegnamento} è una funzione 
\[
    \alpha : \mathcal{L} \to \{0, 1\}
\]

Estendiamo \( \alpha \) ad \( \hat{\alpha} : \text{PROP} \to \{0,1\} \) in questo modo:
\vspace{0.5em}
\begin{itemize}
    \item \( \hat{\alpha}(\neg A) = \begin{cases}
            1 &  A = 0 \\
            0 & A = 1
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \land B) = \begin{cases}
            1 & \hat{\alpha}(A) = \hat{\alpha}(B)  = 1 \\
            0 & altrimenti
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \lor B) = \begin{cases}
            0 & \hat{\alpha}(A) = \hat{\alpha}(B)  = 0 \\
            1 & altrimenti
        \end{cases}\)

        \vspace{0.5em}

    \item \( \hat{\alpha}(A \to B) = \begin{cases}
            0 & \hat{\alpha}(A) = 1 \land \hat{\alpha}(B)  = 0 \\
            1 & altrimenti
        \end{cases}\)

\end{itemize}

\begin{gframe}{notazione}
    Utilizzeremo \( \alpha \) al posto di \( \hat{\alpha} \) per comodità di notazione.
\end{gframe}

Osserviamo che è possibile rappresentare gli assegnamenti in modo compatto utilizzando le \textbf{tavole di verità}, una presentazione tabulare della funzione di assegnamento.

Per esempio, possiamo riscrivere la definizione di \( \alpha(\neg A) \) come segue:

\[  
    \begin{array}{c | c}
        A & \neg A \\
        \hline
        0 & 1 \\
        1 & 0

    \end{array}
\]

Ogni riga di una tavola di verità corrisponde ad un assegnamento \( \alpha \).

Si noti anche che dalla definizione di \( \alpha \) segue che un'implicazione può essere vera senza che ci sia connessione causale o di significato tra antecedente e conseguente (per esempio, "se tutti i quadrati sono pari allora \( \pi \) è irrazionale"). 

In secondo luogo, segue anche che una proposizione è sempre vera se il suo antecedente è falso (il che rispecchia la pratica matematica di considerare vera a vuoto una proposizione ipotetica la cui premessa non si applica).


{\color{CadetBlue} Questo è giustificabile come segue:
    \begin{itemize}
        \item vogliamo che \( (A \land B) \to B \) sia sempre vera
        \item il caso \( 1 \to 1 \) deve essere vero, perché corrisponde al caso in cui \( A \) e \( B \) sono vere; 

            il caso \( 0 \to 0  \) deve essere vero, perché corrisponde al caso in cui \( A\land B \) è falso perché \( B \) è falso; il caso \( 0 \to 0 \) deve essere vero perché corrisponde al caso in cui \( A \land B \) è falso perché \( B \) è falso; 

            il caso \( 0 \to 1 \) deve essere vero perché corrisponde al caso in cui \( A \land B \) è falso perché \( A \) è falso ma \( B \) è vero; 

            resta dunque soltanto il caso \( 1 \to 0 \), che non corrisponde a nessun caso di \( A \land B \to B \).
    \end{itemize}

In più, si vuole che valga, per contrapposizione \( (A \to B)\to(\neg B \to \neg A) \).}

\label{asseq}
Osserviamo che, data \( A = p_1, p_2, \dots, p_k \) e due assegnamenti \( \alpha \) e \( \beta \) t.c.:
\begin{align*}
    \alpha(p_1) &= \beta(p_1) \\
                &\dots \\
    \alpha(p_k) &= \beta(p_k)
\end{align*}

allora necessariamente \( \alpha(A) = \beta(A) \). 

\begin{gframe}[colframe=PineGreen]{soddisfacibilità}
    Se per una formula \( A \) e un assegnamento \( \alpha \) si ha \( \alpha (A) = 1 \), si dice che ``\(A \) soddisfa \( \alpha \)'' (o ``\( A \) è vera sotto \( \alpha \)'').
    \begin{itemize}
        \item Se \( A \) ha almeno un assegnamento che la soddisfa, si dice \textbf{soddisfacibile} (\( A \in \texttt{SAT} \)).
        \item Se non esiste un assegnamento che la soddisfa, \( A \) si dice \textbf{insoddisfacibile} (\( A \in \texttt{UNSAT} \)).
        \item Se \( A \) è soddisfatta da tutti i possibili assegnamenti, si dice \textbf{tautologia} (o "verità logica") (\( A \in \texttt{TAUT} \)).
    \end{itemize}
\end{gframe}

Introduciamo anche alcune regole che 

\section{Conseguenza logica}

\begin{defframe}{Conseguenza logica}{}
    Sia \( T \) una \textit{teoria}, ossia un insieme  \( \{A_1, \dots, A_n\} \) proposizioni in un dato linguaggio proposizionale, e sia \( A \in \text{PROP}\) .

    Diciamo che \( A \) è \textbf{conseguenza logica} di \( T\) se 
    \[ \forall \alpha,\ \alpha(T)=1 \to \alpha(A)=1 \] 
    ovvero se ogni assegnamento che soddisfa \(T\) soddisfa anche \( A_{n+1} \).

    Scriviamo in tal caso \(  T \vDash A_{n+1} \), oppure \( A_1, \dots, A_n \vDash A \).
\end{defframe}

Si ha che:
\begin{itemize}
    \item \(T \not\vDash A\) \ significa che \ \( \exists \alpha \) \ t.c. \ \( \alpha(T) = 1 \land \alpha(A) = 0 \)
    \item \( \emptyset \vDash A \) \ o, equivalentemente \ \( \vDash A \iff A\) è una tautologia
    \item se \( T \vDash A \), allora \( T \cup \neg A \)è insoddisfacibile
    \item la conseguenza logica ha la proprietà di \textbf{monotonia}: se \( T \vDash A \), allora anche \( T \cup B \vDash A \)
    \item ha anche la proprietà di transitività: se \( T \vDash A \) e \( A \vDash B \) allora \( T\vDash B \)
\end{itemize}

\newpage

\begin{lemmaframe}{Equivalenze}{}
    \begin{enumerate}
        \item \( T \vDash A \)
        \item \( \vDash (A_1 \land \dots \land A_n) \to A \)
        \item \( (A_1 \land \dots \land A_n \land \neg A) \in \texttt{UNSAT}\) 
    \end{enumerate}

    sono equivalenti.

\end{lemmaframe}


\subsection*{Operazioni sulle teorie (utili per esercizi)}

Vediamo come si comportano le teorie in base a operatori noti:

\textbf{Unione di teorie} (\( T \cup S \)):

L'unione rappresenta una sorta di "aggiunta di vincoli": si sta chiedendo che valgano sia le proposizioni di \( T \) che quelle di \( S \).
\begin{itemize}
    \item monotonia - se una formula è conseguenza logica di una teoria, lo è anche dell'unione
        \subitem \( T\vDash A \implies T\cup S \vDash A \)

    \item modus ponens - se una teoria fornisce la premessa ed un'altra l'implicazione, la loro unione deriva la conclusione
        \subitem \( T \vDash A \land S \vDash A \to B \implies S \cup T \vDash B \)

    \item "restringimento" dei modelli - i modelli dell'unione sono l'intersezione dei modelli
        \subitem \( Mod(T \cup S) = Mod(T)\cap Mod(S) \)

    \item "incoerenza" - se sia \( T \) che \( S \) sono coerenti, non è detto che la loro unione lo sia
        \subitem esempio: \( T = \{p\}, \ S = \{\neg p\} \)
\end{itemize}

\textbf{Intersezione di teorie} (\( T \cap S \)):

L'intersezione tra teorie è "debole", in quanto contiene solo le proposizioni che appartengono ad entrambi gli insiemi.

\begin{itemize}
    \item "perdita di informazioni" - l'intersezione tra teorie è sempre un sottoinsieme delle teorie originali (banale)
        \subitem \( T\cap S \subseteq T, S \)
    \item coerenza - se \( T \) è coerente, allora \( T \cap S \) è necessariamente coerente (non stiamo aggiungendo informazioni)
\end{itemize}

\textbf{Esempio}:

\begin{table}[H]
\centering
\begin{tabular}{|l|l|c|l|}
\hline
\textit{premesse} & \textit{derivano dalle premesse?} & \textit{sì/no} & \textit{motivo} \\ \hline
$T \models A$ & $T \cup S \models A$ & V & Monotonia \\ \hline
$T \models A$ & $T \cap S \models A$ & F & Serve che anche $S \models A$ \\ \hline
$T \models A \text{ e } S \models \neg A$ & $T \cup S$ è insoddisfacibile & V & Contraddizione ($A \wedge \neg A$) \\ \hline
$T \models A \text{ e } S \models \neg A$ & $T \cap S \models A \leftrightarrow \neg A$ & F & $T \cap S$ è coerente \\ \hline
$A \text{ sat } \iff B \text{ sat }$ & $T \cap S \models (A \leftrightarrow B)$ & F & Sat $\neq$ Equivalenza \\ \hline
$T, A \lor B \models C \text{ e } S \models B$ & $T \cup S \models A \rightarrow C$ & F & $A$ potrebbe non implicare $C$ \\ \hline
\end{tabular}
\label{tab:teorie}
\end{table}

\section{Completezza funzionale}
\textit{Data una tavola di verità arbitraria con \( n \) argomenti, esiste una proposizione \( A \) che ha esattamente quella tavola di verità?}

Una proposizione \( A \) contenente le \( n \) variabili proposizionali \( a_1, a_2, \dots, a_n \) determina una funzione di \( n \) argomenti \( f: \{0, 1\}^n \to \{0,1\} \) (``\textbf{funzione di verità}''), tale che il valore di \( f_A \) su un argomento \ \( (x_1, x_2, \dots, x_n) \in \{0,1\}^n\) \ sia dato da un arbitrario assegnamento \( \alpha \) tale che \( \alpha(p_k) = x_k\) \ per \ \(k \in [1,n] \).

\begin{thmframe}{Teorema}{}
    Sia \( f: \{0, 1\}^n \to \{0,1\} \) una funzione di verità. Esiste una proposizione \( A \) con \( n \) variabili proposizionali tale che, per ogni assegnamento \( \alpha \):
    \[ \alpha(A) = f(\alpha(a_1), \alpha(a_2), \dots, \alpha(a_n)) \]
    (per qualsiasi funzione di verità, esiste sempre una proposizione che si comporta esattamente come essa {\small\color{gray}(il valore di verità di \( A \), \( \alpha(A) \) è uguale al risultato della funzione \( f \) a parità di input)})
\end{thmframe}

\begin{proofframe}[title=dimostrazione]           
    Si dimostra per induzione su \( n \).

    \begin{itemize}
        \item \textbf{caso base}: \( n=1 \)
            abbiamo quattro possibili \( f \): 
            \[
                \begin{aligned}
                    f_1(0) &= 0, \quad f_1(1) = 0 \\
                    f_2(0) &= 1, \quad f_2(1) = 1 \\
                    f_3(0) &= 0, \quad f_3(1) = 1 \\
                    f_4(0) &= 1, \quad f_4(1) = 0
                \end{aligned}
            \]

            Alla funzione $f_1$ corrisponde la formula $(p \land \neg p)$, alla funzione $f_2$ la formula $(p \lor \neg p)$, 
            alla funzione $f_3$ la formula $p$, e alla funzione $f_4$ la formula $(\neg p)$.
        \item \textbf{caso induttivo}: (assumiamo che il teorema valga per \( n-1 \) variabili, e dimostriamo che vale per \( n \))

            Se $n > 1$, scriviamo il grafico di 
            \[
                f : \{0,1\}^n \to \{0,1\}
            \]

            in forma di tavola di verità in questo modo:

            \[
                \begin{array}{cccc|c|l}
                    p_1 & p_2 & \cdots & p_n & f(p_1, \ldots, p_n) & \\ \hline
                    0 & \cdots & \cdots & 0 & \cdots &  \\
                    \vdots & & & \vdots & \vdots & \text{grafico di una funzione } f_0\\
                    0 & \cdots & \cdots & 1 & \cdots & \\ \hline
                    1 & \cdots & \cdots & 0 & \cdots &  \\
                    \vdots & & & \vdots & \vdots & \text{grafico di una funzione } f_1\\
                    1 & \cdots & \cdots & 1 & \cdots & 
                \end{array}
            \]

            Se non consideriamo la prima colonna (\( p_1 \)), la tavola di verità descrive il grafico di due funzioni, \( f_0 \) e \( f_1 \), a \( n-1 \) argomenti.

            Sappiamo, quindi, per ipotesi induttiva, che esistono due formule \( A_0 \) e \( A_1 \) a \( n-1 \) variabili tali che, per ogni assegnamento \( \alpha \):
            \[ \alpha(A_0) = f_0(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]
            \[ \alpha(A_1) = f_1(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]

            Dobbiamo ora combinare le due formule considerando anche la colonna \( p_1 \).

            Possiamo farlo tramite la formula \(A= (\neg p_1 \to A_0) \land (p_1 \to A_1) \).

            Dimostriamo che \( A \) soddisfa il teorem: dobbiamo dimostrare che, dato un assegnamento qualsiasi \( \alpha \), si ha:
    \[ \alpha(A) = f(\alpha(p_1), \alpha(p_2), \dots, \alpha(p_n)) \]

    Distinguiamo i due casi:
    \begin{itemize}
        \item \( \alpha(p_1) = 1 \) 

            in questo caso, si ha:
            \[
                \alpha\!\left(
                    \underset{=1}{(\neg p_1 \to A_0)}
                    \land
                \underset{=1}{(p_1} \to A_1)
                \right)
            \]

            e la formula vale quindi \( 1 \iff \alpha(A_1) = 1 \).

            Ma \( \alpha(A_1) = f_1(\alpha(p_2), \dots, \alpha(p_n)) \), quindi la formula si comporta esattamente come \( f_1 \):
            \[
                f(\alpha(p_1), \alpha(p_2), \ldots, \alpha(p_n))
                = f(1, \alpha(p_2), \ldots, \alpha(p_n))
                = f_1(\alpha(p_2), \ldots, \alpha(p_n)).
            \]

            Quindi, in questo caso, vale 
            \[\alpha(A) = (\alpha(p_1), \alpha(p_2), \ldots, \alpha(p_n))\]

        \item \( \alpha(p_1) = 0 \)            

            in questo caso, si ha:
            \[
                \alpha\!\left(
                    \underset{=1}{(\neg p_1} \to A_0)
                    \land
                    \underset{=1}{(p_1 \to A_1})
            \right)\]

            che vale \( 1 \iff \alpha(A_0)=1\).

            Quindi si può fare lo stesso ragionamento di sopra, ma per \( A_1 \) e \( f_0 \).

            \begin{gframe}{}
                Potremmo anche costruire una funzione \( f \) che rappresenta il comportamento di \( A \):

                \[ f(x_1, x_2, \ldots, x_n) =
                    \begin{cases}
                        f_1(x_2, \ldots, x_n) & \text{se } x_1 = 1, \\
                        f_0(x_2, \ldots, x_n) & \text{se } x_1 = 0.
                    \end{cases}
                \]
            \end{gframe}

    \end{itemize}

\end{itemize}

\end{proofframe}

\section{Forme normali}

\begin{gframe}{notazione}
    Chiamiamo ``letterale'' una variabile proposizionale o una negazione di una variabile proposizionale
\end{gframe}

È utile individuare alcune forme normali canoniche.

\begin{defframe}{Forma Normale Disgiuntiva}{}
    Diciamo che \( A \) è in Forma Normale Disgiuntiva (\textbf{DNF}, \textit{Disjunctive Normal Form}) se \( A \) è una disgiunzione di congiunzioni di letterali, ossia è nella forma seguente:

    \[ \bigvee_{i\leq n} \bigwedge_{j\leq m_i} A_{ij} = (A_{1,1} \land \dots \land A_{1, m_1}) \lor \dots \lor (A_{n,1} \land \dots \land A_{n, m_n}) \]

\end{defframe}

\begin{defframe}{Forma Normale Congiuntiva}{}
    Diciamo che \( A \) è in Forma Normale Congiuntiva (\textbf{CNF}, \textit{Conjunctive Normal Form}) se \( A \) è una disgiunzione di congiunzioni di letterali, ossia è nella forma seguente:

    \[ \bigwedge_{i\leq n} \bigvee_{j\leq m_i} A_{ij} = (A_{1,1} \lor \dots \lor A_{1, m_1}) \land \dots \land (A_{n,1} \lor \dots \lor A_{n, m_n}) \]

\end{defframe}

\newpage
\section{Equivalenza Logica}

\begin{cdefframe}{DeepGreenLight}{PineGreen}{Equivalenza logica}{}
    Due formule \( A, B \in \text{PROP} \) sono logicamente equivalenti (\( A \equiv B \)) quando, per ogni assegnamento \( \alpha \) si ha \( \alpha(A) = \alpha(B) \).
\end{cdefframe}


Introduciamo alcune regole utili per verificare l'equivalenza tra proposizioni.

Con un piccolo abuso di notazione, definiamo \( 1 \) e \( 0 \) come le formule per cui \( \forall \alpha, \ \alpha(1)= 1 \) e \( \alpha(0) = 0 \).

In questo modo, abbiamo:

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Involuzione} & $\neg\neg A \equiv A$ \\
        \hline
        \textbf{Assorbimento (con 0 e 1)} &
        $A \lor 0 \equiv A$ \\
                                          & $A \land 1 \equiv A$ \\
                                          \hline
        \textbf{Cancellazione} &
        $A \lor 1 \equiv 1$ \\
                               & $A \land 0 \equiv 0$ \\
                               \hline
        \textbf{Terzo escluso (\textit{tertium non datur})} &
        $A \lor \neg A \equiv 1$ \\
                                                            & $A \land \neg A \equiv 0$ \\
                                                            \hline
        \textbf{Leggi di De Morgan} &
        $\neg(A \lor B) \equiv \neg A \land \neg B$ \\
                                    & $\neg(A \land B) \equiv \neg A \lor \neg B$ \\
                                    \hline
        \textbf{Commutatività} &
        $A \lor B \equiv B \lor A$ \\
                               & $A \land B \equiv B \land A$ \\
                               \hline
        \textbf{Associatività} &
        $A \lor (B \lor C) \equiv (A \lor B) \lor C$ \\
                               & $A \land (B \land C) \equiv (A \land B) \land C$ \\
                               \hline
        \textbf{Distributività} &
        $A \lor (B \land C) \equiv (A \lor B) \land (A \lor C)$ \\
                                & $A \land (B \lor C) \equiv (A \land B) \lor (A \land C)$ \\
                                \hline
        \textbf{I teorema di assorbimento} &
        $A \lor (A \land B) \equiv A$ \\
                                           & $A \land (A \lor B) \equiv A$ \\
                                           \hline
        \textbf{II teorema di assorbimento} &
        $A \lor (\neg A \land B) \equiv A \lor B$ \\
                                            & $A \land (\neg A \lor B) \equiv A \land B$ \\
                                            \hline

    \end{tabular}
    \caption{Principali leggi di equivalenza logica}
\end{table}

{\color{gray}Nota Bene: soddisfacibilità ed equivalenza logica non sono interscambiabili - una frase del tipo "Se \( A \) è soddisfacibile se e solo se \( B \) è soddisfacibile, allora \( A \leftrightarrow B \)" non è vera in assoluto (se entrambe possono essere vere non significa che lo siano nello stesso momento)}

\section{Formalizzazioni in logica proposizionale}

Il concetto di soddisfacibilità ci permette di usare insiemi di formule proposizionali per catturare determinate strutture matematiche.

Per esempio: sia \( X \) un insieme. Consideriamo il linguaggio proposizionale composto dalle variabili \(p_{(x, y)}  \) per ogni \( (x,y) \in X \times X\), e consideriamo il seguente insieme \( T \) di proposizioni in questo linguaggio:

\begin{enumerate}
    \item \( \neg p_{x,x} \ \ \forall x \in X\) \ {\color{gray}(antiriflessività)}
    \item \( p_{x, y} \to \neg p_{y,x} \ \   \forall x \in X\) \ {\color{gray}(asimmetria)}
    \item \( (p_{x, y} \land p_{y, z}) \to p_{x, z} \ \ \forall x, y, z \in X\) \ {\color{gray}(transitività)}
\item \( (p_{x, y} \lor p_{y, x}) \  \ \forall x \neq  y \in X\) \ {\color{gray}(ordine totale)}
\end{enumerate}

Usiamo una teoria \( T \) per poter gestire anche casi di insiemi infiniti. Infatti, sappiamo che una teoria infinita è soddisfatta se e solo se lo sono tutte le sue proposizioni.

L'insieme \( T = T_X \) esprime il concetto di \textbf{ordine totale stretto} su \( X \). Infatti, se avessimo un assegnamento \( \alpha \) che soddisfa tutte le proposizioni di \( T \), l'ordine indotto da tutte le variabili vere sotto \( \alpha \) sarebbe un ordine totale stretto di \( X  \).

Se \( \alpha \) è un assegnamento, definiamo la relazione \( \prec_{\alpha} \) su \( X \) come segue:
\[ x \prec_\alpha y \leftrightarrow \alpha(p_{x,y})=1 \]

Si ha che per ogni assegnamento \( \alpha \) che soddisfa \( T_X \), l'ordine \( \prec_\alpha \) indotto da \( \alpha \) è un ordine totale stretto su \( X \).

Dall'altra parte, se \( \prec \) è un ordine totale stretto su \( X \), e \( \alpha_\prec \) è l'assegnamento indotto da \( \prec \) così definito:
\[ \alpha_\prec (p_{x,y}) = 1 \leftrightarrow (x \prec y) \]

Si ha che, per ogni ordine totale stretto \( \prec \) su \(X \), l'assegnamento \( \alpha_\prec \) indotto da \( \prec \) sulle variabili \( p_{x, y} \) soddisfa \( T \).

Ovvero, un assegnamento \( \alpha \) soddisfa la teoria \( T_X \) se e solo se l'ordine indotto da \( \alpha \) su \( X \) è un ordine totale.

\subsection{Esempi di formalizzazioni di problemi noti in Logica Proposizionale}

\begin{gframe}{Colorabilità}
    \vspace{-1.5em}
\subsection*{2-colorabilità}

Consideriamo il problema di colorare una mappa (grafo) con due colori (Rosso e Blu) in modo che nazioni confinanti abbiano colori diversi.

Per esempio:
\begin{itemize}
    \item  mappa \( M \): Italia (\( I \)), Austria (\( A \)), Ungheria (\( U \)).
    \item variabili proposizionali: \( X_C \) indica che la nazione \( X \) ha il colore \( C \). 
\end{itemize}

Per modellare il problema in logica proposizionale, definiamo tre tipi di formule:

\begin{enumerate}
    \item \textit{Ogni nazione ha almeno un colore:}
    \[ (I_R \lor I_B) \land (A_R \lor A_B) \land (U_R \lor U_B) \]
    
    \item \textit{Ogni nazione ha al più un colore (unicità):}
    \[ (I_R \to \neg I_B) \land (A_R \to \neg A_B) \land (U_R \to \neg U_B) \]
    
    \item \textit{Nazioni confinanti hanno colori diversi:}
    \[ (I_R \to \neg A_R) \land (I_B \to \neg A_B) \land   (A_R \to \neg U_R) \land (A_B \to \neg U_B)  \]
\end{enumerate}

Esiste una corrispondenza biunivoca tra una colorazione valida e un assegnamento di verità che soddisfa la teoria:
\begin{itemize}
    \item Una colorazione valida \( f \) induce un assegnamento \( \alpha \) che soddisfa le formule (es. se \( I \) è rossa, \( \alpha(I_R)=1, \alpha(I_B)=0 \)).
    \item Un assegnamento \( \alpha \) che soddisfa le formule permette di ricostruire una colorazione valida.
\end{itemize}

La mappa \( M \) è quindi \textit{2-colorabile} se e soltanto se l'insieme delle proposizioni è soddisfacibile.

La formalizzazione completa non è però la più ``economica''. Il vincolo di unicità del colore (punto 2 sopra) è conseguenza logica degli altri vincoli (punto 1 e punto 3).
\[ \text{Vincolo (1)} \land \text{Vincolo (3)} \models \text{Vincolo (2)} \]
È quindi possibile omettere il secondo gruppo di formule senza alterare la soddisfacibilità.

Considerando Slovenia (\( S \)), Austria (\( A \)) e Ungheria (\( U \)):
\begin{itemize}
    \item Queste tre nazioni sono tutte confinanti tra loro (formano un triangolo nel grafo).
    \item L'insieme delle proposizioni risulta \textit{insoddisfacibile}.
     \subitem Infatti, se \( S \) è Rossa (\( S_R=1 \)), allora i vicini devono essere non-rossi (\( A_R=0, U_R=0 \)). Poiché devono avere un colore, allora devono essere Blu (\( A_B=1, U_B=1 \)). Ma \( A \) e \( U \) confinano, quindi non possono essere entrambi Blu. Contraddizione.
\end{itemize}

\subsection*{Formalizzazione della colorabilità di grafi}

Sia \( G = (V, E) \) un grafo e \( k \) il numero di colori disponibili (\( 1, \dots, k \)).
Definiamo le variabili \( P_{v,i} \) che significano "il vertice \( v \) ha colore \( i \)".

L'insieme \( T \) di formule che formalizza il problema è:

\begin{enumerate}
    \item \textbf{Almeno un colore per ogni vertice:}
    \[ \bigvee_{i=1}^{k} P_{v,i} \quad \text{per ogni } v \in V \]
    
    \item \textbf{Al più un colore per ogni vertice (mutua esclusione):}
    \[ \neg(P_{v,i} \land P_{v,j}) \quad \text{per ogni } v \in V, \text{ con } i \neq j \]
    
    \item \textbf{Vincolo di adiacenza (colori diversi per archi):}
    \[ \neg(P_{v,i} \land P_{w,i}) \quad \text{per ogni arco } \{v, w\} \in E, \text{ per ogni colore } i \]
\end{enumerate}

\textbf{Teorema:} Il grafo \( G \) ammette una \( k \)-colorazione se e solo se l'insieme di formule \( T \) è soddisfacibile. La colorazione è data da \( c(v) = i \iff \alpha(P_{v,i}) = 1 \).

\end{gframe}

\begin{gframe}{Pigeonhole Principle}
Il Principio dei Cassetti (Pigeonhole Principle, \( PHP(m, n) \)) afferma che se inseriamo \( m \) oggetti (piccioni) in \( n \) cassetti, con \( m > n \), allora almeno un cassetto deve contenere più di un oggetto.

Consideriamo il caso con \( m \) piccioni e \( n \) cassetti.
Definiamo le variabili proposizionali:
\[ p_{i,j} \quad \text{con } i \in \{1, \dots, m\} \text{ e } j \in \{1, \dots, n\} \]
Il significato intuitivo di \( p_{i,j} \) è: ``l'oggetto \( i \) è nel cassetto \( j \)''.

Per formalizzare il problema, costruiamo due tipi di proposizioni:

\begin{enumerate}
    \item \textbf{Ogni oggetto è in almeno un cassetto (Totalità)}

        Per un singolo oggetto \( i \), la disgiunzione di tutti i possibili cassetti deve essere vera:
\[ (p_{i,1} \lor p_{i,2} \lor \dots \lor p_{i,n}) \]
Per tutti gli \( m \) oggetti, prendiamo la congiunzione:
\[ A = \bigwedge_{i=1}^{m} \left( \bigvee_{j=1}^{n} p_{i,j} \right) \]


\item \textbf{Ogni cassetto contiene al più un oggetto (Iniettività)}

    Questa condizione esprime che non ci sono collisioni. Se questa condizione è vera, la funzione è iniettiva.
Per ogni cassetto \( k \), e per ogni coppia di oggetti distinti \( i \) e \( j \), non è possibile che entrambi siano in \( k \):
\[ \neg(p_{i,k} \land p_{j,k}) \quad \text{equivalente a} \quad (\neg p_{i,k} \lor \neg p_{j,k}) \]
Formalizziamo l'iniettività su tutto il dominio come la congiunzione di questi vincoli:
\[ B = \bigwedge_{k=1}^{n} \bigwedge_{1 \le i < j \le m} (\neg p_{i,k} \lor \neg p_{j,k}) \]


\item \textbf{Il teorema}

Il principio afferma che se ogni oggetto è assegnato a un cassetto (formula \( A \)), allora l'assegnamento \textit{non} può essere iniettivo (non \( B \)), dato che \( m > n \).
La formula che esprime il \( PHP(m, n) \) è quindi:
\[ A \to \neg B \]
(tautologia)

\end{enumerate}

Spesso, nel contesto SAT, si cerca di dimostrare il principio per assurdo, cercando un assegnamento che renda vera la sua negazione. Cerchiamo cioè una situazione in cui tutti i piccioni sono assegnati (\( A \)) \textbf{e} l'assegnamento è iniettivo (\( B \)):
\[ A \land B \]
In forma estesa:
\[ \left( \bigwedge_{i=1}^{m} \bigvee_{j=1}^{n} p_{i,j} \right) \land \left( \bigwedge_{k=1}^{n} \bigwedge_{i \neq j} (\neg p_{i,k} \lor \neg p_{j,k}) \right) \]
Se \( m > n \), questo insieme di formule è una  insoddisfacibile, poiché non esiste alcun modo di mettere \( m \) piccioni in \( n \) cassetti senza collisioni.
\end{gframe}

\newpage

\section{Teorema di compattezza}

\begin{defframe}{Monotonia della conseguenza logica}{}
    Si dice che la nozione di conseguenza logica è \textbf{monotona}, ovvero che \[T' \vDash A \land T' \subseteq T \implies T \vDash A\]
    (se \( A_1, A_2, \dots, A_k \vDash A \), allora \( T \vDash A \) per ogni teoria \( T \) contenente \( A_1, A_2, \dots, A_k \))
\end{defframe}

Nonostante non sembri intuitivamente vero, vale anche il viceversa:

\begin{thmframe}{Teorema di compattezza v.1}{}
    Se \( T \vDash A \), esiste un sottoinsieme finito \( T_0 \) di \( T \) tale che \( T_0 \vDash A \)
\end{thmframe}

Introduciamo il concetto di una teoria finitamente soddisfacibile:

\begin{defframe}{\texttt{FINSAT}}{}
    Una teoria si dice \textbf{finitamente soddisfacibile} (\( \in \texttt{FINSAT} \)) se \textit{ogni} suo sottoinsieme finito è soddisfacibile.
\end{defframe}

Possiamo quindi introdurre una nuova versione del teorema di compattezza:

\begin{thmframe}{Teorema di compattezza v.2}{}
    \( \texttt{FINSAT}\implies \texttt{SAT} \), ovvero se ogni sottoinsieme di \( T \) è soddisfacibile, anche \( T \) è soddisfacibile.
\end{thmframe}

\begin{lemmaframe}{Teorema di compattezza v.1 \( \equiv \) v.2}{}
    I due punti seguenti (le due versioni del teorema di compattezza) sono equivalenti:
    \begin{enumerate}
        \item \( T \vDash A \iff \exists \ T_0 \overset{fin}{\subseteq} T \ t.c. \  T_0 \vDash A\)
        \item \( T \in \texttt{SAT} \iff T \in \texttt{FINSAT} \)
    \end{enumerate}

\end{lemmaframe}
    \begin{pframe}{}
        \begin{itemize}
            \item \textcircled{1} \( \implies \) \textcircled{2}

                Supponiamo per assurdo che \( T\vDash A \implies \exists T_0  \overset{fin}{\subseteq } T \ t.c. \ T_0 \vDash A\), che \( T\in \texttt{FINSAT} \), ma che \( T\not \in \texttt{SAT} \) (\( T\in \texttt{UNSAT} \)).

                Se \( T \in \texttt{UNSAT} \), possiamo dire che \( T \vDash p \land \neg p \) {\small \color{gray} (tutto è conseguenza logica di una teoria insoddisfacibile)}.

                Per \textcircled{1}, quindi, \( \exists T_0 \ t.c, \ T_0 \overset{fin}{\subseteq } T \vDash p \land \neg p \), il che va in contraddizione con \( T \in \texttt{FINSAT} \).

            \item \textcircled{2} \( \implies \) \textcircled{1}

                Supponiamo per assurdo che \( T \in \texttt{FINSAT} \implies T \in \texttt{SAT} \), e che \( T \vDash A \) ma che \( \forall T_0 \overset{fin}{\subseteq } T, \ T_0 \not\vDash A \).

                \( T_0 \not\vDash A \) significa \( T_0 \cup \{\neg A\} \in \texttt{SAT} \).

                Preso un qualsiasi sottoinsieme finito \( S \subseteq (T \cup \{\neg A\}) \), questo sarà contenuto in un qualche \( T_0 \cup \{\neg A\} \). Dato che ogni \( T_0 \cup \{A\} \in \SAT\), anche \( S \in \SAT \). Dunque, \( T \cup \{\neg A\} \in \FINSAT \).
                
                Quindi, visto che \( \texttt{FINSAT} \implies \texttt{SAT} \), \( T \cup \{ \neg A\} \in \texttt{SAT}\), il che va in contraddizione con l'ipotesi \( T \vDash A \). \qed
        \end{itemize}

    \end{pframe}


\begin{thmframe}{Estendibilità di \texttt{SAT}}{}
    Se \( T \) è soddisfacibile, allora \( T \cup \{A\} \) è soddisfacibile oppure \( T \cup \{\neg A\} \) è soddisfacibile.

    \begin{proofframe}[title=dimostrazione dalle dispense]{}
        Sia \( \alpha \) un assegnamento che soddisfa \( T \). Se \( \alpha(A)=1 \) allora \( T \cup \{A\} \) è soddisfacibile. Se \( \alpha(A) = 0 \),  \( T \cup \{\neg A\} \) è soddisfacibile.
    \end{proofframe}
    \begin{proofframe}[title=dimostrazione vista in classe]{}
        Supponiamo \( T \in \texttt{SAT} \), \ \( T \cup \{A\} \in \texttt{UNSAT}\) \ e \ \( T \cup \{\neg A\} \in \texttt{UNSAT}\). Avremmo entrambi \( T \vDash \{\neg A\}\) e \( T \vDash A \), il che è impossibile se \( T\in \texttt{SAT} \).
    \end{proofframe}
\end{thmframe}

Un concetto analogo vale per \texttt{FINSAT}.

\begin{thmframe}{Estendibilità di \texttt{FINSAT}}{}
    Sia \( T \in \texttt{FINSAT} \). Per ogni formula \( A, \  T \cup \{A\} \in \texttt{FINSAT}\)  \ o \( \ T \cup \{\neg A\} \in \texttt{FINSAT}\)
    \begin{pframe}{}
        Supponiamo per assurdo che \( T \cup \{A\} \not\in \texttt{FINSAT}\) e \( T \cup \{\neg A\} \not\in \texttt{FINSAT}\).

        Vuol dire che esistono \( B \ \overset{fin}{\subseteq} T \cup \{A\}\) \ e \ \( C \ \overset{fin}{\subseteq} T \cup \{\neg A\}\) insoddisfacibili.

        Dato che per ipotesi \( T \in \texttt{FINSAT} \), sappiamo che \( A \in B, \ \neg A \in C \) {\small\color{gray}(altrimenti non potrebbero essere \( \UNSAT \), in quanto sarebbero solo \( \subseteq T \in \FINSAT \))}. Possiamo quindi introdurre \( \hat B = B \setminus \{A\}\) e \( \hat C = C \setminus \{\neg A\}\).

        Sappiamo che l'insieme \( \hat B \cup \hat C  \in \texttt{FINSAT}\), in quanto sottoinsieme finito di \( T \).

        Sia \( \alpha \) un assegnamento che lo soddisfa. Se \( \alpha(A)=1 \), allora soddisfa anche \( B \). Se \( \alpha(A) = 0 \), soddisfa anche \( C \). In entrambi i casi abbiamo una contraddizione.

    \end{pframe}

\end{thmframe}

\subsection{Dimostrazione per i linguaggi numerabili}

\begin{gframe}[colframe=DeepGreen, colback=DeepGreenLight]{}
    Sia \( T\) in un linguaggio numerabile. \( T \in \texttt{FINSAT} \implies T\in \texttt{SAT}\).
\end{gframe}

Supponiamo \( \mathcal{L}=\{p_1, p_2, \dots\}\) numerabile. 

Definiamo una ``catena'' di teorie come segue:
\begin{itemize}
    \item \( T_0 = T \)
    \item \( T_1 = \begin{cases}
            T_0 \cup \{p_1\} & T_0 \cup \{p_1\} \in \texttt{FINSAT} \\
            T_0 \cup \{\neg p_1\} & T_0 \cup \{\neg p_1\} \in \texttt{FINSAT}
        \end{cases} \)

        \hspace{1em}\vdots

    \item \( T_{n+1} = \begin{cases}
            T_n \cup \{p_{n+1}\} & T_0 \cup \{p_{n+1}\} \in \texttt{FINSAT} \\
            T_n \cup \{\neg p_{n+1}\} & T_0 \cup \{\neg p_{n+1}\} \in \texttt{FINSAT}
        \end{cases} \)
\end{itemize}

(aggiungiamo quindi proposizioni una alla volta in modo che \( T_i \) resti \texttt{FINSAT})

\begin{gframe}{}
    (la definizione è ben posta per l'estendibilità di \texttt{FINSAT} )
\end{gframe}

Avremo quindi \( {\color{gray} T = }\ T_0 \subseteq T_1 \subseteq T_2 \subseteq \dots \)

Definiamo \[ T^* = \bigcup_{n\in \mathbb{N}} T_n \]

Sappiamo che \( T^* \in \texttt{FINSAT} \) perché \( \forall X = \{A_1, A_2, \dots, A_k\} \overset{fin}{\subseteq} T^*\), esiste \( n^* \) t.c. \( X \subseteq T_{n^*} \).

(\( T \) è costruito come una catena crescente, quindi ogni suo sottoinsieme finito è un sottoinsieme di uno degli insiemi della catena - quello con ``pedice massimo'';
per esempio, se \( X = \{A_1, A_2\} \) con \( A_1 = \{p_1\}, \ A_2 = \{p_3, p_5\}\), avremo \( X \subseteq T_5 \))

Visto che, per costruzione, \( \forall p_n \) vale \( ( p_n \in T^* \oplus \neg p_n \in T^* )\), possiamo definire un assegnamento:
\[ \alpha^*(p_n) = \begin{cases}
    1 & p_n \in T^* \\
    0 & p_n \not\in T^* \ {\color{gray} (\neg p_n \in T^*)}\\
\end{cases} \]

\begin{gframe}[colframe=DeepTeal, colback=DeepTealLight]{}
    \textbf{Claim}: \( \alpha^*(T) = 1 \)
    
    {\small\color{gray}(avremmo \( T\in \texttt{SAT} \), quindi avremmo finito)}
\end{gframe}

Dobbiamo quindi dimostrare che \( \forall A \in T, \alpha^*(A) = 1 \).

Abbiamo \( A = \{p_{i1}, \dots, p_{i_k} \}\in T\).

Introduciamo la notazione: \( p_n^* = \begin{cases}
    p_n & p_n \in T^* \  \ {\color{gray} (\alpha^*(p_n)=1)} \\
    \neg p_n & \neg p_n \in T^* \  \ {\color{gray} (\alpha^*(p_n)=0)} \\
\end{cases} \)

Poiché \( A\in T \subseteq T^* \) e \( \{p^*_{i1}, \dots, p^*_{ik}\} \subseteq T^*\), abbiamo \( A^* = A \cup \{p^*_{i1}, \dots, p^*_{ik}\} {\color{gray}= \{A, p^*_{i1}, \dots, p^*_{ik}\}} \overset{fin}{\subseteq } T^*\).

Dato che \( T^* \in \texttt{FINSAT}, \ \exists \beta \) t.c. \( \beta(A^*)=1 \) (il che può succedere solo se \( \beta(A) = 1 \ \land \ \beta(p^*_{ij}) = 1 \ \forall j \in [k] \)).

Ma, poiché \( \beta(p^*_{ij}) = 1 \ \forall j \in [k]  \), notiamo che necessariamente \( \beta(p_j) = 1  \) se \( p_j \in T^* \) e \( \beta(p_j) = 0  \) se \( p_j \not\in T^* \). Dunque, notiamo che \( \beta \) e \( \alpha^* \) si comportano allo stesso modo per ogni variabile \( p_{i1}, \dots, p_{ik} \).

Da questo (e dall'osservazione a fine pagina \pageref{asseq}), poiché \( p_{i1}, \dots, p_{ik} \) sono le variabili che compongono \( A \), segue che \( \beta(A) = \alpha^*(A) \).

Ma \( \beta(A) = 1 \) per scelta di \( \beta \), quindi \( \alpha^*(A) = 1 \). Visto che possiamo applicare lo stesso ragionamento ad ogni \( A \in T \), si ha che \( \alpha^*(T) = 1 \), ovvero \( T \in \texttt{SAT} \) \qed

{\small \color{gray}(ogni proposizione che va verificata, in quanto finita, riguarda solo un sottoinsieme di \(T  \), e crea quindi un ``bottleneck'')}

\subsection{Dimostrazione per i linguaggi arbitrari}

\begin{lemmaframe}{Lemma di Zorn}{}
    Sia \( X \) un insieme, e \( \leq \ \subseteq X^2 \) una relazione di \textbf{ordine parziale} (riflessiva, antisimmetrica e transitiva) su \( X \). 
    Definiamo, in \( X \), i concetti di:
    \begin{itemize}
        \item catena \( C \) = sottoinsieme di \( X \) i cui elementi sono a due a due confrontabili via \( \leq  \)
        \item maggiorante = elemento \( x \in X \) t.c. \( \forall y \in C, \ y\leq x \)
    \end{itemize}
    Il \textbf{lemma di Zorn} afferma che, se per ogni catena \( C \) in \( X \) esiste un \textbf{maggiorante} in \( X \), allora esiste un elemento \( m \in X \) \textbf{massimale}.
\end{lemmaframe}

{\color{CadetBlue}Il Lemma di Zorn è una forma dell'Assioma della Scelta (che, informalmente, afferma che quando viene data una collezione di insiemi non vuoti si può sempre costruire un nuovo insieme ``scegliendo'' un singolo elemento da ciascuno di quelli di partenza).}

A noi basta considerare come relazione d'ordine l'inclusione insiemistica \( \subseteq \) per la quale l'\textbf{unione è un maggiorante}.

Usiamo il Lemma di Zorn per dimostrare (il verso non banale de) il Teorema di Compattezza.

\begin{lemmaframe}{Lemma di Zorn per famiglie di insiemi}{}

Sia $A$ un insieme e $\mathcal{P}(A)$ il suo insieme delle parti. 

Sia $\mathcal{F} \subseteq \mathcal{P}(A)$ una famiglia di sottinsiemi di $A$. 

Se per ogni \textbf{catena} $\mathcal{C}$ in $\mathcal{F}$ (i.e., per ogni famiglia di sottinsiemi di $A$ appartenenti a $\mathcal{F}$ i cui elementi sono due a due confrontabili via $\subseteq$) esiste un \textbf{maggiorante} in $\mathcal{F}$ (ossia un sottinsieme $S$ di $A$ in $\mathcal{F}$ tale che per ogni $S' \in \mathcal{C}$ vale $S' \subseteq S$), allora esiste un sottinsieme \textbf{massimale} $M$ di $A$ in $\mathcal{F}$ (ossia $M \in \mathcal{F}$ tale che per ogni $S \in \mathcal{F}$, se $M \subseteq S$ allora $S = M$).

\begin{gframe}{}
    Si osserva facilmente che se $\mathcal{F}$ contiene l'\textbf{unione} di ogni sua catena allora soddisfa le condizioni di applicabilità del lemma, in quanto l'unione risulta un maggiorante della catena.

\end{gframe}

\end{lemmaframe}

Data \( T \in \texttt{FINSAT} \), definiamo \( \mathcal{T} = \{\hat T \mid T \subseteq \hat T \ \land \  \hat T \in \texttt{FINSAT}\} \), la famiglia di teorie \texttt{FINSAT} che estendono \( T \). Sappiamo che \( \mathcal{T}\neq \emptyset \), in quanto contiene almeno \( T \).

Vogliamo verificare che \( \mathcal{T} \) verifichi le condizioni per applicare il lemma di Zorn.

Sia \( C = \{T_i\}_{i\in \N} \subseteq \mathcal{T} \) una catena crescente. È evidente che \( \bigcup_i T_i\) è un maggiorante, e anche che estende \(T\). Sappiamo anche che è \texttt{FINSAT}. Infatti, se consideriamo un qualsiasi sottoinsieme finito di \( \bigcup_i T_i\), ogni sua proposizione sarà un elemento di qualche elemento della catena; questo significa che l'insieme stesso è un sottoinsieme di un elemento della catena, ed è quindi \texttt{FINSAT}.

Applicando quindi il lemma di Zorn, otteniamo che \( \mathcal{T} \) contiene un massimale \( T^* \), ovvero una teoria tale che:
\begin{itemize}
    \item \( T \subseteq T^* \)
    \item \( T^* \in \texttt{FINSAT}\)
    \item \( T^* \) non può essere propriamente esteso mantenendo la condizione di finita soddisfacibilità - ovvero \( \forall T' \in \mathcal{T}, \ \ T^* \subseteq T' \implies T' = T^* \)
\end{itemize}

In quanto massimale, \( T^* \) gode di alcune proprietà:
\begin{enumerate}
    \item data \( A \), non può essere che \( \neg A \in T^* \) e \( A \in T^* \)
    \item se \( A \not\in T^*\), necessariamente \( \neg A \in T^* \) {\color{gray}(altrimenti \( T^* \) potrebbe essere estesa con \( A \) o \( \neg A \) senza perdere la finita soddisfacibilità)}
    \item se \( A \in T^* \) e \( A \vDash B \), si ha \( B \in T^* \) (\( T^* \) è chiuso per conseguenza logica)
        \subitem {\color{gray}(se \( B\not\in T^* \), si avrebbe \( \neg B \in T^* \), ma dato che \( A \vDash B \), si avrebbe \( \{A, B\}\subseteq T^* \in \texttt{UNSAT} \), quindi \( T^* \not\in \texttt{FINSAT}\))}
\end{enumerate}

Come per la dimostrazione precedente, definiamo un assegnamento
\[ \alpha^*(p_n) = \begin{cases}
    1 & p_n \in T^* \\
    0 & \neg p_n \in T^*
\end{cases}  \]

\textbf{Claim}: \( \alpha^*(T)=1 \)

Dimostrare che \( \alpha^* \) soddisfa \( T^* \) basta a dimostrare che soddisfa anche \( T \). 

Possiamo dimostrare una proprietà più forte: che \( \forall A, \ \alpha(A)=1 \iff A \in T^* \)

Lavoriamo per induzione sulla struttura di \( A \):
\begin{itemize}
    \item \textbf{caso base}: \( A = p_n \) \ \ - \ \ si ha \( \alpha^*(p_n) = 1 \iff p_n \in T^* \)
    \item \textbf{casi induttivi}:
        \begin{enumerate}
            \item \textbf{NOT: \( A = \neg B \)}
\[
\alpha^*(\neg B) = 1 \iff \alpha^*(B) = 0
\]

Per l'ipotesi induttiva su \( B \), sappiamo che \( \alpha^*(B) = 0 \iff B \notin T^* \).
Sfruttando la proprietà di massimalità di \( T^* \) {\color{gray}\small(ogni formula o la sua negazione deve appartenere all'insieme)}:


\[
B \notin T^* \iff \neg B \in T^*
\]

Pertanto, \( \alpha^*(\neg B) = 1 \iff \neg B \in T^* \).


                \subitem 
            \item \textbf{AND: } \( A = B \land C \)


\vspace{0.5em}
Dobbiamo mostrare che \( \alpha^*(B \land C) = 1 \iff (B \wedge C) \in T^* \).
\vspace{0.5em}

\subitem \textbf{(\(\Rightarrow\))} \ Sia \( \alpha^*(B \land C) = 1 \).
Per definizione di valutazione, questo implica \( \alpha^*(B) = 1 \) e \( \alpha^*(C) = 1 \).
Per l'ipotesi induttiva, abbiamo \( B \in T^* \) e \( C \in T^* \).
Supponiamo per assurdo che \( (B \land C) \notin T^* \). Per la massimalità, allora \( \neg(B \wedge C) \in T^* \).
Consideriamo l'insieme finito \( \{B, C, \neg(B \land C)\} \subseteq T^* \). Questo insieme è insoddisfacibile (UNSAT), il che contraddice il fatto che \( T^* \) sia FINSAT (finitamente soddisfacibile).
Quindi deve essere \( (B \land C) \in T^* \).

\vspace{0.5em}

\subitem 
\textbf{(\(\Leftarrow\))} Sia \( (B \land C) \in T^* \).
Dobbiamo mostrare che \( B \in T^* \) e \( C \in T^* \).
Se \( B \notin T^* \), allora \( \neg B \in T^* \). L'insieme \( \{B \land C, \neg B\} \subseteq T^* \) sarebbe UNSAT, impossibile. Quindi \( B \in T^* \). Analogamente \( C \in T^* \).
Per ipotesi induttiva, \( \alpha^*(B)=1 \) e \( \alpha^*(C)=1 \), quindi \( \alpha^*(B \land C) = 1 \).

\subitem

            \item \textbf{OR: }\( A = B \lor C \)

\vspace{0.5em}
Dobbiamo mostrare che \( \alpha^*(B \lor C) = 1 \iff (B \vee C) \in T^* \).

\vspace{0.5em}
\subitem \textbf{(\(\Rightarrow\))} Sia \( \alpha^*(B \lor C) = 1 \).
Allora \( \alpha^*(B) = 1 \) oppure \( \alpha^*(C) = 1 \).
Per ipotesi induttiva, \( B \in T^* \) oppure \( C \in T^* \).
Supponiamo WLOG che \( B \in T^* \). L'insieme \( \{B, \neg(B \lor C)\} \) è insoddisfacibile. Poiché \( T^* \) è FINSAT e \( B \in T^* \), non può contenere \( \neg(B \lor C) \). Per massimalità, deve contenere \( (B \vee C) \).

\vspace{0.5em}

\subitem \textbf{(\(\Leftarrow\))} Sia \( (B \lor C) \in T^* \).
Supponiamo per assurdo che \( \alpha^*(B \lor C) = 0 \). Questo implicherebbe \( \alpha^*(B)=0 \) e \( \alpha^*(C)=0 \).
Per ipotesi induttiva, \( B \notin T^* \) e \( C \notin T^* \).
Per massimalità, \( \neg B \in T^* \) e \( \neg C \in T^* \).
Consideriamo l'insieme finito \( \{(B \lor C), \neg B, \neg C\} \subseteq T^* \). Questo insieme è chiaramente insoddisfacibile, contraddicendo la proprietà \FINSAT di \( T^* \).
Quindi l'ipotesi che la valutazione sia 0 è falsa, pertanto \( \alpha^*(B \lor C) = 1 \).

\subitem

            \item \textbf{IMPLICAZIONE: }\( A = B \to C\)

\vspace{0.5em}
Dobbiamo mostrare che \( \alpha^*(B \rightarrow C) = 1 \iff (B \rightarrow C) \in T^* \).

\vspace{0.5em}
\subitem \textbf{(\(\Leftarrow\))} Sia \( (B \rightarrow C) \in T^* \).
Se \( \alpha^*(B \rightarrow C) = 0 \), allora \( \alpha^*(B)=1 \) e \( \alpha^*(C)=0 \).
Per ipotesi induttiva, \( B \in T^* \) e \( C \notin T^* \) (quindi \( \neg C \in T^* \)).
Consideriamo l'insieme finito \( \{(B \rightarrow C), B, \neg C\} \subseteq T^* \). Questo insieme è \UNSAT {\color{CadetBlue}(Modus Ponens contraddetto)}.
Poiché \( T^* \) è \FINSAT, non possiamo avere questa configurazione. Quindi \( \alpha^*(B \rightarrow C) \) deve essere 1.

\vspace{0.5em}

\subitem \textbf{(\(\Rightarrow\))} Sia \( \alpha^*(B \rightarrow C) = 1 \).
Questo accade se \( \alpha^*(B)=0 \) oppure \( \alpha^*(C)=1 \).

\begin{itemize}
    \item Se \( \alpha^*(B)=0 \implies B \notin T^* \implies \neg B \in T^* \). L'insieme \( \{\neg B, \neg(B \rightarrow C)\} \) è  \UNSAT. Quindi \( (B \rightarrow C) \in T^* \).
    \item Se \( \alpha^*(C)=1 \implies C \in T^* \). L'insieme \( \{C, \neg(B \rightarrow C)\} \) è  \UNSAT. Quindi \( (B \rightarrow C) \in T^* \).
\end{itemize}

        \end{enumerate}
\end{itemize}


\subsubsection*{Conclusione}
Abbiamo mostrato che per ogni \( A \), \( \alpha^*(A)=1 \iff A \in T^* \).
Poiché \( T \subseteq T^* \) e per ogni \( A \in T^* \) vale \( \alpha^*(A)=1 \), ne consegue che \( \alpha^* \) soddisfa tutte le formule in \( T \).
Dunque \( T \) è soddisfacibile (\( \SAT \)).



\section{Applicazioni del teorema di compattezza}

\subsection*{Assegnamenti soddisfacibili}
Sia \( T = \{A_1, A_2, \dots\} \) una teoria finita numerabile tale che ogni assegnamento soddisfa qualche proposizione in \( T \). Dimostriamo per compattezza che allora \( \exists k \in \N \) t.c. \( A_1 \lor A_2 \lor \dots \lor A_k \in \TAUT \)

Per assurdo:
\begin{itemize}
    \item supponiamo che ogni assegnamento soddisfi qualche proposizione, ma che nessuna \( A_1 \lor \dots \lor A_k \) sia una tautologia
    \item segue che \( \forall j \in \N \ \exists \alpha \) t.c. \( \alpha(A_0 \lor \dots \lor A_j) = 0 \)
    \item perciò, \( \forall j \) la teoria \( \{\neg A_0, \neg A_1, \dots, \neg A_j\}\) è soddisfacibile, ovvero \( \hat{T} = \{\neg A_0, \neg A_1, \dots\} \in \FINSAT\)
    \item per compattezza, \( \hat{T}\in \SAT \), ovvero \( \exists \alpha \) t.c. \( \alpha(\hat{T})=1 \), il che è in contraddizione con l'ipotesi per cui ogni assegnamento soddisfa qualche proposizione. \qed
\end{itemize}

\subsection*{Colorabilità di grafi (Erdős-De Bruijn)}
Un grafo \( G=(V,E) \) è \( k \)-colorabile se esiste una partizione dei vertici in \( k \) classi (colori) tale che non esistono archi tra vertici della stessa classe. In altre parole, è possibile assegnare a ogni vertice un colore in modo che vertici adiacenti abbiano colori diversi.

\begin{thmframe}{Teorema di Erdős-De Bruijn}{}
Sia \( G \) un grafo infinito. \( G \) è \( k \)-colorabile se e solo se ogni sottografo di \( G \) indotto da un insieme finito di vertici è \( k \)-colorabile.
\end{thmframe}

\textbf{Dimostrazione (per compattezza)}:
Vogliamo dimostrare che se la condizione vale per i sottografi finiti, allora vale per il grafo infinito (l'altra implicazione è banale).

Costruiamo una teoria proposizionale \( T \) che descrive la \( k \)-colorazione.

Associamo a ogni vertice \( v \in V \) e ogni colore \( i \in \{1, \dots, k\} \) una variabile \( P_{v,i} \). La teoria \( T \) è composta da:

\begin{itemize}
    \item \textit{Esistenza del colore}: ogni vertice ha almeno un colore.
    \[ P_{v,1} \lor P_{v,2} \lor \dots \lor P_{v,k} \quad \forall v \in V \]
    \item \textit{Unicità del colore}: un vertice non ha più colori contemporaneamente.
    \[ \neg(P_{v,i} \land P_{v,j}) \quad \forall v \in V, i \neq j \]
    \item \textit{Vincoli di adiacenza}: vertici collegati hanno colori diversi.
    \[ \neg(P_{v,i} \land P_{w,i}) \quad \forall \{v,w\} \in E, \forall i \]
\end{itemize}

Se un assegnamento \( \alpha \) soddisfa \( T \), definisce una colorazione valida ponendo \( c(v)=i \iff \alpha(P_{v,i})=1 \).

Dobbiamo mostrare che \textbf{ogni sottoinsieme finito \( T_0 \subseteq T \) è soddisfacibile}.
\begin{itemize}
    \item sia \( T_0 \) un sottoinsieme finito di \( T \).
    \item sia \( V_0 \) l'insieme dei vertici menzionati nelle formule di \( T_0 \). Poiché \( T_0 \) è finito, \( V_0 \) è finito.
    \item consideriamo il sottografo indotto da \( V_0 \). Per ipotesi del teorema, esso è \( k \)-colorabile tramite una colorazione \( c \).
    \item definiamo l'assegnamento \( \alpha \) basato su \( c \):
    \[ \alpha(P_{v,i}) = 1 \iff v \in V_0 \land c(v) = i \]
    \item poiché \( c \) è una colorazione valida sul sottografo finito, \( \alpha \) soddisfa tutte le formule in \( T_0 \).
\end{itemize}

Poiché \( T \in \FINSAT \), per il Teorema di Compattezza \( T \in \SAT \). Esiste quindi un assegnamento che soddisfa \( T \), il quale induce una \( k \)-colorazione valida per tutto \( G \). \qed

\subsection*{Estensione di ordini parziali}
Ogni ordine parziale può essere esteso a un ordine totale.

\begin{thmframe}{}{}
Per ogni ordine parziale \( (X, <) \) esiste un ordine totale \( (X, \prec) \) che estende \( < \), ovvero tale che:
\[ \text{se } x < y \text{ allora } x \prec y \quad \forall x,y \in X \]
\end{thmframe}

\textbf{Dimostrazione (per compattezza)}:
Assumiamo come vero il teorema per insiemi finiti e usiamo questo fatto per dimostrare il caso infinito.

Il nostro obiettivo è trovare un assegnamento di verità che descriva la relazione d'ordine totale \( \prec \). Introduciamo le variabili proposizionali \( p_{x,y} \) con il significato di "\( x \prec y \)".

La teoria è composta dalle seguenti formule:
\begin{itemize}
    \item Per ogni \( x, y, z \in X \):
        \begin{itemize}
            \item \textit{Irriﬂessività}: \( \neg p_{x,x} \)
            \item \textit{Asimmetria}: \( p_{x,y} \to \neg p_{y,x} \)
            \item \textit{Transitività}: \( (p_{x,y} \land p_{y,z}) \to p_{x,z} \)
            \item \textit{Totalità}: \( p_{x,y} \lor p_{y,x} \) (per \( x \neq y \))
        \end{itemize}
    \item Dobbiamo garantire che il nuovo ordine rispetti quello vecchio. Per ogni coppia \( x, y \in X \) tale che \( x < y \) nell'ordine originale, aggiungiamo la formula:
    \[ p_{x,y} \]
\end{itemize}

Se \( T \) è soddisfacibile, un modello \( \alpha \) definisce l'ordine totale: \( x \prec y \iff \alpha(p_{x,y})=1 \).

Dimostriamo che ogni sottoinsieme finito \( T_0 \subseteq T \) è soddisfacibile.
\begin{itemize}
    \item Sia \( T_0 \subseteq T \) un insieme finito di formule.
    \item Sia \( X_0 \) l'insieme dei vertici \( x,y \in X \) che compaiono come indici nelle variabili \( p_{x,y} \) presenti in \( T_0 \). Poiché \( T_0 \) è finito, anche \( X_0 \) è finito.
    \item Consideriamo la restrizione dell'ordine parziale originale \( < \) all'insieme \( X_0 \). Otteniamo un ordine parziale finito \( (X_0, <|_{X_0}) \).
    \item Poiché \( X_0 \) è finito, sappiamo che esiste un ordine totale \( \prec_0 \) su \( X_0 \) che estende \( <|_{X_0} \).
    \item Usiamo \( \prec_0 \) per definire un assegnamento \( \alpha \) per le variabili in \( T_0 \):
    \[ \alpha(p_{x,y}) = 1 \iff x \prec_0 y \]
    \item Questo assegnamento soddisfa \( T_0 \) perché è un ordine totale, e \( \prec_0 \) è un'estensione dell'ordine originale (se \( x < y \) in \( X_0 \), allora \( x \prec_0 y \), quindi \( \alpha(p_{x,y})=1 \)).
\end{itemize}

Poiché ogni sottoinsieme finito \( T_0 \) è soddisfacibile, per il Teorema di Compattezza l'intera teoria \( T \) è soddisfacibile.
Esiste dunque un modello globale che definisce un ordine totale \( \prec \) su tutto \( X \) che estende l'ordine parziale di partenza \( < \). \qed

\subsection{Lemma di König}

\begin{thmframe}{Lemma di König}{}
Ogni albero binario infinito \( A \) contiene un ramo infinito.
\end{thmframe}

\textbf{Dimostrazione (per compattezza)}:
Vogliamo dimostrare l'esistenza di un ramo infinito costruendo una teoria proposizionale che lo descriva.

Fissiamo il linguaggio contenente una variabile \( p_\sigma \) per ogni stringa \( \sigma \in A \). L'intuizione è che \( p_\sigma \) è vera se il nodo \( \sigma \) fa parte del ramo infinito.
La teoria \( T_A \) è composta da tre tipi di formule:

\begin{itemize}
    \item \textit{Esistenza (il ramo non muore)}: per ogni livello \( n \in \N \), il ramo deve contenere almeno un nodo di quel livello. Se \( \sigma_1, \dots, \sigma_k \) sono tutti i nodi di \( A \) di lunghezza \( n \):
    \[ p_{\sigma_1} \lor p_{\sigma_2} \lor \dots \lor p_{\sigma_k} \]
    (poiché l'albero è binario, ogni livello ha un numero finito di nodi, quindi la disgiunzione è finita).
    
    \item \textit{Unicità (il ramo non si divide)}: per ogni livello \( n \), il ramo contiene al massimo un nodo.
    \[ \neg(p_\sigma \land p_\tau) \quad \text{per ogni coppia } \sigma, \tau \in A \text{ di livello } n \text{ con } \sigma \neq \tau \]
    
    \item \textit{Connessione (chiusura verso l'alto)}: se un nodo fa parte del ramo, anche il suo predecessore deve farne parte.
    \[ p_\sigma \to p_\tau \quad \text{se } \tau \text{ è un segmento iniziale (prefisso) di } \sigma \]
\end{itemize}

Dobbiamo mostrare che ogni sottoinsieme finito \( T_0 \subseteq T_A \) è soddisfacibile.

\begin{itemize}
    \item Sia \( T_0 \) un sottoinsieme finito di \( T_A \).
    \item Consideriamo tutte le variabili \( p_\sigma \) che compaiono in \( T_0 \). Poiché sono in numero finito, esiste una lunghezza massima \( N \) tra le stringhe menzionate.
    \item Poiché l'albero \( A \) è infinito per ipotesi, deve necessariamente contenere nodi di livello \( N \) (altrimenti avrebbe un numero finito totale di nodi).
    \item Scegliamo un nodo \( \bar{\sigma} \in A \) di livello \( N \).
    \item Consideriamo il percorso finito dalla radice fino a \( \bar{\sigma} \). Definiamo l'assegnamento \( \alpha \) tale che:
    \[ \alpha(p_s) = 1 \iff s \text{ è un prefisso di } \bar{\sigma} \]
    \item Questo assegnamento soddisfa \( T_0 \). Infatti:
        \begin{itemize}
            \item Per ogni livello \( n \le N \), c'è esattamente un nodo vero (il prefisso di lunghezza \( n \) di \( \bar{\sigma} \)), soddisfacendo esistenza e unicità.
            \item Le implicazioni di connessione sono soddisfatte perché stiamo prendendo un ramo dell'albero.
        \end{itemize}
\end{itemize}

Poiché \( T_A \in \FINSAT \), allora \( T_A \in \SAT \) per Compattezza.
Sia \( \alpha \) un modello di \( T_A \). L'insieme \( R = \{ \sigma \in A : \alpha(p_\sigma)=1 \} \) definisce un ramo infinito in \( A \), in quanto interseca ogni livello in un unico punto e rispetta l'ordinamento. \qed

\pagebreak

\section{Decidibilità}

Dato il potere espressivo della logica proposizionale, è naturale chiedersi se sia possibile automatizzare la risposta alla domanda ``\( T\overset{?}{\vDash} A \)''. 

Se \( T = \{A_1, \dots, A_n\} \) è una \textbf{teoria finita}, la risposta è banalmente ``sì'', in quanto sappiamo che \( T\vDash A \iff (A_1 \land \dots \land A_n) \to A \in \texttt{TAUT} \) (il che è facilmente verificabile tramite tavole di verità).

\begin{defframe}{Decidibilità}{}
        Dato uno spazio \( X \) di possibili input, chiamiamo un \textit{problema} un qualsiasi sottoinsieme \( S \subseteq X\). 

    Diciamo che \( S \) è \textbf{algoritmicamente decidibile} se esiste un algoritmo tale che \( \forall \ x \in X \), se \( x \in S \), l'algoritmo su input \( x \) termina in tempo finito e risponde ``sì'', e se \( x \not\in S \), l'algoritmo su input \( x \) termina in tempo finito e risponde ``no''.
\end{defframe}

Se invece \( T \) è una teoria \textbf{infinita numerabile}, potremmo usare il \textit{teorema di compattezza} per fare un ragionamento del genere:
\begin{itemize}
    \item Sappiamo che \( T \vDash A \iff \exists \ T_0 \overset{fin}{\subseteq} T  \ \ t.c. \ \ T_0 \vDash A\) 
    \item Indicando con \( Fin(T) \) l'insieme dei sottoinsiemi finiti di \( T \), sappiamo che \( Fin(T) \) è numerabile (in quanto \( T \) lo è). 
    \item Se potessimo quindi produrre algoritmicamente un'enumerazione di \( Fin(T) \) del tipo \( S_1, S_2, S_3, \dots \), poiché, grazie al teorema di compattezza, sappiamo che \( \exists i \in \mathbb{N} \ \ t.c. \ \ S_i \vDash A\), potremmo seguire questa procedura:
        \subitem partendo da \( i = 1 \), ci chiediamo se \( S_i \vDash A \). Poiché \( S_i \) è finito, si può rispondere algoritmicamente. Se la risposta è ``sì'', terminiamo la procedura e rispondiamo ``sì''. Altrimenti, ripetiamo con \( i+1 \).
\end{itemize}

Se l'enumerazione di \( Fin(T) \) si può produrre algoritmicamente, allora tutta la procedura è algoritmica. Notiamo però che, mentre nel caso in cui \( T \vDash A \) sicuramente l'algoritmo terminerà e darà la risposta esatta, nel caso in cui \( T \not\vDash A \), esso non terminerà mai (visto che \( T \) è infinita).

Chiamiamo questo tipo di problema semi-decidibile.

\begin{defframe}{Problema semi-decidibile}{}
    Dato uno spazio ambiente \( X \) e un problema \( S \subseteq X\), diciamo che \( S \) è \textbf{semi-decidibile} se esiste un algoritmo tale che \( \forall \ x \in X \), se \( x\in S \), l'algoritmo (su input \( x \)) termina e risponde ``sì''; se invece \( x \not\in S \), l'algoritmo (su input \( x \)) continua all'infinito (\textit{diverge}).

    \begin{gframe}{}
    (equivalente al concetto di "problema Turing-riconoscibile")
    \end{gframe}
\end{defframe}

\begin{defframe}{Problema computabilmente enumerabile}{}
    Un insieme infinito per cui esiste una procedura algoritmica di enumerazione di tutti e soli i suoi elementi è detto \textbf{computabilmente enumerabile}.
\end{defframe}

(Notiamo che \( \neg(\text{numerabile}\to \text{computabilmente enumerabile}) \))

\begin{thmframe}{}{}
    Se \( T \) è computabilmente enumerabile, allora il problema \( T\vDash A \) è semi-decidibile.
\end{thmframe}

Notiamo quindi che, se lo spazio \( X \) dei possibili input è computabilmente enumerabile, allora:
    \begin{itemize}
        \item ogni problema decidibile è anche semi-decidibile {\small\color{gray}(questo sempre)}
        \item un problema è semi-decidibile se e solo se è computabilmente numerabile
    \end{itemize}


Possiamo stabilire delle proprietà di \( T \) che ci garantiscano la decidibilità?
La risposta è sì.

Consideriamo la procedura introdutta poco fa ed estendiamola in questo modo: 
\begin{itemize}
    \item ad ogni passo, controlliamo non solo \( S_i \vDash A \), ma anche \( S_i \vDash \neg A \)
    \item se \( S_i \vDash A \), terminiamo e rispondiamo ``sì''; se \( S_i \vDash \neg A \), terminiamo e rispondiamo ``no''
\end{itemize}

Escludiamo le teorie per cui si ha \( T\vDash A \land T \vDash \neg A \), in quanto sono ``\textbf{incoerenti}'' (ed insoddisfacibili).

Ci restano quindi tre casi:
\vspace{-0.5em}
\begin{enumerate}
    \item \textbf{Caso 1}: \(T \models A\) e \(T \not\models \neg A\): la procedura applicata a \(A\) termina e risponde affermativamente mentre la procedura applicata a \(\neg A\) diverge. Possiamo concludere che \(T \models A\).

    \item \textbf{Caso 2}: \(T \not\models A\) e \(T \models \neg A\): la procedura applicata a \(A\) diverge e la procedura applicata a \(\neg A\) termina e risponde affermativamente. Possiamo comunque concludere che \(T \models \neg A\). Se \(T\) non è insoddisfacibile, non può essere che \(T \models A\). Dunque possiamo concludere e rispondere che \(T \models A\).

    \item \textbf{Caso 3}: \(T \not\models A\) e \(T \not\models \neg A\): La procedura diverge quando viene applicata sia ad \(A\) che a \(\neg A\). Questo caso esiste, ma vogliamo escluderlo.
\end{enumerate}

\begin{defframe}{Teoria semanticamente completa}{}
    Una teoria \( T \) è detta \textbf{semanticamente completa} se \( \forall \ A \) nel linguaggio di \( T \), vale esattamente una tra \( T \vDash A \) e \( T \vDash \neg A \).
\end{defframe}

Da questo possiamo derivare che:
\begin{thmframe}{}{}
    Se \( T \) è computabilmente enumerabile e semanticamente completa, allora \( T \vDash A ?\) è decidibile algoritmicamente \( \forall \ A \).
\end{thmframe}

\vspace{1em}

\begin{gframe}{}{}
    Notiamo che le proprietà seguenti sono equivalenti:
    \vspace{-1em}
    \begin{enumerate}
        \item \(T\) è semanticamente completa.
        \item Per ogni formula \(A\), vale \(T \models A \iff T \not\models \neg A\).
        \item \(T\) è soddisfacibile e per ogni formula \(A\) se \(T \not\models A\) allora \(T \models \neg A\).
        \item \(T\) ha un unico modello.
        \item Per ogni formula \(A, B\) vale \(T \models A \lor B\) se e solo se \(T \models A\) oppure \(T \models B\).
        \item Per ogni formula \(A, B\) vale \(T \not\models A \to B\) se e solo se \(T \models A\) e \(T \models \neg B\).
    \end{enumerate}
\end{gframe}

\pagebreak

\chapter{Calcolo Proposizionale}

\begin{gframe}{Nota: sintassi (\( \vdash \)) vs semantica (\( \vDash \))}
    È fondamentale distinguere tra due piani che idealmente coincidono, ma sono concettualmente diversi:
    \begin{itemize}
    \item \textit{Semantica} (\( T \vDash A \)): riguarda il significato dei simboli e la loro verità - ci si chiede se una formula sia vera in tutti i ``mondi possibili'' (es. analizzando le tavole di verità)
\item \textit{Sintassi} (\( T \vdash A \)): riguarda la forma e la deduzione - ci si chiede se una formula sia derivabile dagli assiomi rispettando le regole del sistema di prova interessato (non conta il significato dei simboli, ma solo la loro manipolazione meccanica tramite le regole di inferenza)
    \end{itemize}

    L'obiettivo del \textit{Calcolo Proposizionale} è costruire una macchina sintattica formata da assiomi e regole che sia capace di catturare esattamente tutte le verità semantiche (teoremi di correttezza e completezza).
\end{gframe}

Una dimostrazione rigorosa è una successione ordinata e finita di asserzioni, ognuna delle quali può essere giustificata richiamandosi a una verità assunta come ipotesi (assioma), o a una regola di ragionamento corretta che permette di ottenerla da altre proposizioni.

La regola che utilizziamo nel nostro sistema di dimostrazioni (``alla Hilbert'') è il \textbf{Modus Ponens}: da \( X \land (X\to Y) \) segue \( Y \).

Lo scriviamo in questo modo:
    \AxiomC{X}
    \AxiomC{\( X \to Y \)}
    \BinaryInfC{Y}
    \DisplayProof

\begin{defframe}{Dimostrazione}{}
    Una \textbf{dimostrazione} / deduzione è una \textit{successione finita} \( F_1, \dots, F_k \) di proposizioni t.c., \( \forall \ i \in [k] \):
    \begin{itemize}
        \item \( F_i \) è un'istanza di un assioma, oppure
        \item \( F_i \) si ottiene da due formule precedenti tramite regole di inferenza
    \end{itemize}
\end{defframe}

Nel nostro sistema (in cui limitiamo il linguaggio ai connettivi \( \neg \) e \( \to \)), scegliamo come assiomi:

\begin{gframe}{}
    \label{assprop}
    \begin{enumerate}
        \item \( X \to (Y\to X) \)
        \item \( (X \to (Y \to Z)) \to\)
            \subitem \( ( \ (X \to Y) \to (X\to Z)\ )\)
            \subitem {\color{gray}(se \( X \) implica \( Y \to Z \), allora \( X\to Y \) implica \( X\to Z \) (una sorta di transitività))}
        \item \( (\neg Y \to \neg X) \to (X \to Y) \)
    \end{enumerate}
\end{gframe}

Abbiamo scelto questo sistema perché vogliamo la completezza rispetto alla conseguenza logica.
Vogliamo quindi che \( \vDash A \iff A \) è dimostrabile da queste regole di inferenza e ipotesi in \( T \).

\begin{defframe}{Dimostrazione nel calcolo proposizionale}{}
Una \textbf{dimostrazione} / deduzione di \( A \) da \( T \) nel C.P. è una \textit{successione finita} \( F_1, \dots, F_k \) di proposizioni t.c.:
\begin{itemize}
    \item \( F_k = A\)
    \item  \( \forall \ i \in [k] \), si può avere che:
        \begin{itemize}
            \item \( F_i \) è un'istanza di \textbf{assioma}
            \item \( F_i \in T \)
            \item \( \exists \ p, q < i \ \ \ t.c. \ \ \) 
                \AxiomC{\(F_q\)}
                \AxiomC{\(F_p = F_q \to F_i\)}
                \BinaryInfC{\(F_i\)}
                \DisplayProof
                \subitem (è un'istanza del M.P.)
        \end{itemize}
\end{itemize}
\end{defframe}

\begin{defframe}{Teorema}{}
    \( A \) è un teorema se:
    \[ \vdash A \]
    ovvero \( A \) è dimostrabile a partire ``semplicemente'' dagli assiomi.
\end{defframe}

\begin{thmframe}{Teorema di Correttezza}{}
    \textit{Tutti i teoremi sono tautologie.}
    \[ \vdash A \implies \vDash A \]
    Possiamo estendere il teorema facilmente anche a:
    \[ T \vdash A \implies T \vDash A \]
\end{thmframe}

La dimostrazione è semplice: \( \vdash A \) significa che \( A \) è dimostrabile a partire dagli assiomi logici (che sono verità logiche), e il Modus Ponens preserva le verità logiche (e il discorso è facilmente estendibile per \( T \vdash A \implies T \vDash A\)).

    Se scriviamo \( Teor(T) = \{A : T\vdash A\}\), la Correttezza si esprime insiemisticamente in questo modo:
    \[ Teor(T) \subseteq Cons(T) \]
ovvero, il nostro sistema permette di derivare formalmente dalle ipotesi di \( T \) solo \textit{conseguenze logiche} di \( T \).
\newpage
\section{Teorema di completezza}

\begin{thmframe}{Teorema di completezza}{}
    Il teorema di completezza sancisce l'equivalenza tra la nozione semantica di conseguenza logica e quella sintattica di derivabilità formale:
    \[ \vdash A \iff \vDash A \]
    \[ T \vdash A \iff T \vDash A \]
\end{thmframe}

\begin{gframe}{}
    \textbf{idea di dimostrazione} (\( T\vDash A \implies T\vdash A \)):

    Dal teorema di compattezza sappiamo che
    \begin{align*}
        T\vDash A &\iff \exists \{A_1, \dots, A_n\} \subseteq T \ \ t.c. \ \ A_1, \dots, A_n \vDash A \\
                  &\iff \vDash (A_1 \to (A_2 \to \dots (A_n \to A)\dots))
    \end{align*}

    Dimostreremo che tutte le tautologie sono teoremi del calcolo proposizionale, e che quindi 
    \[\exists \{A_1, \dots, A_n\} \subseteq T \ \ t.c. \ \  \vdash (A_1 \to (A_2 \to \dots (A_n \to A)\dots)) \]
    Da questo vogliamo ottenere \( T\vdash A \). 

    Lo faremo verificando che \( \vdash (A_1 \to (A_2 \to \dots (A_n \to A)\dots)) \iff  A_1, \dots, A_n \vdash A \).

\end{gframe}

\subsection{Teorema di Deduzione}

Il passaggio chiave per collegare la soddisfacibilità alla dimostrabilità è il Teorema di Deduzione, che ci permette di spostare le premesse all'interno della formula sotto forma di implicazione.

\begin{thmframe}{Teorema di Deduzione [Herbrand, 1930]}{}
    Sia \( T \) un insieme di formule e \( A, B \) due formule. Allora:
    \[ T, B \vdash A \iff T \vdash (B \to A) \]
\end{thmframe}

\begin{proofframe}[title=dim]
    Dobbiamo dimostrare la doppia implicazione.

    \textbf{Direzione 1:} \( T \vdash (B \to A) \implies T, B \vdash A \) \\
    Questa direzione è immediata.
    \begin{enumerate}
        \item Sia \( (G_1, \dots, G_m) \) una derivazione di \( B \to A \) a partire da \( T \).
        \item Aggiungiamo \( B \) come nuova ipotesi (poiché ora lavoriamo in \( T \cup \{B\} \)).
        \item Avendo \( B \) e \( B \to A \), per Modus Ponens otteniamo \( A \).
        \item Dunque \( T, B \vdash A \).
    \end{enumerate}

    \textbf{Direzione 2:} \( T, B \vdash A \implies T \vdash (B \to A) \) \\
    Sia \( (F_1, \dots, F_n) \) una derivazione di \( A \) (quindi \( F_n = A \)) a partire dalle premesse \( T \cup \{B\} \).
    Dobbiamo dimostrare per induzione sull'indice \( i \) (lunghezza della derivazione) che \( T \vdash (B \to F_i) \) per ogni \( i = 1, \dots, n \).

    \textit{Caso base (\(i=1\)):} \( F_1 \) è l'inizio della derivazione. Ci sono tre casi:
    \begin{itemize}
        \item \textbf{Caso 1:} \( F_1 \) è un assioma logico oppure \( F_1 \in T \). \\
        In questo caso \( T \vdash F_1 \) (senza bisogno di \( B \)).
        Utilizziamo l'assioma logico \( F_1 \to (B \to F_1) \).
        Per Modus Ponens, otteniamo \( T \vdash B \to F_1 \).

        \item \textbf{Caso 2:} \( F_1 \) è la formula \( B \). \\
        Dobbiamo dimostrare \( T \vdash B \to B \).
        Sappiamo che \( \vdash B \to B \) è un teorema logico.
        Quindi a maggior ragione \( T \vdash B \to B \).
    \end{itemize}

    \textit{Passo induttivo (\(i > 1\)):}
    Supponiamo che la tesi valga per tutti i passi \( k < i \). Analizziamo \( F_i \):
    \begin{itemize}
        \item Se \( F_i \) è un assioma, un elemento di \( T \) o \( B \), si procede come nel caso base.
        \item \textbf{Caso 3:} \( F_i \) è ottenuto per \textbf{Modus Ponens}. \\
        Significa che esistono \( m, l < i \) tali che \( F_l \) è la formula \( F_m \to F_i \).
        Per ipotesi induttiva sappiamo che:
        \begin{align*}
            1) \ & T \vdash B \to F_m \\
            2) \ & T \vdash B \to (F_m \to F_i) \quad (\text{poiché } F_l = F_m \to F_i)
        \end{align*}
        Utilizziamo l'Assioma 2 (distributività dell'implicazione):
        \[ (B \to (F_m \to F_i)) \to ((B \to F_m) \to (B \to F_i)) \]
        Applicando il Modus Ponens due volte (usando le ipotesi induttive 1 e 2), concludiamo:
        \[ T \vdash B \to F_i \]
    \end{itemize}
    Poiché \( F_n = A \), l'induzione prova che \( T \vdash B \to A \).
\end{proofframe}




\subsection{Completezza Semplice}

L'obiettivo di questa sezione è dimostrare che le verità logiche (tautologie) sono dimostrabili nel calcolo proposizionale.
\[ \vDash B \implies \vdash B \]

Per farlo, utilizziamo un lemma fondamentale che collega la verità semantica (valutazioni $\alpha$) alla dimostrabilità sintattica.

\begin{lemmaframe}{}{}
    Sia \( B \) una formula contenente le variabili proposizionali \( p_1, \dots, p_k \).
    Sia \( \alpha \) un assegnamento di verità. Definiamo la formula \( B^\alpha \) come:
    \[
    B^\alpha = \begin{cases}
    B & \text{se } \alpha(B) = 1 \\
    \neg B & \text{se } \alpha(B) = 0
    \end{cases}
    \]
    (e analogamente per le variabili \( p_j^\alpha \)).
    Allora vale sempre:
    \[ p_1^\alpha, \dots, p_k^\alpha \vdash B^\alpha \]

\begin{pframe}
    Si procede per \textbf{induzione} sul numero \( n \) di connettivi logici (\(\neg, \to\)) in \( B \).

    \textbf{Base (\(n=0\)):} \( B \) è una variabile atomica \( p_i \).
    La tesi diventa \( p_i \vdash p_i \) (se \(\alpha(p_i)=1\)) oppure \( \neg p_i \vdash \neg p_i \) (se \(\alpha(p_i)=0\)). Entrambe sono banalmente vere.

    \textbf{Passo Induttivo (\(n>0\)):}
    Supponiamo il lemma vero per formule con meno connettivi. Analizziamo la forma di \( B \):

    \begin{itemize}
        \item \textbf{Caso \( B = \neg C \):}
        \begin{itemize}
            \item Se \(\alpha(C)=0\), allora \(\alpha(B)=1\). Per ipotesi induttiva \( \Gamma \vdash C^\alpha \) cioè \( \Gamma \vdash \neg C \). Ma \( B^\alpha \) è \( B \) (cioè \( \neg C \)). Quindi \( \Gamma \vdash B^\alpha \).
            \item Se \(\alpha(C)=1\), allora \(\alpha(B)=0\), quindi \( B^{\alpha} = \neg B \). Per ipotesi induttiva \( \Gamma \vdash C \). Dobbiamo dimostrare \( \Gamma \vdash \neg B \), che corrisponde a \( \neg\neg C \). Usiamo il teorema \( \vdash C \to \neg\neg C \).
        \end{itemize}

        \item \textbf{Caso \( B = C \to D \):}
        Si analizzano i valori di verità di \( C \) e \( D \). Ad esempio, se \(\alpha(C)=1\) e \(\alpha(D)=0\), allora \(\alpha(B)=0\).
        Per ipotesi induttiva abbiamo \( \Gamma \vdash C \) e \( \Gamma \vdash \neg D \).
        Dobbiamo dimostrare \( \Gamma \vdash \neg(C \to D) \). Questo segue dal teorema \( C \to (\neg D \to \neg(C \to D)) \).
    \end{itemize}
\end{pframe}
\end{lemmaframe}


\begin{thmframe}{Teorema di Completezza Semplice}{}
    Se \( B \) è una tautologia, allora \( \vdash B \).

\end{thmframe}
\begin{pframe}
    Sia \( B \) una tautologia con variabili \( p_1, \dots, p_k \).
    Poiché è una tautologia, per \textit{ogni} assegnamento \( \alpha \) vale \( \alpha(B)=1 \), quindi \( B^\alpha = B \).
    Dal Lemma precedente segue che per ogni assegnamento \( \alpha \):
    \[ p_1^\alpha, \dots, p_k^\alpha \vdash B \]

    Consideriamo due assegnamenti \( \alpha \) e \( \beta \) che differiscono solo per il valore di \( p_k \); poiché \( B \) è una tautologia, abbiamo quindi:
    \begin{itemize}
        \item \( \alpha(p_k)=1 \implies p_1^\alpha, \dots, p_{k-1}^\alpha, p_k \vdash B \)
        \item \( \beta(p_k)=0 \implies p_1^\alpha, \dots, p_{k-1}^\alpha, \neg p_k \vdash B \)
    \end{itemize}
    Applicando il Teorema di Deduzione a entrambi:
    \[ \Gamma \vdash p_k \to B \quad \text{e} \quad \Gamma \vdash \neg p_k \to B \]
    (dove \( \Gamma = \{p_1^\alpha, \dots, p_{k-1}^\alpha\} \)).

    Utilizzando il teorema noto \( (A \to B) \to ((\neg A \to B) \to B) \), otteniamo:
    \[ p_1^\alpha, \dots, p_{k-1}^\alpha \vdash B \]
    Abbiamo eliminato la dipendenza da \( p_k \). Iterando il procedimento per \( k-1, k-2, \dots, 1 \), eliminiamo tutte le premesse e otteniamo infine:
    \[ \vdash B \]
\end{pframe}

\subsection{Conclusione del Teorema di Completezza}

Grazie al Teorema di Deduzione, possiamo ora completare la strategia descritta all'inizio:

\begin{enumerate}
    \item Dal \textbf{Teorema di Compattezza}: \( T \vDash A \implies \exists \{A_1, \dots, A_n\} \subseteq T \) tale che \( A_1, \dots, A_n \vDash A \).
    \item Questo equivale a dire \( \vDash (A_1 \to (\dots \to A)\dots) \) (ovvero \(  (A_1 \to (\dots \to A)\dots) \) è una tautologia).
    \item Per la \textbf{Completezza Semplice} (le tautologie sono teoremi), abbiamo:
    \[ \vdash (A_1 \to (A_2 \to \dots (A_n \to A)\dots)) \]
    \item Applicando \( n \) volte il \textbf{Teorema di Deduzione} (nella direzione \( \Longleftarrow \)), ``scarichiamo'' le premesse una alla volta:
    \[ A_1, A_2, \dots, A_n \vdash A \]
\item Poiché \( \{A_1, \dots, A_n\} \subseteq T \), per la proprietà di \textbf{monotonia} concludiamo:
    \[ T \vdash A \]
\end{enumerate}





\chapter{Logica Predicativa}

\section{Introduzione}

Abbiamo visto come la logica proposizionale ci permette di modellare alcuni tipi di problemi facilmente. Tuttavia, per altri tipi di problemi è necessario un maggiore potere espressivo.

\begin{defframe}{Struttura relazionale}{}
Una struttura relazionale è una tupla \( \mathcal{A} = (A, \ R_1, \dots, R_n, \ f_1, \dots, f_n, \ c_1, \dots, c_n) \), dove:
\begin{itemize}
    \item \( A \) rappresenta un insieme di elementi (tipicamente non vuoto) (\textit{dominio})
    \item \(R_1, \dots, R_n \) sono \textit{relazioni} su \( A \) (anche unarie), ossia suoi sottoinsiemi 
    \item \( f_1, \dots, f_n \) sono \textit{funzioni} su \( A \)
    \item \( c_1, \dots, c_k \) sono \textit{costanti} su \( A \)
\end{itemize}
\end{defframe}

\textbf{Esempio}:
un esempio di struttura è quella di gruppo.

Un gruppo è definito da un insieme $A$ (di elementi del gruppo), un elemento $e \in A$ (l'elemento neutro) e un'operazione binaria $\circ : A \times A \to A$, che soddisfa le seguenti proprietà:
\begin{enumerate}
    \item Per ogni $a \in A$, $a \circ e = e \circ a = a$
    \item Per ogni $a \in A$ esiste un $b \in A$ tale che $a \circ b = b \circ a = e$
    \item Per ogni $a, b, c \in A$: $a \circ (b \circ c) = (a \circ b) \circ c$.
\end{enumerate}
{\small (Un gruppo è inoltre abeliano se soddisfa: per ogni $a, b \in A$ si ha $a \circ b = b \circ a$.)}

\begin{defframe}{Linguaggio predicativo}{}
    Un \textbf{linguagggio predicativo} \( \mathcal{L} \) è una collezione (finita o infinita) di simboli di tre tipi:
    \begin{itemize}
        \item simboli di \textit{relazioni}, con la loro arietà
        \item simboli di \textit{funzioni}, con la loro arietà
        \item simboli di \textit{costanti} (di arietà 0)
    \end{itemize}
    
    Inoltre, assumiamo sempre un insieme numerabile di \textit{variabili} \( v_1, v_2, \dots \)
\end{defframe}

\textbf{Esempio}: per continuare con l'esempio di sopra, un linguaggio adeguato per la teoria dei ruppi è \( \mathcal{L}_G = \{\cdot, e\} \), dove \( \cdot \) è un simbolo di funzione binaria per l'operazione di gruppo, e \( e \) è una costante per l'elemento neutro.

\begin{gframe}{Nota bene}
  Nella logica dei predicati, si può quantificare solo sugli \textit{elementi} delle strutture e non sulle strutture stesse (si chiama, per questo, Logica di Primo Ordine o FOL, First-Order Logic). 

  Per quantificare sulle strutture, esiste la Logica di Secondo Ordine (non trattata in questo corso).
\end{gframe}


\begin{defframe}{Termini}{}
    I \textbf{termini} sono ottenuti partendo dalle variabili e dalle costanti e chiudendo sotto applicazione dei simboli di funzione.

    Un termine che non contiene variabili è un \textbf{termine chiuso}.
\end{defframe}

Per formulare proposizioni nel linguaggio \( \mathcal{L} \), si usano i seguenti simboli logici:
\begin{itemize}
    \item \textbf{connettivi}: \( \land, \lor, \to, \neg \)
    \item \textbf{quantificatori}:  \( \exists, \forall \)
    \item il simbolo di \textbf{eguaglianza}:  \( = \)
\end{itemize}

\vspace{1em}

\begin{defframe}{Formule}{}
    
Una \textbf{formula atomica} è una stringa del tipo \( R(t_1, \dots, t_k) \), dove \( R \) è un simbolo di relazione di arità \( k \) e \( t_1, \dots, t_k \) sono termini, oppure una stringa del tipo \( t = s \), dove \( t \) e \( s \) sono termini.

Le \textbf{formule} sono ottenute partendo dalle formule atomiche e chiudendo sotto connettivi proposizionali e quantificatori universali ed esistenziali. 
\end{defframe}

Nelle formule \( (\forall v)F \) e \((\exists v)F\), \( F \) è detto il \textbf{dominio} (o \textit{scope}) del quantificatore e \( v \) la variabile quantificata. Se \( v \) non occorre in \( F \), possiamo identificare le due formule quantificate con \( F \). 

Un'occorrenza di una variabile \( x \) in una formula \( F \) è \textbf{vincolata} se e solo se:
\begin{itemize}
    \item l'occorrenza di \( x \) è la variabile quantificata di un quantificatore, oppure
    \item l'occorrenza di \( x \) è nel dominio di un quantificatore con variabile quantificata
\end{itemize}

Tutte le altre occorrenze di \( x \) sono dette \textbf{libere}.

\begin{defframe}{Enunciato}{}
Un \textbf{enunciato} è una formula senza variabili libere.
\end{defframe}

Se \( F \) è una formula e \( x_1, \dots, x_n \) sono variabili distinte, indichiamo con \( F(x_1, \dots, x_n) \) il fatto che le variabili libere di \( F \) sono contenute nell'insieme \( \{x_1, \dots, x_n\} \).

\begin{defframe}{Termine libero}{}
    \label{terlib}
    Un termine \( t \) è \textbf{libero per una variabile} \( v \) in una formula \( F \) se nessuna occorrenza libera di \( v \) in \( F \) è nel dominio di un quantificatore \( \forall y \) o \( \exists y \) con \( y \) una variabile in \( t\).

    (ovvero, se si sostituisce \( v \) con \( t \) nella formula, nessuna delle variabili di \( t \) viene legata da un quantificatore presente in \( F \))
\end{defframe}

Per esempio, se \( F \) è \( \exists y (x = y + y) \), nessun termine contenente \( y \) è libero per \( x \) in \( F \).


\section{Semantica}
Vogliamo poter definire il concetto di \textbf{verità logica} nella logica dei predicati (analogo a quello di tautologia nella logica proposizionale). A tale scopo, ci serve definire la nozione di verità di una formula della logica predicativa.

La verità di una formula della logica predicativa dipende dalla scelta dell'ambiente in cui decidiamo di interpretare i simboli del linguaggio. Un tale ambiente è detto \textbf{struttura}.

\begin{defframe}{Struttura per un linguaggio \( \Ll \)}{}
    Dato un linguaggio \( \Ll\), una \textbf{struttura} (o interpretazione) \(\mathcal{A}\) per il linguaggio \( \Ll \) consiste di:
    \begin{itemize}
        \item un insieme \( A \) non vuoto, detto \textbf{dominio}
        \item per ogni simbolo \( R_i \) di arietà \( d \), una relazione di arietà \( d \) sul dominio \( A \), che denotiamo con \(\Ra_i \) dove \( \Ra_i \subseteq A^d \)
        \item per ogni simbolo \( f_j \) di arietà \( d \), una funzione a \( d \) argomenti sul dominio \( A \), che denotiamo con \(\fa_i \) dove \( \fa_j : A^d \to A \)
        \item per ogni \( k \in K \), un elemento di \( A \) che denotiamo con \( \ca_k\)
    \end{itemize}
    
\end{defframe}

Un \textbf{assegnamento} \( \alpha \) in \( \Aa \) è una mappa che associa ad ogni variabile un elemento di \( A \), i.e.:
\[ \alpha : \{v_n : n \in \N \} \to A\]

Un assegnamento si estende in modo univoco ai termini ponendo:
\begin{itemize}
    \item \( \alpha(c) = c^{\Aa} \) 
    \item \( \alpha(f(t_1, \dots, t_k)) = f^{\Aa}(\alpha(t_1), \dots, \alpha(t_k))\).
\end{itemize}

\begin{gframe}{}
    Indichiamo con \( \alpha\ass{x}{a} \) l'assegnamento che differisce da \( \alpha \) solo perché associa l'elemento \( a \) alla variabile \( x \).
\end{gframe}

\begin{defframe}{Soddisfazione}{}
    Definiamo la relazione \( \Aa \vDash F[\alpha] \), che significa ``la formula \( F \) è soddisfatta nella struttura \( \Aa \) relativamente all'assegnamento \( \alpha \)''

    La definiamo per induzione sulla complessità di \( F \) (semantica Tarskyana):

    \begin{itemize}
    \item $\Aa \vDash R(t_1, \dots, t_k)[\alpha]$ se e solo se $(\alpha(t_1), \dots, \alpha(t_k)) \in R^{\Aa}$, dove $t_1, \dots, t_k$ sono termini e $R$ è un simbolo di relazione di varietà $k$.
    \item $\Aa \vDash (t = s)[\alpha]$ se e solo se $\alpha(t) = \alpha(s)$, dove $t$ e $s$ sono termini.
    \item $\Aa \vDash \neg G[\alpha]$ se e solo se non vale $\Aa \vDash G[\alpha]$ {\color{gray}\small(\( \Aa \vDash \neg G[\alpha] \iff \Aa \not\vDash G[\alpha]\))}.
    \item $\Aa \vDash (G \land H)[\alpha]$ se e solo se $\Aa \vDash G[\alpha]$ e $\Aa \vDash H[\alpha]$.
    \item $\Aa \vDash (G \lor H)[\alpha]$ se e solo se $\Aa \vDash G[\alpha]$ o $\Aa \vDash H[\alpha]$.
    \item $\Aa \vDash (G \to H)[\alpha]$ se e solo se: se $\Aa \vDash G[\alpha]$ allora $\Aa \vDash H[\alpha]$.
    \item $\Aa \vDash (\exists x G)[\alpha]$ se e solo se esiste $a \in \Aa$ tale che $\Aa \vDash G[\alpha(x/a)]$.
    \item $\Aa \vDash (\forall x G)[\alpha]$ se e solo se per ogni $a \in \Aa$ vale $\Aa \vDash G[\alpha(x/a)]$.
\end{itemize}

\begin{gframe}{}
    Notiamo quindi che una struttura decide univocamente lo stato di verità di qualsiasi formula del suo linguaggio.

    Ovvero \( Th(\Aa) \), l'insieme di tutte le frasi vere in una specifica struttura \(\Aa\), è una teoria completa (e, chiaramente, una struttura non può essere contraddittoria).
\end{gframe}
\end{defframe}

\begin{gframe}{Osservazione}
    Il fatto che valga \( \Aa \vDash F[\alpha] \) dipende solo dai valori di \( \alpha \) sulle variabili libere che appaiono in \( F \). Quindi, come già visto in maniera simile per la logica proposizionale, se \( \alpha \) e \( \beta \) sono due assegnamenti che coincidono sui valori assegnati alle variabili \( x_1, \dots, x_n \), allora \( \Aa \vDash F[\alpha] \iff \Aa \vDash F[\beta]\).

    Da questo segue che, se \( F \) è un \textbf{enunciato}, allora \( \Aa \vDash F[\alpha]\) vale \textbf{per tutti gli assegnamenti o per nessuno}.
\end{gframe}

\begin{defframe}{Soddisfacibilità, Validità}{}
    Se \( \exists \alpha \ \ t.c. \ \ \Aa \vDash E[\alpha] \), diciamo che \( \alpha \) \textit{soddisfa} un enunciato \( E \) in \( \Aa \). In questo caso, \( E \) è detto \textbf{soddisfacibile} in \( \Aa \).

    Diciamo che una formula \( F \) è \textbf{vera} in una struttura se \textit{è soddisfatta da tutti gli assegnamenti} in quella struttura.

    \begin{gframe}{}
        Una formula \( F \) è vera in una struttura se e solo se l'enunciato
        \[ \forall x_1, \dots \forall x_n \ F(x_1, \dots, x_n) \] 
        (dove \( x_1, \dots, x_n \) sono tutte e sole le variabili libere di \( F \)) è vero nella struttura.
    \end{gframe}

    Un enunciato \( E \) è \textbf{valido} se è vero in tutte le strutture (ossia se \( \forall \Aa, \ \Aa \vDash E \)). In tal caso, scriviamo \( \vDash E \).

    Dualmente, \( E \) è \textit{insoddisfacibile} se non esiste una struttura in cui è vero.
\end{defframe}

Si può estendere il concetto di verità logica anche alle formule predicative. Per esempio, la formula \( \forall x R(x) \lor \neg\forall x R(x)\) (ottenuta da \( p \lor \neg p \) sostituendo \( p \)) è soddisfatta in ogni struttura che possieda un'interpretazione per \( R \).

Questo tipo di formule prendono il nome di \textit{istanze di tautologie proposizionali}.

\section{Teorie}

Dato un linguaggio \( \Ll \), ci interessa introdurre questi insiemi degni di nota:
\begin{itemize}
    \item \textbf{Teoria} - una teoria è un insieme \( T \) di enunciati in \( \Ll \)
    \item \textbf{Modello} - un modello di una teoria è una struttura per \( \Ll \) che \textit{soddisfa tutti gli elementi di \( T \)}.
        \subitem scriviamo \( \Aa \vDash T \)
        \subitem e definiamo quindi \( Mod(T)=\{\Aa : \Aa \vDash T\} \)
        \subitem (nota: una teoria si dice \textit{soddisfacibile} se ha un modello)
    \item \textbf{Conseguenza logica di una teoria} - \( E \) \ t.c. \(E \) è vero in tutti i modelli di \( T \) (diciamo che \( T \) \textit{implica logicamente} \( E \))
        \subitem definiamo coerentemente \( Conseq(T) = \{E : T\vDash E\} \)
\end{itemize}

Mentre la teoria di una singola struttura è sempre completa, l'insieme delle sue conseguenze logiche non lo è necessariamente

\begin{gframe}{Esempio: Teoria dei Gruppi}
Un esempio è la teoria formata dagli assiomi di gruppo scritti in un linguaggio predicativo \( \mathcal{L}_G = \{ \circ, e \} \), dove \( \circ \) è un simbolo di funzione di arietà due ed \( e \) è un simbolo di costante.

Gli assiomi della teoria di gruppo si esprimono con i seguenti enunciati, che formano la ``teoria dei grupppi'' \( T_G \):
\begin{align*}
\forall v_1 \forall v_2 \forall v_3 ((v_1 \circ v_2) \circ v_3 &= v_1 \circ (v_2 \circ v_3)) \\
\forall v_1 ((v_1 \circ e = v_1) &\land (e \circ v_1 = v_1)) \\
\forall v_1 \exists v_2 ((v_1 \circ v_2 = e) &\land (v_2 \circ v_1 = e))
\end{align*}

I modelli di \( T_G \) sono le strutture che chiamiamo gruppi; dunque \( Mod(T_G) \) è l'insieme di tutti e soli i gruppi.

Gli enunciati che sono veri in qualunque gruppo formano l'insieme delle conseguenze logiche della teoria, indicato con \( Conseq(T_G) = \{E : T_G \models E\} \)
(le proprietà vere in uno specifico gruppo \( G \) formano invece la ``teoria completa di \( G \)'', ossia \( Th(G) = \{E : G \models E\} \)).

Un esempio di teoria incompleta ci viene dato proprio da \( T_G \) (e \( Conseq(T_G) \)): dato che esistono gruppi abeliani e gruppi non-abeliani, e dato che la proprietà di essere abeliano è esprimibile nel linguaggio dei gruppi con l'enunciato \( C = \forall v_1 \forall v_2 (v_1 \circ v_2 = v_2 \circ v_1) \), esistono modelli di \( T_G \) che soddisfano \( C \) e modelli che soddisfano \( \neg C \).

Dunque né \( C \) né \( \neg C \) appartengono a \( Conseq(T_G) \) (né l'essere abeliano né l'essere non abeliano sono conseguenze logiche degli assiomi di gruppo).

La teoria dei gruppi \( T_G \) è dunque incompleta.
\end{gframe}

\subsection*{Relazioni tra teorie e coerenza}

Siano \( T \) e \( S \) due teorie sullo stesso linguaggio tali che \( T \subseteq S \).

Valgono le seguenti proprietà:
\begin{itemize}
    \item monotonia \( \longrightarrow \) \( T\vDash \varphi \implies S \vDash \varphi \)

    \item "ereditarietà" dei modelli \( \longrightarrow \) ogni modello di \( S \) è anche modello di \( T \) (tutto \( T \) si trova dentro \( S \))
        \subitem \( Mod(S) \subseteq Mod(T) \)

    \item coerenza \( \longrightarrow \) se \( S \) è corente, allora anche \( T \) lo è
        \subitem (se \( T \) è corente, non è detto che \( S \) lo sia)
\end{itemize}

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.3} 
\begin{tabular}{|l|c|p{7cm}|}
\hline
\textbf{affermazione} & \textbf{risp} & \textbf{motivo} \\ \hline
Se $T \models A$, allora $S \models A$? & VERO & Monotonia \\ \hline
Se $\mathcal{A} \models S$, allora $\mathcal{A} \models T$? & VERO & Definizione di estensione (i modelli diminuiscono). \\ \hline
Se $T$ è coerente, allora $S$ è coerente? & FALSO & $S$ potrebbe aggiungere assiomi che contraddicono $T$. \\ \hline
Se $S$ è coerente, allora $T$ è coerente? & VERO & Se esiste un modello per tutto $S$, quel modello va bene anche per il sottoinsieme $T$. \\ \hline
Se $T$ è completa, $S$ (propria) è coerente? & FALSO & $T$ ha già deciso tutto - se $S$ aggiunge qualcosa di nuovo (non derivabile da $T$), crea incoerenza. \\ \hline
\end{tabular}
\end{table}




\section{Isomorfismi tra strutture}
Se esiste un isomorfismo tra due strutture \( \Aa \) e \( \Bb \), significa che queste sono ``indistinguibili'', ovvero che hanno le stesse proprietà. È dunque vero che \( \Aa \iso \Bb \implies \Aa \text{ e } \Bb \) soddisfano gli stessi enunciati? La risposta è sì (nel linguaggio per cui sono isomorfe).

\begin{thmframe}{Isomorfismo e soddisfacibilità}{}
    \( \Aa \iso \Bb \implies \Aa \text{ e } \Bb \) \textbf{soddisfano le stesse formule}.

    Sia \( h \) l'isomorfismo. Si ha quindi \( \forall F(x_1, \dots, x_n), \ \forall (a_1, \dots, a_n) \in A^n \)
    \[ \Aa \vDash F(x_1, \dots, x_n)[a_1, \dots, a_n] \iff  \Bb \vDash F(x_1, \dots, x_n)[h(a_1), \dots, h(a_n)]\]
\end{thmframe}

Lo dimostriamo per le formule, che sono una struttura induttiva (così che valga anche per gli enunciati).

\begin{pframe}
    \begin{itemize}
        \item \textbf{caso base}:
            \begin{enumerate}
                \item \( t_1 \leq t_2 \)
                    \begin{align*}
                        \Aa \vDash (x \leq y)[a_1, a_2] &\iff \Bb \vDash (x\leq y)[h(a_1), h(a_2)]\\
                        (a_1, a_2)\in \leq_A &\iff (h(a_1), h(a_2)) \in \leq_B \\
                    \text{vero per }& \text{def. di isomorfismo}
                    \end{align*}

                \item \( t_1 = t_2 \)
                    \begin{align*}
                        \Aa \vDash (x = y)[a_1, a_2] &\iff \Bb \vDash (x = y)[h(a_1), h(a_2)]\\
                        a_1 = a_2 &\iff h(a_1) = h(a_2) \\
                    \text{vero per }& \text{def. di isomorfismo}
                    \end{align*}

    \end{enumerate}
                    \item \textbf{passo induttivo:}
    Assumiamo che la proprietà valga per le formule \(\phi\) e \(\psi\). 

    Sia \(\vec{a} = (a_1, \ldots, a_n)\) la sequenza degli elementi in \(A\) e \(h(\vec{a}) = (h(a_1), \ldots, h(a_n))\) la sequenza in \(B\).

    \begin{enumerate}
        \item \textbf{negazione ($\neg$)}:
        \[ \mathcal{A} \models \neg \phi[\vec{a}] \]
        \[ \iff \mathcal{A} \not\models \phi[\vec{a}] \quad \text{(def. di } \neg) \]
        \[ \iff \mathcal{B} \not\models \phi[h(\vec{a})] \quad \text{(ip. ind. su } \phi) \]
        \[ \iff \mathcal{B} \models \neg \phi[h(\vec{a})] \quad \text{(def. di } \neg) \]

        \item \textbf{congiunzione ($\land$)}:
        \[ \mathcal{A} \models (\phi \land \psi)[\vec{a}] \]
        \[ \iff \mathcal{A} \models \phi[\vec{a}] \text{ e } \mathcal{A} \models \psi[\vec{a}] \quad \text{(def. di } \land) \]
        \[ \iff \mathcal{B} \models \phi[h(\vec{a})] \text{ e } \mathcal{B} \models \psi[h(\vec{a})] \quad \text{(ip. ind. su } \phi \text{ e } \psi) \]
        \[ \iff \mathcal{B} \models (\phi \land \psi)[h(\vec{a})] \quad \text{(def. di } \wedge) \]

        \item \textbf{quantificazione ($\exists$)}:
        Sia \(\phi\) con variabile libera \(y\) in aggiunta a \(x_1, \ldots, x_n\).
        \[ \mathcal{A} \models (\exists y \phi)[\vec{a}] \]
        \[ \iff \exists c \in A \text{ tale che } \mathcal{A} \models \phi[\vec{a}, c] \quad \text{(def. di } \exists) \]
        \[ \iff \exists c \in A \text{ tale che } \mathcal{B} \models \phi[h(\vec{a}), h(c)] \quad \text{(ip. ind. su } \phi) \]
        Poiché \(h\) è suriettiva, l'insieme \(\{h(c) \mid c \in A\}\) è uguale all'insieme base \(B\). Posto \(b = h(c)\):
        \[ \iff \exists b \in B \text{ tale che } \mathcal{B} \models \phi[h(\vec{a}), b] \]
        \[ \iff \mathcal{B} \models (\exists y \phi)[h(\vec{a})] \quad \text{(def. di } \exists) \]
        (Il caso per \(\forall\) segue da \(\forall y \phi \equiv \neg \exists y \neg \phi\)).
            \end{enumerate}
    \end{itemize} \qed
\end{pframe}

Passiamo ad un caso ancora più generale. Vogliamo mostrare che un isomorfismo tra due strutture 
\begin{align*}
    \Aa &= (A, \{R_i^A\}_{i\in I}, \{f_j^A\}_{j\in J},\{c_k^A\}_{k\in K} ) \\
    \Bb &= (B, \{R_i^B\}_{i\in I}, \{f_j^B\}_{j\in J},\{c_k^B\}_{k\in K} ) 
\end{align*}
preserva \textit{l'intera struttura}.

Quindi

\begin{defframe}{Isomorfismo tra due strutture}{}
    Siano \( \Aa \) e \( \Bb \) due strutture per il linguaggio \( \Ll \). \\
    \( \Aa \) è isomorfa a \( \Bb \) se e solo se esiste una mappa \( h: \Aa \to \Bb \) biiettiva tale che:
\begin{enumerate}
    \item[(1)] Per ogni simbolo di relazione $n$-ario $R$ nel linguaggio, per ogni $(a_1, \dots, a_n) \in A^n$,
    \[
    \mathcal{A} \models R(x_1, \dots, x_n)[a_1, \dots, a_n] \text{ se e solo se } \mathcal{B} \models R(x_1, \dots, x_n)[h(a_1), \dots, h(a_n)],
    \]
    i.e.
    \[
    (a_1, \dots, a_n) \in R^{\mathcal{A}} \iff (h(a_1), \dots, h(a_n)) \in R^{\mathcal{B}}.
    \]
    
    \item[(2)] Per ogni simbolo di costante $c$ nel linguaggio,
    \[
    h(c^{\mathcal{A}}) = c^{\mathcal{B}},
    \]
    
    \item[(3)] Per ogni simbolo di funzione $n$-ario $f$ nel linguaggio, per ogni $(a_1, \dots, a_n) \in A^n$,
    \[
    h(f^{\mathcal{A}}(a_1, \dots, a_n)) = f^{\mathcal{B}}(h(a_1), \dots, h(a_n)).
    \]
    ($h$ "commuta" con il simbolo di funzione $f$).
\end{enumerate}

\end{defframe}

Vogliamo dimostrare che, per ogni termine $t$ e ogni assegnazione $\alpha$,
il valore del termine \(t\) in \(\Aa\) con assegnazione \(\alpha\), quando mappato dall'isomorfismo \(h\), è uguale
al valore del termine \(t\) in \(\Bb\) con assegnazione \(h(\alpha)\):
\[ h(t^{\Aa, \alpha}) = t^{\Bb, h(\alpha)} \]
Si dimostra per induzione sulla struttura del termine \(t\).

\begin{proofframe}
\begin{enumerate}
    \item \textbf{Caso 1: $t$ è una variabile ($t = x$)}
    \begin{align*}
    h(x^{\Aa, \alpha}) &= h(\alpha(x)) & \text{(per def. di valutazione: } x^{\Aa, \alpha} = \alpha(x)\text{)} \\
    x^{\Bb, h(\alpha)} &= h(\alpha)(x) & \text{(per def. di valutazione in } \Bb \text{ con assegnazione } h(\alpha)\text{)}
    \end{align*}
    Per definizione dell'assegnazione $h(\alpha)$, si ha $h(\alpha)(x) = h(\alpha(x))$.
    Quindi, l'uguaglianza è soddisfatta:
    \[ h(x^{\Aa, \alpha}) = h(\alpha(x)) = h(\alpha)(x) = x^{\Bb, h(\alpha)} \]

    \item \textbf{Caso 2: $t$ è una costante ($t = c$)}

        (in questo caso \( \alpha \) non ha impatto - non ci sono assegnazioni) 
    \begin{align*}
    h(c^{\Aa, \alpha}) &= h(c^\Aa) & \text{(la valutazione di } c \text{ è l'interpretazione } c^\Aa \text{)} \\
    &= c^\Bb & \text{(poiché } h \text{ è un isomorfismo, preserva le costanti)} \\
    c^{\Bb, h(\alpha)} &= c^\Bb & \text{(la valutazione di } c \text{ è l'interpretazione } c^\Bb \text{)}
    \end{align*}
    Quindi, l'uguaglianza è soddisfatta:
    \[ h(c^{\Aa, \alpha}) = c^\Bb = c^{\Bb, h(\alpha)} \]

\item \textbf{Caso 3: $t$ è una funzione ($t = f(t_1, \ldots, t_p)$)}
\begin{align*}
h(t^{\Aa, \alpha}) &= h(f(t_1, \ldots, t_p)^{\Aa, \alpha}) \\
&= h(f^\Aa(t_1^{\Aa, \alpha}, \ldots, t_p^{\Aa, \alpha})) & \text{(def. di valutazione di termine funzione)} \\
&= f^\Bb(h(t_1^{\Aa, \alpha}), \ldots, h(t_p^{\Aa, \alpha})) & (h \text{ isomorfismo, preserva la funzione } f) \\
&= f^\Bb(t_1^{\Bb, h(\alpha)}, \ldots, t_p^{\Bb, h(\alpha)})\\
&= f(t_1, \ldots, t_p)^{\Bb, h(\alpha)} & \text{(def. di valutazione di termine funzione in } \Bb) \\
&= t^{\Bb, h(\alpha)}
\end{align*}

\end{enumerate}
La proprietà è dimostrata per tutti i termini. \qed
\end{proofframe}


\begin{corframe}{Equivalenza elementare}
    Si ha quindi che \( \Aa \iso \Bb \implies \Aa \equiv \Bb \) (``elementarmente equivalenti'')

    ovvero, \( \Aa \) e \( \Bb \) soddisfano gli stessi enunciati.

\end{corframe}

\begin{thmframe}{Equivalenza elementare su domini finiti}{}
    In generale, non vale \( \Aa \equiv \Bb \implies \Aa \iso \Bb \). Vale però se \( \Aa \) e \( \Bb \) finite e \( \Ll \) ha solo simboli di relazione.
\end{thmframe}


\begin{proof}
Sia \( \mathcal{A} \) una struttura finita con dominio \( A \) di cardinalità \( n \). Possiamo enumerare gli elementi del dominio come \( A = \{a_1, a_2, \dots, a_n\} \).

L'idea della dimostrazione è costruire un singolo enunciato \( \sigma_{\mathcal{A}} \) che descriva completamente la struttura \( \mathcal{A} \) a meno di isomorfismo.

Costruiamo \( \sigma_{\mathcal{A}} \) come segue:
\[
\sigma_{\mathcal{A}} = \exists x_1 \dots \exists x_n \left( \psi_{\text{card}} \land \psi_{\text{strut}} \right)
\]

\paragraph{1. Fissare la cardinalità}
La formula \( \psi_{\text{card}} \) assicura che il dominio abbia esattamente \( n \) elementi distinti:
\[
\psi_{\text{card}} = \left( \bigwedge_{1 \le i < j \le n} x_i \neq x_j \right) \land \left( \forall y \bigvee_{i=1}^n y = x_i \right)
\]
La prima parte afferma che gli \( x_i \) sono tutti diversi tra loro, mentre la seconda afferma che ogni elemento \( y \) del dominio coincide con uno degli \( x_i \).

\paragraph{2. Fissare la struttura}
La formula \( \psi_{\text{strut}} \) descrive tutte le relazioni che valgono (e non valgono) tra gli elementi. Per ogni simbolo di relazione \( R \) in \( L \) (supponiamo WLOG che \( L \) contenga un solo simbolo di relazione binaria \( E \)):
\[
\psi_{\text{strut}} = \left( \bigwedge_{(a_i, a_j) \in E^{\mathcal{A}}} E(x_i, x_j) \right) \land \left( \bigwedge_{(a_i, a_j) \notin E^{\mathcal{A}}} \neg E(x_i, x_j) \right)
\]

\paragraph{Conclusione}
Chiaramente \( \mathcal{A} \models \sigma_{\mathcal{A}} \), poiché basta interpretare le variabili \( x_i \) con gli elementi \( a_i \).
Dato che \( \mathcal{A} \equiv \mathcal{B} \), allora anche \( \mathcal{B} \models \sigma_{\mathcal{A}} \).

Ciò significa che esistono elementi \( b_1, \dots, b_n \) nel dominio di \( \mathcal{B} \) che soddisfano il corpo della formula \( \sigma_{\mathcal{A}} \).
Definiamo la mappa \( f: A \to B \) ponendo \( f(a_i) = b_i \).

Grazie a \( \psi_{\text{card}} \), sappiamo che i \( b_i \) sono distinti e coprono tutto il dominio di \( \mathcal{B} \), quindi \( f \) è una biiezione.
Grazie a \( \psi_{\text{strut}} \), la relazione è preservata:
\[
(a_i, a_j) \in E^{\mathcal{A}} \iff \mathcal{B} \models E(b_i, b_j) \iff (f(a_i), f(a_j)) \in E^{\mathcal{B}}
\]
Pertanto, \( f \) è un isomorfismo e \( \mathcal{A} \cong \mathcal{B} \).
\end{proof}
\pagebreak
\section{La teoria DLO}

\subsection{Numeri razionali}
Prendiamo la struttura \( \Qq = (\Q, \leq ) \). Le proprietà di questa struttura si possono esprimere in enunciati predicativi nel linguaggio \( \Ll = \{\leq (x,y)\}\), per il quale, per comodità, usiamo la notazione infissa \( x \leq y \). 

Aggiungiamo anche \( x < y \) come abbreviazione di \( (x \leq y) \land \neg(x = y)\). 

Le proprietà di \( Q, \leq \) sono le seguenti:

\begin{mdframed}
\begin{enumerate}
    \item (A1 - Riflessività) $\forall x\ (x \leq x),$
    \item (A2 - Transitività) $\forall x\forall y\forall z \ ((x \leq y \land y \leq z \to x \leq z),$
    \item (A3 - Antisimmmetria) $\forall x\forall y\ ((x \leq y \land y \leq x) \to y = x),$
    \item (A4 - Totalità) $\forall x\forall y\ (x \leq y \lor x \leq y),$
    \item (A4 - Illimitato a destra) $\forall x\exists y\ (x < y),$
    \item (A5 - Illimitato a sinistra) $\forall x\exists y\ (y < x),$
    \item (A6 - Densità) $\forall x\forall y(x < y \to \exists z(x < z \land z < y)).$
\end{enumerate}
\end{mdframed}

Chiamiamo questa teoria \textbf{DLO} (\textit{Dense Linear Order}).

\begin{thmframe}{\( Q \) e DLO}{}
    \( \Q \) è l'\textit{unico ordine lineare denso numerabile senza estremi} a meno di isomorfismi.
\end{thmframe}

\subsubsection{Isomorfismo: caso numerabile}

\begin{thmframe}{Isomorfismo: caso numerabile}{}
    Sia \( \Bb = (B, \leq_B) \) una struttura con dominio \( B \) numerabile e \( \leq_B \) un ordine totale denso senza estremi su \( B \). Allora esiste un isomorfismo tra \( \Bb\) e \(\Qq \).
\end{thmframe}

Vogliamo dimostrare che \textit{ogni struttura} dove \( B \) è numerabile e \( \leq_B \) è un ordine totale denso senza estremi su \( A \) è isomorfa a \( (\Q, \leq)  \).

\begin{gframe}{}
    È naturale definire l'isomorfismo così: \(\Bb \cong \Qq \iff \exists h : \Q \bij B \ \text{ t.c. } \ \forall q, q' \in \Q\)
    \[ q \leq q' \iff h(q) \leq_B h(q')\]
    \[ q = q' \iff h(q) = h(q')\]
\end{gframe}

La dimostrazione usa un metodo chiamato \textit{Back-and-Forth}.

\begin{proofframe}
    Vogliamo costruire un isomorfismo tra \( \Bb \) e \( \Qq \). 
    
    Entrambe hanno un dominio numerabile, quindi fissiamo una enumerazione di \( B \) \( (b_0, b_1, b_2, \dots) \) e una enumerazione di \( \Q \) \( (q_0, q_1, q_2, \dots) \).

    Definiremo ricorsivamente una enumerazione \( p_1, p_2, p_3, \dots \) e una enumerazione \( d_1, d_2, d_3, \dots \) in modo tale che la mappa \( p_i \mapsto d_i \) sia un isomorfismo tra \( \Bb \) e \( \Qq \).

    Per induzione:
    \begin{itemize}
        \item Poniamo \( p_0 = b_0 \) e \( d_0 = q_0 \).
        \item Consideriamo un \( n \) generico e assumiamo che \( p_0, \dots, p_n \) e \( d_0, \dots, d_n \) siano definiti.

            Distinguiamo due casi:

            \begin{enumerate}
                \item Caso \textbf{pari}: scegliamo un elemento \(p_{n+1}\) in \(B \setminus \{p_0, \dots, p_n\}\) con indice minimo in \((b_0, b_1, b_2, \dots)\). Compariamo questo elemento agli elementi già scelti. 

                    Abbiamo tre casi:

                    \begin{itemize}
                        \item {\color{gray}(Prima di tutti gli altri elementi)}

                            Per ogni \(m \le n\), \(p_{n+1} < p_m\). In questo caso scelgo un \(q_{n+1}\) in \( \Q\) tale che per ogni \(m \le n\) abbiamo \(d_{n+1} < d_m\). Questo elemento esiste perché \( \Q \) soddisfa gli assiomi che asseriscono la \textit{non esistenza di estremi} nell'ordine. 

                            {\color{gray}(Scelgo un elemento da \( \Q \) che sia anch'esso prima di tutti gli altri)}

                        \item {\color{gray}(Dopo tutti gli altri elementi)}

                            Per ogni \(m \le n\), \(d_{n+1} > d_m\). In questo caso scelgo un \(q_{n+1}\) in \(\Q \) tale che per ogni \(m \le n\) valga \(d_{n+1} > d_m\). Questo elemento esiste perché \( \Q \) soddisfa l'assioma che \textit{esclude l'esistenza di un estremo destro} nell'ordine.
                            
                            {\color{gray}(Scelgo un elemento da \( \Q \) che sia anch'esso dopo tutti gli altri)}

                        \item {\color{gray}(Da qualche parte nel mezzo)}

                            Nessuno dei primi due casi. Allora esistono \(m_0, m_1 \le n\) tali che \(p_{m_0} < p_{n+1} < p_{m_1}\) e nessun altro elemento di \(\{p_0, p_1, \dots, p_n\}\) è nell'intervallo \([p_{m_0}, d_{m_1}]\). In questo caso scelgo un elemento \(d_{n+1}\) in \(\Q\) tale che \(d_{m_0} < d_{n+1} < d_{m_1}\). Questo elemento esiste perché \(\Q\) soddisfa l'assioma di \textit{densità}.
                            
                            {\color{gray}(Scelgo un elemento da \( \Q \) che sia anch'esso in mezzo agli altri)}

                    \end{itemize}

                \item Caso \textbf{dispari}: procediamo allo stesso modo, ma partendo da un elemento \(q_{n+1} \in \Q \setminus \{q_0, \dots, q_n\}\).

            \end{enumerate}

    \end{itemize}

    Grazie alla separazione in passi pari e dispari (poiché scegliamo sia a partire da \( B \) che da \( \Q\)), non ci saranno ``buchi'' nelle nostre scelte di elementi. 
\end{proofframe}

Notiamo che nella dimostrazione non servono proprietà di \( \Q \) se non quelle di DLO (e l'ipotesi di numerabilità del dominio). Il teorema si può quindi generalizzare.

\begin{thmframe}{Teorema di isomorfismo di Cantor}{}
        \label{thm:Cantor}
    Siano \( \Aa = (A, \leq_A) \) e \( \Bb = (B, \leq_B) \) t.c. \( A, B \) sono entrambi numerabili e \( \Aa \vDash \text{DLO} \) e \( \Bb \vDash \text{DLO} \). Allora, \( \Aa \iso \Bb \).
\end{thmframe}



\section{DLO: caso generale}
Ci chiediamo: data una struttura \( \Dd = (D, \leq_D) \vDash \text{DLO}\) con \( D \) più che numerabile, \( \Dd \isit{\equiv} \Qq \) - ovvero, per esempio, esiste un enunciato nel linguaggio degli ordini vero in \( \Q \) e falso in \( \R \)? (Se potessimo scrivere la completezza di \( \R \) in linguaggio degli ordini, allora questo sarebbe sicuramente vero (in quanto \(\Q\) non è completo) - ma non è possibile farlo).

Vogliamo quindi individuare un \textbf{criterio sufficiente} a concludere \( \Qq \equiv \Rr\).

\subsection{Sottostrutture, proprietà del testimone}

Introduciamo come prima cosa il concetto di sottostruttura:

\begin{defframe}{Sottostruttura}{}
    Date due strutture \( \Aa \) e \( \Bb \), \( \Aa \) si dice \textbf{sottostruttura} di \( \Bb \) (\( \Aa \subseteq  \Bb \)) se e solo se si ha:
    \begin{itemize}
        \item \( A \subseteq B \)
        \item per ogni simbolo \( R \) di relazione, \( R^\Aa = R^\Bb \cap A^n \) (dove \( n \) arità di \( R \))
        \item per ogni simbolo di costante, \( c^\Bb \in A \) e \( c^\Aa = c^\Bb \)
        \item per ogni simbolo di funzione, \(f^\Aa = f^\Bb \vert_A^n \) (con \( n \) arietà di \( f \))
    \end{itemize}

\end{defframe}

\begin{defframe}{Sottostruttura elementare}{}
    Date due strutture \( \Aa \) e \( \Bb \) tali che \( \Aa \subseteq \Bb \), si dice che \( \Aa \) è \textbf{sottostruttura elementare} di \( \Bb \) (\( \Aa \prec \Bb \)) se la verità delle formule è preservata prendendo parametri da \( A \).
    
    Formalmente, per ogni formula \( F(x_1, \dots, x_n) \in \Ll \) e per ogni scelta di elementi \( a_1, \dots, a_n \in A \):
    \[ \Aa \vDash F[a_1, \dots, a_n] \iff \Bb \vDash F[a_1, \dots, a_n] \]
    
\begin{gframe}{}
        se \( \Aa \prec \Bb \), allora \( \Aa \equiv \Bb \) (sono elementarmente equivalenti)
\end{gframe}

\end{defframe}

Tornando alla teoria DLO, notiamo che \( \Qq \subseteq \Rr \).

Data una formula \( F \), è naturale che se \( \alpha \)  è un assegnamento in \( \Q \) e \( \Qq \vDash \exists x F[\alpha] \), allora \( \Rr \vDash \exists x F[\alpha] \).

Non è però detto che valga l'inverso, ossia:
\begin{thmframe}{Proprietà del testimone tra \( \Rr \) e \( \Qq \)}{}
    Per ogni formula \( F \) con \( x \) variabile libera, \textit{per ogni assegnamento} \( \alpha \) in \( \Q \), se
    \[ \Rr \vDash \exists x \ F(x)[\alpha] \]
allora \( \exists q \in \Q \) tale che:
\[ \Rr \vDash F(x)[\alpha \ass{x}{q}] \]

(quindi, abbiamo una formula \( F \) con tutte le variabili in \( \Q \) tranne una; presumiamo che sia vera con l'ultima variabile assegnata in \( \R \) - allora vogliamo che \(\exists q \in \Q \) (da assegnare all'ultima variabile) che la soddisfi)
\end{thmframe}

La proprietà del testimone è la condizione sufficiente per dedurre \( \Qq \equiv \Rr \).

Come già visto, conviene dimostrare la proprietà per le formule (così che valga anche per gli enunciati).

\begin{corframe}{Conseguenza della proprietà del testimone}{}
    Se vale la proprietà del testimone tra \( \Rr \) e \( \Qq \), allora \( \forall F, \forall \alpha \) su \( Q \),
    \[ \Qq \vDash F[\alpha] \iff \Rr \vDash F[\alpha] \]
\end{corframe}

\begin{corframe}{Conseguenza della proprietà del testimone}{}
    Se vale la proprietà del testimone tra \( \Rr \) e \( \Qq \), allora \( \forall F, \forall \alpha \) su \( Q \),
    \[ \Qq \vDash F[\alpha] \iff \Rr \vDash F[\alpha] \]
\end{corframe}

\begin{proofframe}{}{}
    Si dimostra per induzione sulla complessità della formula \( F \).

    \begin{itemize}
        \item \textbf{caso base}: \( F \) è una formula atomica, ad esempio di tipo \( (x \leq y) \).
        
        Poiché \( \Qq \subseteq \Rr \), la relazione d'ordine in \( \Qq \) è definita esattamente come la restrizione dell'ordine di \( \Rr \) ai numeri razionali (\( \leq_\Qq = \leq_\Rr \cap (\Qq \times \Qq) \)). Essendo \( \alpha(x) \) e \( \alpha(y) \) numeri razionali, la relazione vale in un modello se e solo se vale nell'altro:
            \begin{align*}
                \Qq \vDash (x\leq y)[\alpha] &\iff \alpha(x) \leq_\Q \alpha(y) \\
                &\iff \alpha(x) \leq_\R \alpha(y) \quad (\text{poiché } \Qq \subseteq \Rr) \\
                &\iff \Rr \vDash (x\leq y)[\alpha] 
            \end{align*}
            (Il ragionamento è analogo per l'uguaglianza \( x = y \)).

        \item \textbf{passo induttivo (booleani)}:

        Supponiamo per Ipotesi Induttiva che il teorema valga per le sottoformule \( A \) e \( B \). Ovvero:
        \[
        \Q \models A[\alpha] \iff \R \models A[\alpha] \quad \text{e} \quad \Q \models B[\alpha] \iff \R \models B[\alpha]
        \]
        La verità di una congiunzione dipende unicamente dalla verità delle singole parti. Quindi l'equivalenza si conserva:
            \begin{align*}
                \Qq \vDash (A \land B) [\alpha] &\iff \Qq \vDash A[\alpha] \land \Qq \vDash B[\alpha] \\
                (\text{per I.I.}) &\iff \Rr \vDash A[\alpha] \land \Rr \vDash B[\alpha] \\
                &\iff \Rr \vDash (A \land B)[\alpha]
            \end{align*}
            (Argomento analogo per gli altri connettivi).

        \item \textbf{passo induttivo (esistenziale)}:
        
            Sia \(F \equiv \exists x \, G(x)\). 

            \textit{Ipotesi Induttiva}: Assumiamo che per la formula interna \( G(x) \) e per qualsiasi assegnamento in \( \Qq \), l'equivalenza valga.
        Dobbiamo mostrare:
        \[
        \Q \vDash \exists x \, G(x)[\alpha] \iff \R \vDash \exists x \, G(x)[\alpha]
        \]

        \textit{Direzione \(\implies\):}
        Assumiamo \(\Q \vDash \exists x \, G(x)[\alpha]\).
        Significa che esiste un testimone concreto \(q \in \Q\) tale che \(\Q \vDash G(x)[\alpha\ass{x}{q}]\).
        Poiché \( \Qq \subseteq \Rr \), questo \( q \) esiste anche in \( \Rr \).
        Applicando l'I.I. alla formula \( G(x) \) valutata su \( q \):
        \[
            \Q \vDash G(x)[\alpha \ass{x}{q}] \implies \R \vDash G(x)[\alpha \ass{x}{q}]
        \]
        Dato che abbiamo trovato un elemento in \( \Rr \) (lo stesso \( q \)) che soddisfa la formula, concludiamo:
        \[
            \R \vDash \exists x \, G(x)[\alpha]
        \]

        \textit{Direzione \(\impliedby\):}
        Assumiamo \(\R \vDash \exists x \, G(x)[\alpha]\).

        Normalmente, il testimone in \( \Rr \) potrebbe essere irrazionale. Ma la \textit{Proprietà del Testimone} garantisce che se esiste una soluzione in \( \Rr \), allora esiste un testimone \(q \in \Q\) tale che:
        \[
            \R \vDash G(x)[\alpha \ass{x}{q}]
        \]
        Ora che abbiamo un parametro \( q \) razionale, possiamo usare l'I.I.:
        \[
            \R \vDash G(x)[\alpha\ass{x}{q}] \iff \Q \vDash G(x)[\alpha\ass{x}{q}]
        \]
        Quindi \(\Q \vDash G(x)[\alpha\ass{x}{q}]\). Poiché abbiamo trovato un testimone in \( \Qq \), per definizione di soddisfacibilità:
        \[
            \Q \vDash \exists x \, G(x)[\alpha]
        \]

    \end{itemize}
    \qed
\end{proofframe}

\begin{corframe}{Altra conseguenza della proprietà del testimone}
    Quindi, se vale la proprietà del testimone tra \( \Qq \) e \( \Rr \), per ogni enunciato \( E \) nel linguaggio degli ordini si ha:
    \[ \Qq \vDash E \iff \Rr \vDash E \]

    ovvero \( \Qq \equiv \Rr \), e quindi \( \Qq \prec \Rr \).
\end{corframe}

\subsection{Equivalenza tra \( \Rr \) e \( \Qq \)}

Per dimostrare \( \Qq \equiv \Rr \), definiamo \( \Aa = (A, \leq_A) \) t.c. \( \Qq \subseteq \Aa \subseteq \Rr \) e \( A \) numerabile. 

Seguiremo quindi questi passi:
\vspace{-0.5em}
\begin{enumerate}
    \item dimostreremo la proprietà del testimone tra \( \Aa \) e \( \Rr \), ottenendo \( \Aa \equiv \Rr \)
    \item visto che \( \Rr \vDash\) DLO e (1), si ha \( \Aa \vDash \) DLO
    \item da (2) e \( A \) numerabile, applicando il Teorema di Cantor (p.\pageref{thm:Cantor}) si ottiene \( \Aa \iso \Qq \)
    \item visto che \( \iso \implies \equiv \), si ha \( \Aa \equiv \Qq \)
    \item per transitività, \( \Rr \equiv \Qq \).
\end{enumerate}

Costruiamo quindi \( \Aa \) partendo da \( \Qq \).

Sia \( F \) una formula del linguaggio DLO e siano \( x_1, x_2, y \) le sue variabili libere.

Se \( \Rr \vDash \exists y F(x_1, x_2, y) \tworowmatrix{x_1 & x_2}{q_1 & q_2} \), per definizione di soddisfacibilità sappiamo che 
\\\( \exists r \in \R\) \ t.c. \ \( \Rr \vDash F(x_1, x_2, y) \tworowmatrix{x_1 & x_2 & y}{q_1 & q_2 & r} \). Ne scegliamo uno in modo canonico {\color{gray}(usiamo implicitamente l'assioma della scelta)}.

\begin{defframe}{Funzione di Skolem}{}
    Chiamiamo \textbf{funzione di Skolem} (da \href{https://en.wikipedia.org/wiki/Thoralf_Skolem}{Thoralf Skolem}) della formula \( F \) relativamente ad \( y \) la funzione 
    \[ f_{F, y} : \Qq^n \to \Rr \]
    che associa ad ogni scelta di \( (q_1, \dots, q_n) \) un tale \( r \in \R \) in modo canonico.
\end{defframe}

Dato \( \Ff = \{ \text{funzioni di Skolem}\} \), chiudiamo \( \Q \) sotto \( \Ff \).

Otteniamo \( A_1 = \Q \cup \{b \in \R \mid b = f(q_1, \dots, q_n) \text{ con } f\in \Ff, \ (q_1, \dots, q_n) \in Q^n\} \).

Sappiamo che \( \Qq \subseteq \Aa_1 = (A_1, \leq_A) \subseteq \Rr\).

È però vero che se \( x_1, x_2 \) sono assegnati in \( A_1 \) come \( a_1, a_2 \) allora esiste un \( a \in A_1\) t.c. \\ \( \Rr \vDash F(x_1, x_2, y) \tworowmatrix{x_1 & x_2 & y}{a_1 & a_2 & a}  \)? Non necessariamente. Infatti, se \( a_1, a_2 \in \Q \), sicuramente sì. 

Ma, se \( a_1, a_2 \in \Aa_1 \setminus \Qq \), non possiamo saperlo per certo. Dobbiamo quindi chiudere nuovamente sotto \( \Ff \).

Non ci basta però chiudere un'altra volta, in quanto il problema si ripropone. Dobbiamo ripetere l'operazione \( \forall i \geq 0\).

Abbiamo quindi
\[ A_{i+1} = A_i \cup \Ff(A_i) \]
{\color{gray}(utilizziamo la notazione \( \Ff(A) \) per indicare la chiusura di \( A \) su \( F \))}

Definiamo 
\[ A = \bigcup_{i\in \N} A_i \]

Si vede che \( A \) è chiuso sotto funzione di Skolem. \\Infatti, se \( a_1, \dots, a_n \in A_k \) e \( f\in \Ff \) allora \( f(a_1, \dots, a_n) \in A_{k+1} \).

\( \Aa = ( A =\bigcup_{i\in \N} A_i, \leq_A) \) ha anche la Proprietà del Testimone relativamente ad \( \Rr \).

Ovvero, se 
\[ \Rr \vDash \exists y F(x_1, x_2, y)\tworowmatrix{x1 & x2}{a_1 & a_2} \quad a_1, a_2 \in A\]
allora \( \exists a \in A \) t.c.
\[ \Rr \vDash F(x_1, x_2, y)\tworowmatrix{x1 & x2 & y}{a_1 & a_2 & a} \]

{\color{CadetBlue}[caso generale: \( \forall F, \forall \alpha \in A \), se:
    \[ \Rr\vDash \exists x F(x)[a] \]
    allora \( \exists a \in A \) t.c.:
    \[ \Aa \vDash F(x)\left[\alpha \ass{x}{a}\right] \]
]}

Possiamo quindi concludere che \( \Aa \equiv \Rr \).

Possiamo anche verificare che \( \Aa \) è numerabile:
\begin{itemize}
    \item \( \Ff \) è numerabile (perché esiste una funzione per ogni scelta di formula del linguaggio e di variabile libera, entrambe da insiemi numerabili)
    \item ogni \( A_k \) è numerabile (\( A_1 = \Q \) è numerabile, e ogni \( A_{k+1} \) è l'unione di un \( A_k \) numerabile con la sua chiusura sotto un altro insieme numerabile)
\end{itemize}

Abbiamo quindi dimostrato la seguente proposizione
\begin{propframe}{}{}
    Esiste una sottostruttura numerabile \( \Aa \) di \( \Rr \) che contiene \( \Q \) e soddisfa esattamente gli stessi enunciati di \( \Rr \) nel linguaggio degli ordini.
\end{propframe}

\( \Aa \) è anche un modello numerabile di DLO, perché \( \Rr \vDash  \)DLO.

Dunque \( \Aa \iso \Qq \). Dunque \( \Qq \equiv \Rr \) (nel linguaggio degli ordini).

\subsection{Generalizzazione della dimostrazione}
    La dimostrazione è generale - si può ricostruire in maniera equivalente partendo non da \( \Rr \) ma da un qualunque \( \Bb \) modello non-numerabile di DLO.

    La Proprietà del Testimone si esprime non relativamente a \( \Qq \) ma ad una sottostruttura numerabile \( \Xx \) di \( \Bb \) del tipo \( (X, \leq^\Xx ) \) con \( X \subseteq B \) e \( \leq^\Aa = \leq^\Bb \cap (A \times A)\).

    Si parte da un sottoinsieme numerabile \( X \) di \( \Bb \) (che ha sicuramente), e si procede per chiusura sotto funzioni di Skolem allo stesso modo.

    Si costruisce così \( \Xx = \bigcup_{i\in \N} X_i \). Si ha \( \Xx \vDash  \)DLO, e quindi \( \iso  \) e \( \equiv \Qq\).

    \begin{thmframe}{}{}
        Si ha quindi che \textbf{tutti i modelli di DLO} (numerabili o meno) soddisfano esattamente gli stessi enunciati di \( \Qq \).

        i.e. \( \Bb \vDash \text{DLO} \implies \Bb \equiv \Qq \)
    
        DLO ``identifica'' quindi \( (\Qq, \leq ): Th(\Qq) = Th(\Bb) \)
    \end{thmframe}

    \begin{corframe}{}
        DLO è una teoria completa.

        (ossia, \( \forall \text{ enunciato } E, \text{DLO}\vDash E \text{ oppure DLO} \vDash \neg E \) {\color{gray}(e DLO ha almeno un modello)}).

        \begin{pframe}{}{}
            Un modello di DLO soddisfa esattamente gli stessi enunciati di \( \Qq \). Dunque, \( Cons(\text{DLO}) \) sono esattamente gli enunciati veri nella singola struttura di \( \Qq \), che è una teoria completa.
        \end{pframe}
    \end{corframe}

\subsection*{Vademecum per esercizi su DLO}
Riassumiamo alcune informazioni utili su DLO.

Poiché DLO è completa e \( \Qq \) ne è un modello, e poiché DLO e \( \R \) condividono la stessa teoria nel linguaggio degli ordini, vale:
\[ \text{DLO} \vDash E \iff \Qq \vDash E \iff \Rr \vDash E \]

Questo significa che (limitatamente al linguaggio degli ordini)
\begin{itemize}
    \item se un enunciato \( E \) è vero in \( \R \), DLO \(\vDash E  \)
    \item se un enunciato \( E \) è falso in \( \Q \), DLO \( \vDash \neg E \)
\end{itemize}

\vspace{0.5em}
{\color{CadetBlue}esempio: 
se sappiamo che \( \Qq \vDash (E \lor F)\land \neg(E \land F) \) e che \( \Rr \vDash F \), è necessariamente vero che DLO \( \vDash \neg E \)?
\begin{itemize}
    \item abbiamo che \( \Rr \vDash F \implies \Qq \vDash F \)
    \item la formula \(  (E \lor F)\land \neg(E \land F)  \) è essenzialmente uno XOR su \( E \) ed \( F \)
    \item poiché \( \Qq \vDash F \), otteniamo che \( \Qq \vDash \neg E \)
    \item  quindi, DLO \(\vDash \neg E\)
\end{itemize}
}

\section{Criterio di Tarski-Vaught}

Per stabilire se una sottostruttura è anche una \textbf{sottostruttura elementare} (\(\mathcal{A} \preceq \mathcal{B}\)), possiamo quindi utilizzare la \textit{Proprietà del Testimone}, che chiamiamo anche ``criterio di Tarski-Vaught''.

\begin{defframe}{Proprietà del Testimone (generale)}{}
    
Sia \(\mathcal{A} \subseteq \mathcal{B}\). Diciamo che \(\mathcal{A}\) soddisfa la \textbf{Proprietà del Testimone} rispetto a \(\mathcal{B}\) se, per ogni formula del tipo \(\exists x F(x)\) e per ogni assegnamento \(\alpha\) in \(A\), se
\[
\mathcal{B} \models \exists x F(x)[\alpha]
\]
allora  \(\exists a \in A\) tale che:
\[
    \mathcal{B} \models F(x)\left[\alpha\ass{x}{a}\right]
\]

{\color{gray}\small(se in \(\mathcal{B}\) esiste una soluzione (un testimone) per una certa proprietà parametrizzata da elementi di \(A\), dobbiamo essere in grado di trovare quel testimone già dentro \(A\))}
\end{defframe}

\begin{thmframe}{}{}
    Sa \(\mathcal{A}\) è una sottostruttura di \(\mathcal{B}\) che \textbf{soddisfa la Proprietà del Testimone} rispetto a \(\mathcal{B}\), allora \(\mathcal{A}\) è una \textbf{sottostruttura elementare} di \(\mathcal{B}\).
\[
    \mathcal{A} \subseteq \mathcal{B} \text{ e Testimone} \implies \mathcal{A} \preceq \mathcal{B} \ \color{gray}(\implies \mathcal{A} \equiv \mathcal{B})
\]
\end{thmframe}


Quindi, iniziamo a vedere che partendo da un arbitrario modello \(\mathcal{B}\) infinito, ne esiste sempre uno numerabile (purché il linguaggio sia numerabile).

\begin{pframe}
Prendiamo \(\mathcal{B} \models T\) con \(|\mathcal{B}| = \infty\) e \(X \subseteq B\) con \(X\) numerabile.

Facciamo la solita chiusura per funzioni di Skolem. 

Immaginiamo una successione di insiemi \(X_0 \subseteq  X_1 \subseteq X_2 \dots\).

Definiamo:
\[
A = \bigcup_{i \in \mathbb{N}} X_i
\]

Definiamo la struttura \(\mathcal{A}\) in questo modo:
\begin{itemize}
    \item Per ogni simbolo di relazione: \(R^\mathcal{A} = R^\mathcal{B} \cap A^n\)
    \item Per ogni funzione: \(f^\mathcal{A} = f^\mathcal{B} \big|_{A^n}\)
\end{itemize}

\textbf{NB:} Ci manca la proprietà sulle costanti. Dobbiamo avere \(c^\mathcal{B} \in A\). Possiamo trattare le costanti come funzioni di Skolem 0-arie {\color{gray} \small("casi base" della definizione induttiva)}, garantendo la loro inclusione nella chiusura.

La struttura risultante è:
\[
\mathcal{A} = \left( \bigcup_{i \in \mathbb{N}} X_i, \{c_i^\mathcal{A}\}, \{R_j^\mathcal{A}\}, \{f_k^\mathcal{A}\} \right)
\]
\(\mathcal{A}\) è una sottostruttura per definizione e ha la proprietà del testimone (Tarski-Vaught).
\[
\implies \mathcal{A} \equiv \mathcal{B} \quad (\text{elementarmente equivalenti})
\]
Quindi, \(\mathcal{A} \models T\).
\end{pframe}


\section{Teorema di Löwenheim-Skolem (All'in giù)}

\begin{thmframe}{Teorema di Löwenheim-Skolem all'in giù}{}
Sia \(\mathcal{B}\) una struttura infinita adeguata per un linguaggio numerabile \(\mathcal{L}\). Sia \(X \subseteq B\) un sottoinsieme del suo dominio. Esiste una struttura \(\mathcal{A}\) tale che:
\begin{enumerate}
    \item \(X \subseteq A\)
    \item \(\mathcal{A} \preceq \mathcal{B}\) (è sottostruttura elementare)
    \item Se il linguaggio \(\mathcal{L}\) e l'insieme \(X\) sono numerabili, allora \(A\) è numerabile.
\end{enumerate}

Essenzialmente, \textbf{ogni teoria in un linguaggio numerabile che ammette un modello infinito (\(\mathcal{B}\)), ammette un ``sotto-modello'' numerabile} (\(\mathcal{A}\)) che è una sottostruttura elementare di \(\mathcal{B}\).

\end{thmframe}

La dimostrazione procede quasi analogamente a quella vista sopra.

\begin{corframe}{}{}
Non esiste una teoria \(T\) in un linguaggio \(\mathcal{L}\) numerabile (predicativo) che possa forzare i suoi modelli ad essere ``più che numerabili''.
\[
\mathcal{B} \models T \implies |B| > \aleph_0 \quad \text{(Falso in generale)}
\]
\end{corframe}

\begin{corframe}{``Paradosso'' di Skolem}
    La teoria assiomatica degli insiemi (ZFC) (se ha un modello) ha modelli numerabili.

    (Il linguaggio ha un solo simbolo di relazione binaria (\(\in\)) ed è numerabile).

    Il ``paradosso'' (non un vero paradosso) nasce dal fatto che:
\begin{itemize}
    \item In ZFC si dimostra l'esistenza di insiemi non numerabili (es. l'insieme dei reali \(\mathbb{R}\)). Formalmente:
    \[
    \text{ZFC} \vdash \exists x (\text{``}x \text{ è non numerabile''})
    \]
    \item Se ZFC ha un modello \(\mathcal{V}\), allora per il Teorema di Löwenheim-Skolem deve averne anche un modello numerabile \(\mathcal{M}\).
    \item Quindi esiste una struttura numerabile in cui è soddisfatto l'enunciato ``esiste un insieme non-numerabile''.
\end{itemize}

\end{corframe}

\section{Teorie categoriche (\(\omega\)-categoricità)}

L'argomento usato per dimostrare la completezza di DLO si può generalizzare.

\begin{defframe}{\(\omega\)-categoricità)}{}
Una teoria \(T\) si dice \textbf{\(\omega\)-categorica} se tutti i suoi modelli \textbf{numerabili} sono isomorfi tra loro.

\textit{(ricordiamo che se due modelli sono isomorfi, allora sono necessariamente elementarmente equivalenti)}
\end{defframe}

Sia \(T\) una teoria in un linguaggio numerabile che soddisfa le seguenti tre proprietà:
\begin{enumerate}
    \item \(T\) è \textbf{soddisfacibile} (ha almeno un modello).
    \item \(T\) \textbf{non ha modelli finiti} (ha solo modelli infiniti).
    \item \(T\) è \textbf{\(\omega\)-categorica} (ha un solo modello numerabile a meno di isomorfismo).
\end{enumerate}
Possiamo concludere che \(T\) è una teoria \textbf{completa}.

\begin{proofframe}{}{}
Supponiamo che \(T\) non sia completa.

1.  Se \(T\) non è completa, esiste un enunciato \(E\) nel linguaggio tale che \(T\) non dimostra né \(E\) né \(\neg E\).    
\[
    T \not\vdash E \quad \text{e} \quad T \not\vdash \neg E
    \]
    
2.  Questo implica che esistono due modelli \(\mathcal{B}\) e \(\mathcal{C}\) tali che:
    \[
    \mathcal{B} \models T \cup \{\neg E\} \quad \text{e} \quad \mathcal{C} \models T \cup \{E\}
    \]
    
3.  Per l'ipotesi (2), \(T\) non ha modelli finiti, quindi \(\mathcal{B}\) e \(\mathcal{C}\) sono entrambi infiniti.

4.  Applichiamo il Teorema di Löwenheim-Skolem a entrambi i modelli:
    \begin{itemize}
        \item Esiste \(\mathcal{B}_0 \preceq \mathcal{B}\) con \(\mathcal{B}_0\) numerabile. Poiché \(\mathcal{B} \models \neg E\), allora \(\mathcal{B}_0 \models \neg E\).
        \item Esiste \(\mathcal{C}_0 \preceq \mathcal{C}\) con \(\mathcal{C}_0\) numerabile. Poiché \(\mathcal{C} \models E\), allora \(\mathcal{C}_0 \models E\).
    \end{itemize}

5.  Ora abbiamo due modelli numerabili di \(T\), \(\mathcal{B}_0\) e \(\mathcal{C}_0\).
    Per l'ipotesi (3) di \textbf{\(\omega\)-categoricità}, tutti i modelli numerabili sono isomorfi:
    \[
    \mathcal{B}_0 \cong \mathcal{C}_0
    \]

6.  Se due strutture sono isomorfe, soddisfano gli stessi enunciati:
    \[
    \mathcal{B}_0 \equiv \mathcal{C}_0
    \]
    Tuttavia, abbiamo stabilito al punto 4 che \(\mathcal{B}_0 \models \neg E\) e \(\mathcal{C}_0 \models E\) (contraddizione) \qed
\end{proofframe}

\chapter{Calcolo dei Predicati}
Introduciamo ora il calcolo dei predicati (con identità) ``alla Hilbert''. Ad ogni linguaggio \( \Ll \) possiamo associare un calcolo dei predicati del I ordine.

\begin{defframe}{Dimostrabilità}{}
    Si ha \( T\vdash A \) se e solo se esiste una sequenza \( (A_1, A_2, \dots, A_n) \) di formule tali che:
    \begin{itemize}
        \item \( A_n = A \)
        \item \( \forall 1\leq i \leq n \):
            \begin{itemize}
                \item \( A_i \in T \), oppure
                \item \( A_i \) assioma, oppure
                \item \( A_i \) segue dai precedenti per regole di inferenza
            \end{itemize}
    \end{itemize}
\end{defframe}

Gli assiomi logici sono i seguenti:
\begin{gframe}{}
    \begin{enumerate}
        \item Tutti gli assiomi proposizionali (illustrati a p.\pageref{assprop})\\[1em]
            Gli assiomi predicativi:
        \item \( \forall x F\to F [x/t] \) con \( t \) termine libero per \( x \) in \( F \) {\small \color{gray} (per ``libero'' vedi p.\pageref{terlib})}
            \subitem da questa regola deriva anche:
            \AxiomC{\( F[x/t] \)}
            \UnaryInfC{\( \exists x \ F\)}
            \DisplayProof
        \item \( \forall x (F\to G)\to (F \to \forall x \ G) \), con \( F \) senza occorrenze libere di \( x \) {\small \color{gray} (si dice ``\( F \) non parla di \( x \)'')}\\[1em]
            Gli assiomi dell'identità:
        \item Per ogni simbolo di relazione \( R \):
            \[ \forall x_1 \dots x_n, \ \forall y_1, \dots y_n, \ \left(\bigwedge_{i=1}^{n} (x_i = y_i)\right) \to \bigl(R(x_1, \dots, x_n)\leftrightarrow R(y_1, \dots, y_n)\bigr) \]
        \item Per ogni simbolo di funzione \( f \):
            \[ \forall x_1 \dots x_n, \ \forall y_1, \dots y_n, \ \left(\bigwedge_{i=1}^{n} (x_i = y_i)\right) \to \bigl(f(x_1, \dots, x_n) = f(y_1, \dots, y_n)\bigr) \]
        \item (uguaglianza e transitività)
            \[ \forall x \ y \ z \Bigl( (x = x) \land \bigl((x = y) \to (y = x)\bigr) \land \bigl( (\left(x = y) \land (y = z) \right) \to (x = z)\bigr) \Bigr)\]
            {\small \color{gray}(valgono \( (x = x) \) e \( (x = y \to y = x) \) e \( ((x = y \land y = z) \to x = z) \))}
    \end{enumerate}
\end{gframe}

Le \textbf{regole di inferenza} che utilizziamo nel calcolo predicativo sono:
\begin{enumerate}
    \item \textit{Modus Ponens}:
        \AxiomC{\( X \)}
        \AxiomC{\( X \to Y \)}
        \BinaryInfC{\( Y \)}
        \DisplayProof
    \item \textit{Generalizzazione}:
        {\large \AxiomC{\( F \)}
        \UnaryInfC{\( \forall x \ F \)}
        \DisplayProof}
        \subitem {\small \color{gray}(attenzione ! non è come dire che se una formula \( F\) vale in un caso, allora vale \( \forall x \) - stiamo dicendo che, se ho \textit{dimostrato in maniera generica} \( F \), allora essa è vera \( \forall x \))}
\end{enumerate}

\subsection{Proprietà fondamentali del Calcolo dei Predicati}

Il calcolo dei predicati mantiene molte delle proprietà del calcolo proposizionale, come:
\begin{itemize}
    \item il \textbf{teorema di correttezza}: \( T \vdash A \implies T \vDash A \) (anche qui tutti gli assiomi sono verità logiche e le regole di inferenza preservano le verità logiche)
    \item \( T\vdash A \land T \subseteq S \implies S \vdash A  \) \ (monotonia)
    \item se \( \vdash A \), \( A \) è detto ``teorema''
    \item 
        \AxiomC{\( T \vdash A \)}
        \AxiomC{\( A \vdash B \)}
        \BinaryInfC{\( T \vdash B \)}
        \DisplayProof
    \item         
        \AxiomC{\( T \vdash A \)}
        \AxiomC{\( S \vdash B \)}
        \BinaryInfC{\( T \cup S \vdash A \land B \)}
        \DisplayProof
\end{itemize}

\vspace{1em}

\begin{thmframe}{Teorema di deduzione per il calcolo predicativo}{}
    Sia \( E \) un enunciato, \( A \) una formula e \( \Gamma \) un insieme di formule.
    Vale:
    \[ \Gamma, E \vdash A \iff \Gamma \vdash (E \to A) \]
\end{thmframe}

\textbf{Altre proprietà}:
\begin{itemize}
    \item  Ogni istanza di tautologia proposizionale è una verità nel Calcolo dei Predicati
\end{itemize}

\subsection{Teorema di completezza per la logica predicativa}
Come per la logica proposizionale, vogliamo dimostrare \( T\vDash A \iff T \vdash A \).

Esiste però un'altra definizione equivalente per il teorema di completezza.

\begin{defframe}{Coerenza}{}
    Una teoria \( T \) è \textbf{coerente} (o non-contraddittoria) \(\iff \neg \exists \) enunciato \( A \) t.c. \( T \vdash A \land T\vdash \neg A \)
\end{defframe}

\begin{gframe}{}
    Il Calcolo dei Predicati è coerente, ossia per nessuna formula vale \( \vdash F \land \vdash \neg F \).
\end{gframe}

\begin{defframe}{Teorema di completezza v.2}{}
    \vspace{-1em}
    \[ T \text{ coerente } \iff T \text{ ha un modello } (\in \texttt{SAT}) \]
\end{defframe}

Notiamo facilmente che \( T \) incoerente come testimoniato da \( A \) (ovvero \( T \vdash A \land T \vdash \neg A \)) implica necessariamente \( T \) insoddisfacibile.

Infatti, \( T\vdash A \implies T\vDash A \) \ e \ \( T\vdash \neg A \implies T\vDash \neg A \), e se valgono sia \( T \vDash A\) che \(T \vDash \neg A \) sappiamo che \( T \) è insoddisfacibile (\( Mod(T) = \emptyset \)).

Ci manca da dimostrare \( T \) coerente \( \implies Mod(T) \neq \emptyset\).

\begin{thmframe}{Equivalenza tra le due forme di teorema di completezza}{}
    Si ha che \( \underline{T \vDash A \iff T \vdash A}_{\color{Blue}(1)} \ \equiv \ \underline{T \text{ coerente} \iff T \text{ ha un modello } (\in \SAT)}_{\color{purple}(2)}\)
    
\end{thmframe}

\begin{proofframe}
\begin{enumerate}
    \item Assumiamo {\color{purple}(2)} e dimostriamo \( T \vDash A \implies T \vdash A \) 

    Sappiamo che \( T \vDash A \). Ci sono due opzioni:
    \begin{itemize}
        \item \( T \in \UNSAT \): \( T\vDash A \) è vera \( \forall A \), quindi \( T \) incoerente 

            \subitem(se \( \exists B \ \text{ t.c. } \ T\vdash B \ \land \ T \vdash \neg B \), possiamo dimostrare una qualsiasi affermazione \( A \) in questo modo: \( \vdash B\to(\neg B \to A) \))

            quindi \( T \vdash A \)

        \item \( T \in \texttt{SAT} \): se \( T\in \SAT \) e \( T\vDash A \), sappiamo che \( T \cup \neg A \in \UNSAT \). 
            \subitem Per {\color{purple}(2)}, quindi, \( T \cup \neg A \) è incoerente, quindi \( T \vdash A \)

            {\color{CadetBlue}\( T\cup \neg A  \) incoerente significa \( T \cup \neg A \vdash \bot\), quindi (x deduzione) \( T \vdash \neg A \to \bot \); \\
            per reductio ad absurdum ( \((\neg A \to \bot) \vdash A \)), si ha quindi \( T \vdash A \).}
    \end{itemize}

\item Assumiamo {\color{blue}(1)} e dimostriamo \( T \) coerente \(\implies T \) ha un modello

    Presumiamo che \( T \) non abbia un modello. Per definizione di conseguenza logica, abbiamo \( T\vDash \bot \). Per {\color{blue}(1)}, otteniamo \( T\vdash \bot \), ovvero \( T \) incoerente.
\end{enumerate}
\end{proofframe}

\subsection{Estensioni di teorie}
Vogliamo dimostrare coerenza \( \implies \) soddisfacibilità. Per farlo, introduciamo il concetto di \textit{estensione}.

\begin{defframe}{Estensione}{}
    Diciamo che una teoria \( T' \) \textbf{estende} una teoria \( T \) se \( T \subseteq T' \).
\end{defframe}

\begin{defframe}{Teoria sintatticamente completa}{}
        Una teoria \( T \) si dice \textbf{sintatticamente completa} se per ogni enunciato \( E \) nel linguaggio di \( T \), vale \( T \vdash E \) oppure \( T \vdash \neg E \).
\end{defframe}

\begin{lemmaframe}{Lemma di  Lindenbaum}{}
    Ogni teoria coerente (in un linguaggio numerabile) ammette un'estensione coerente e completa.

    (Sia \( T \) coerente. Allora \( \exists S\) teoria nel linguaggio di \( T \) t.c.:
\begin{itemize}
    \item \( T \subseteq S \)
    \item \(S  \) è coerente
    \item \( S \) è sintatticamente completa
\end{itemize}
    )
\end{lemmaframe}

\begin{proofframe}{}{}
Fissiamo un'enumerazione \( \{ E_1, E_2, \dots \} \) di tutti gli enunciati di \( T \).

Definiamo una successione di teorie in quessto modo:
\begin{itemize}
    \item \( S_0 = T \)
    \item \( S_{n+1} = \begin{cases}
            S_n \cup \{ E_{n+1}\} & \text{se } S_n \cup \{E_{n+1}\} \text{ coerente (ovvero } S_n \not\vdash \neg E_{n+1} \text{)} \\
            S_n  & \text{altrimenti (ovvero } S_n \vdash \neg E_{n+1} \text{)} 

    \end{cases} \)

    {\color{gray} \small nel secondo caso non serve aggiungere \( \{\neg E_{n+1}\} \) perché si ha già \( S_n \vdash \neg E_{n+1} \) (sarebbe superfluo)}
\end{itemize}
Sia \( S = \bigcup_{n\in \N} S_n \).
\begin{enumerate}
    \item \( S \) è \textbf{coerente}

        \( S \) è coerente significa che \( \not \exists E \) per cui \( \exists \{A_1, A_2, \dots, A_t\} , \{B_1, B_2, \dots, B_t\} \subseteq S\) t.c.\\ \(  A_1, A_2, \dots, A_t\vdash E\) e \(  B_1, B_2, \dots, B_t\vdash \neg E\).

        Si nota facilmente che questo è impossibile, in quanto, per costruzione, entrambi gli insiemi di enunciati apparterrebbero a un \( S_m \) per qualche \( m \) (vista la costruzione ``a catena'' di \( S \)), e si avrebbe \( S_m \vdash E \) e \( S_m \vdash \neg E \), quindi \( S_m \) incoerente (ma per costruzione, \( \forall i\ S_i \) è coerente).
        

    \item \( S \) è sintatticamente \textbf{completa}

        Scegliamo di dimostrarlo nella forma \( S\not\vdash \neg E \implies S \vdash E \)

        Sia \( E = E_{n+1} \) per un qualche \( n \). Sappiamo che \( \forall i\) e in particolare per \( n, \ S_n\not\vdash \neg E_{n+1}\). 

        Quindi, per costruzione \( S_{n+1} = S_n \cup \{E_{n+1}\} \implies S_{n+1} \vdash E_{n+1} \overset{{\color{gray}S_{n+1}\subseteq S}}{\implies}  S \vdash E_{n+1} \).
\end{enumerate}

\end{proofframe}

Se invece di \( T \) coerente avessimo ipotizzato \( T \) soddisfacibile, la conclusione sarebbe stata banale perché si sarebbe definita \( S \) facilmente come (dato \( \Aa \) modello di \( T \)) \( S = Th(\Aa) = \{E \mid \Aa \vDash E\}\), evidentemente coerente e completo.

Il teorema di completezza mostra che le due cose sono equivalenti.

Abbiamo quindi dimostrato che \( T \) coerente \( \implies \exists S \supseteq T\) coerente e completa. \\Vogliamo però \( T \) coerente \( \implies T \) soddisfacibile.

Il passo successivo è dimostrare che \( S \) è già quasi un modello.

Cerchiamo quindi un modello \( \Mm = (M, \Rr^\Mm, f_j^\Mm, c_i^\Mm) \)

Per definirlo, facciamo alcune assunzioni.

Assumiamo di lavorare con un linguaggio \( \Ll = \{R_i, f_j, c_k\} \) che contenga almeno una costante e una funzione (nota bene: se ci sono una costante e una funzione, ci sono infiniti termini chiusi).

Definiamo \( \Mm \) (detto \textbf{modello di Henkin} dei termini di \( S \)):
\begin{itemize}
    \item \( M = \{\text{termini chiusi di } \Ll \}\)
        \subitem {\color{gray}es. \( \Ll_1 = \{0, 1, +\}, \ M = \{0, 1, 0+0, 0+1, 1+0, \dots\} \)} 
    \item \( c_k^\Mm = c_k \in M \) 
        \subitem l'interpretazione della costante \( c \) è data dalla costante \( c \) stessa
        \subitem {\color{gray} es. \( \Ll_2 = \{e, *\}, M_2 = \{e, e*e, \dots\} \) - come interpretazione di \( c_0 = e \) prendo \( e\in M_2 \)}
    \item l'interpretazione di un simbolo di relazione \( \Rr \) è data dall'insieme dei termini chiusi di cui \( S \) dimostra che soddisfano la relazione - ovvero \( (\Mm_1, \dots, \Mm_n) \in \Rr^\Mm_i \iff  S \vdash \Rr_i(t_1, \dots, t_n)\)
    \item l'interpretazione di un simbolo di funzione \( f \) è l'associazione \( t_1, \dots, t_n \mapsto f(t_1, \dots, t_n) \) - \( f^\Mm_j : M^n \to M \) è t.c. \( f^\Mm_j (t_1, \dots, t_n) := f_j(t_1, \dots, t_n) \)
        \subitem {\color{gray}es. \( +^\Mm(0,1) = \underbracket{+(0,1)}_{t} \)}

\end{itemize}

Osserviamo che l'interpretazione in \( \Mm \) di un termine chiuso \( t \) coincide con il termine stesso (\( t^\Mm = t \)).

Vogliamo dimostrare \( \Mm \vDash S \). Per farlo (come spesso accade) ci è più comodo dimostrare un'affermazione più forte: \( \forall E \ \Mm \vDash E \iff S \vdash E \).

\begin{proofframe}{}
    Dimostriamo per casi (su \( E \)):
    \begin{itemize}
        \item \( E \)  è \( \neg G \)

            \subitem se \(\Mm \not \vDash E\), per ipotesi induttiva si ha \( S \not \vdash G \) e da \( S \) completa segue \( S \vdash \neg G \).

            \subitem se \( \Mm \vDash E \), allora per ipotesi induttiva \( S \vdash G \) e da \( S \) coerente segue \( S \not\vdash \neg G \)


        \item \( \Mm \vDash G \land H \) {\color{CadetBlue}\( \iff S\vdash G \land H \)}

            (\( \implies \)) {\color{CadetBlue}supponiamo \( \Mm \vDash G\land H \);}
            \subitem allora, \( \Mm \vDash G \ \land \Mm \vDash H\) 

            \subitem per ipotesi induttiva, abbiamo \( S \vdash G \ \land S \vdash H \), e usando la tautologia \( G\to (H \to (G \land H)) \) ottengo \( S\vdash G\land H \) 

            (\( \impliedby \)) {\color{CadetBlue}supponiamo \( S \vdash G \land H \);}
            \subitem per la tautologia \( G\land H \to G \), otteniamo \( S\vdash G \ \land \ S \vdash H \)

            \subitem per ipotesi induttiva, segue \( S\vDash G \ \land \ S \vDash H \), da cui \( S\vDash G \land H \)
            
        \item se \(E\) è un enunciato atomico \( R(t_1, \dots, t_k) \), abbiamo che \( \Mm \vDash R(t_1, \dots, t_n) \) per definizione \(\iff (t^\Mm_1, \dots t^\Mm_n)\in \R^\Mm \) e, per l'osservazione sui termini, \( \iff (t, \dots, t_n)\in R^\Mm \), il che per definizione equivale a \( S\vdash R(t_1, \dots, t_n) \)

        \item se \( E \) è del tipo \( \forall x F \)

            sappiamo \( \iff \forall m \in M \Mm \vDash F \tworowmatrix{x}{m}\)

            {\color{CadetBlue}e qui vale \( \Mm \vDash F \tworowmatrix{x}{m} \iff \Mm \vDash F[x/m]\)}

            \subitem per ipotesi induttiva, abbiamo che \( \forall m \in M, \ S\vdash F[x/m] \), ma non abbiamo il \( \iff \). 

            sappiamo \( S \vdash \forall x F \implies S\vdash F[x/t] \), ma non l'altro verso {\color{gray}\small (è come dire che sappiamo che per ogni numero c'è una dimostrazione, ma vogliamo che ci sia una dimostrazione per ogni numero)}
    \end{itemize}
\end{proofframe}

Possiamo definire una teoria che ci aiuta nella dimostrazione.

\begin{defframe}{Teoria con testimoni}{}
    Una \textbf{teoria con testimoni}, o \textbf{teoria di Henkin} (o ``scapegoat theory'')  soddisfa la seguente proprietà:
    \begin{itemize}
        \item \( \forall \) formula \( F \) con un'unica variabile libera \( x \), \( \exists \) un  termine chiuso \( t \) t.c.
            \[ T \vdash \exists x \neg F(x) \to \neg F(t) \]

            \subitem (\( t \) è un testimone dell'enunciato \( \exists x \neg F(x) \))
    \end{itemize}

    {\color{CadetBlue}(un testimone è un termine specifico (\( t \)) che la teoria ``nomina'' per concretizzare un'affermazione esistenziale - normalmente, se diciamo \( \exists x P(x) \), non sappiamo chi sia \( x \) per cui \( P \) vale; se siamo in una teoria con testimoni, invece, abbiamo \( \exists x P(x) \to P(t) \), sappiamo esattamente chi sia \( t \))}
\end{defframe}

Vediamo come una teoria con testimoni ci aiuta a dimostrare il caso \( \forall x F(x) \) con \( F(x) \) aperta.

\begin{pframe}
(Dimostriamo che, se \( \Mm \vDash \forall x F \) allora \(T \vdash \forall x F\))

Per assurdo, supponiamo \( \Mm \vDash \forall x F \) e \( T \not\vdash \forall x F \).

Per completezza di \( T \) vale \( T \vdash \neg E \), ovvero \( T \vdash \exists x \neg F(x) \). Dato che \( T \) è una teoria con testimoni, esiste un termine chiuso \( t \) tale che \( T \vdash \exists x \neg F(x) \to \neg F (t) \). 

Dunque \( T\vdash \neg F(t) \).

Per ipotesi induttiva, \( \Mm \vDash \neg F(t)\). Ma da \( \Mm \vDash \forall x F(x) \), e da \( \Mm \vDash \forall x F(x)\), vale, per qualsiasi termine chiuso \( \Mm \vDash F(x) \to F(t)\).

Dunque, \( \Mm \vDash F(t)\), il che contraddice \( \Mm \vDash \neg F(t) \). \qed

\end{pframe}

Se \( T \) coerente, \( T \) si può estendere a \( T^* \supseteq T\) che sia coerente e con testimoni (in un \( \Ll \) che estende \( \Ll_T \) con un insieme numerabile di costanti.

\begin{thmframe}{}{}
    Per ogni teoria \( T \) coerente esiste una teoria  \( T' \) tale che:
    \begin{itemize}
        \item \( T' \) è un'estensione di \( T \)
        \item \( T' \) è una teoria con testimoni
        \item il linguaggio di \( T' \) è numerabile ed estende quello di \( T \)
        \item \( T' \) è coerente
    \end{itemize}
    
\end{thmframe}

\begin{proofframe}{}{}
    Sia \( T \) coerente. 

    Sia \( T_0  = T \ \cup \ \{\text{istanze degli assiomi logici nel linguaggio esteso}\}\).

    Fissiamo un'enumerazione delle formule in \( \Ll \) con una variabile libera: \( F_1(x_1), F_2(x_2), \dots \)

    Sia \( B = \{b_1, b_2, b_3, \dots\} \) un insieme di nuovi simboli di costante. Fissiamone un'enumerazione \( b_{j1}, b_{j2}, \dots \), in cui \( b_{jk} \) è il primo (per indice) t.c.
    \begin{itemize}
        \item \( b_{jk} \) non appare in \( F_1(x_1), \dots, F_k(x_k) \)
        \item \( b_{jk} \) è diverso da \( b_{j1}, \dots, b_{j_{k-1}} \)
    \end{itemize}

    {\small \color{gray} quindi \( b_{j1} \) è la prima costante \( \not \in F_1\), \( b_{j2} \) la prima che non compare in \( F_2 \) e non è già stata usata (quindi \( \neq b_{j1} \)), ecc}

    Sia \( W_k \) il seguente enunciato:
    \[ \exists x_k \neg F_k(x_k) \to \neg F_k(b_{jk})\]

    Sia \( T_n = T_0 \cup \{W_1, \dots, W_n\} \), e sia \( T_{\infty} = \bigcup_n T_n \).

\textbf{claim}: \( T^* = \bigcup_{n\in \N} T \) è di Henkin, coerente ed estende \( T \).

{\color{CadetBlue} di Henkin: \( \forall n \exists t = b_{j_n} \) t.c. \( T^* \ni \exists x_n \neg F_n(x_n) \to \neg F_n (b_{j_n})\) è vero per costruzione}

    \begin{itemize}
        \item Dimostriamo che \( T_\infty \) è coerente (basta dimostrare che \( \forall n \ T_n \) coerente)
    \end{itemize}

    per induzione:

    \begin{itemize}
        \item \textbf{C.B.}: \( T_0 \) è coerente
            \subitem {\color{gray} ``banale'', \( T \) coerente e abbiamo aggiunto a \( T \) solo assiomi}

            \subitem {\color{gray}\( T_0 \vdash \bot \implies T \cup \underset{\text{assiomi}}{A = \{A_1, \dots, A_t\}} \vdash \bot \implies T \vdash A \to \bot\) - visto che \( A \) assiomi, \( T \vdash  A \) e per MP, \( T\vdash \bot \) - ma questo è impossibile perché \( T \) coerente)}

        \item \textbf{P.I.}: assumiamo \( T_{n-1} \) coerente

            per assurdo, sia \( T_n \) incoerente;

            allora, si ha \( T_n \vdash \bot \), e \( \bot \to B \implies T_n \vdash B \ \forall B \); quindi \( T_n \vdash \neg W_n \);

            ma \( T_n = T_{n-1} \cup \{W_n\} \), quindi (per deduzione) \( T_{n-1} \vdash W_n \to \neg W_n \);

            {\color{gray}\small \( \neg W_n \) è una negazione di un'implicazione (quindi verifica la premessa \( \exists x_n \neg F_n (x_n) \) e falsifica la conseguenza \( \neg F_n (b_{j_n}) \))} quindi \( T_{n-1} \vdash \exists x_n \neg F)n (x_n)\) e \( T_{n-1} \vdash F_n (b_{j_n})  \).

        Per costruzione, sappiamo che \( T_{n-1} = T_0 \) {\color{gray}\small \( (= T \ \cup\ \) assiomi) } \( \cup \ \{W_1, \dots, W_{n-1}\} \); abbiamo scelto \( b_{j_n} \) e quindi sappiamo che:
        \begin{itemize}
            \item esso non compare in \( W_1, \dots, W_{n-1} \);
            \item per definizione, non compare in \( T \);
        \end{itemize}
            Dovrà quindi far parte degli assiomi logici.

            Notiamo che quindi, sostituendo \( b_{j_n} \) con una nuova variabile, la formula restante rimarrà un assioma logico.

            Sia quindi \( y \) una variabile che non compare nella dimostrazione \( \delta \) (di \( F_n(b_{j_n}) \)). 

            \textbf{claim}: \( \delta^y = \delta [b_{j_n}/y] = (D^y_1, \dots, D^y_n) \) è ancora una dimostrazione.

            Infatti:
            \begin{itemize}
                \item gli assiomi rimangono tali (o non dicono niente su \( b_{j_n} \)) o dicono cose sempre vere, quindi sostituendo non cambia nulla
                \item le ipotesi \( T_{n-1}, W_1, \dots, W_n \) non cambiano, in quanto \( \not \ni b_{j_n} \)
                \item il Modus Ponens è preservato
                \item la Generalizzazione non viene mai applicata su \( b_{j_n} \) (vorrebbe dire che una formula \( \forall y H(y) \) sarebbe stata ottenuta da una formula \( H(b_{j_n}) \) (ricordiamo che \( b_{j_n} \) è una costante specifica), il che è impossibile)
            \end{itemize}

            Ora - se è vero \( T_{n-1} \vdash F_n(y) \), per Generalizzazione si ha anche \( T_{n-1} \vdash \forall y F_n(y) \). Ma abbiamo anche \( T_{n-1} \vdash \exists x \neg F_n(x) \). Le due cose sono chiaramente contraddittorie, quindi \( T_{n-1} \) è incoerente. \qed
    \end{itemize}
\end{proofframe}

Quindi, possiamo formalizzare i seguenti teoremi:

\begin{thmframe}{}{}
    Sia \( T \) una teoria con testimoni e coerente in un linguaggio numerabile. Allora, \( T \) ha un modello numerabile.
\end{thmframe}

\begin{thmframe}{Esistenza del modello}{}
    Ogni teoria coerente (in un linguaggio numerabile) ha un modello numerabile.
\end{thmframe}

\begin{proofframe}
    Partiamo da \( T \) coerente \  {\color{CadetBlue}(in \( \Ll) \)}
    \begin{itemize}
        \item \( \overset{\text{Henkin}}{\implies} \ T^* \supseteq T \) coerente con testimoni \  {\color{CadetBlue}(in \( \Ll^* \text{ numerabile } \supseteq \Ll) \)}

        \item \( \overset{\text{Lindenbaum}}{\implies} \ \hat T \supseteq T^*\) coerente e completa con testimoni \ {\color{CadetBlue}(in \( \Ll^*)\)
            \subitem (la proprietà di essere con testimoni è preservata perché il lemma di Lindenbaum non cambia il linguaggio)}
        \item \( \implies \ \Mm_{\hat T} \vDash  T \)  (il modello dei termini di \( \hat T \) è un modello numerabile di \( T \))

    \end{itemize}
    
\end{proofframe}

\textbf{nota bene ! logica con identità}

La dimostrazione sopra descritta si limita alla logica di primo ordine senza identità.

Per il modello sopra definito, \( \Mm \vDash (t_1 = t_2) \iff \) \( t \) ed \( s \) sono esattamente lo stesso termine {\color{gray}(quindi, per esempio, \( (1+1) \neq 2 \))}.

Per risolvere questo problema, basta quozientare sulla seguente relazione:
\[ t \sim s \iff T\vdash(t = s) \]

\begin{itemize}
    \item notiamo che \( \sim \) è una relazione di equivalenza
\end{itemize}

Definiamo quindi il modello dei termini \( \Mm/\sim \) in questo modo:
\begin{itemize}
    \item il dominio è \( M/\sim = \{[t]_\sim \mid t \text{ termine chiuso}\}\)
    \item \( c^{\Mm/\sim} = [c]_\sim\)
    \item \( f^{\Mm/\sim}([t_1]_{\sim}, \dots, [t_n]_{\sim}) = [f(t_1, \dots, t_n)]_{\sim} \)
    \item \(([t_1]_{\sim}, \dots, [t_n]_{\sim}) \in R^{\Mm/\sim}\) se e solo se \(T \vdash R(t_1, \dots, t_n)\)
\end{itemize}

La dimostrazione \( \Mm/\sim \vDash E \iff T\vdash E \) procede esattamente come quella di \( \Mm \). Inoltre, se \( \Mm \) ha cardinalità numerabile, anche \( \Mm/\sim \) ha cardinalità numerabile.

\section{Teorema di compattezza}
Il teorema di compattezza si può riformulare in diversi modi:

\begin{thmframe}{Teorema di compattezza, versioni equivalenti}{}

    \begin{itemize}
        \item Un insieme di enunciati è coerente se e solo se ogni suo sottinsieme finito è coerente.

        \item Un insieme di enunciati ha un modello se e soltanto se ogni suo sottoinsieme finito ha un modello.

        \item \( T\vDash E \) se e solo se esiste un sottoinsieme finito \( T_0 \subseteq T \) tale che \( T_0 \vDash E \).
    \end{itemize}
    
\end{thmframe}

\subsection{Applicazione: (non) assiomatizzabilità}

Data una proprietà \( P \) di strutture, è utile chiedersi se possa essere espressa da enunciati del primo ordine, ovvero se esista un insieme di enunciati \( T \) che soddisfa, per ogni struttura \( \Aa \), la seguente equivalenza:
\[ \Aa \vDash T \iff \Aa \text{ ha la proprietà }  P \]

Se un tale \( T \) esiste, diciamo che \textbf{assiomatizza} o \textit{definisce} la proprietà \( P \).

Ha ancora più senso chiedersi, nello specifico, data una classe di strutture \( \Cc \) e un linguaggio predicativo \( \Ll \), se esista una teoria in \(\Ll \) tale che la proprietà s opra sia soddisfatta.

Se esiste una teoria \( T \) che assiomatizza una proprietà \( P \), ci si può chiedere se esiste un \textit{insieme finito di enunciati} che assiomatizza \( P \). Questo è equivalente a chiedersi se esiste un singolo enunciato \( E \) {\color{gray} (l'AND tra tutti gli enunciati)} tale che, per ogni struttura \( \Aa \) nella classe \( \Cc \),
\[ A \vDash E \iff \Aa \text{ ha la proprietà } P\]


In questo caso, diciamo che \( P \) è \textbf{finitamente assiomatizzabile} relativamente alla classe \( \Cc \).

\textbf{Esempio 1: finitezza}

\begin{itemize}
    \item \( P = \) ``avere dominio finito'';
    \item \( \Cc =  \) tutte le strutture;
\end{itemize}


Partiamo da \( P_n = \) ``avere dominio di cardinalità \( \geq n \)''.

Possiamo assiomatizzare questa proposizione con un linguaggio \( \Ll \) ``vuoto'' (senza relazioni specifiche) in questo modo:
\[ 
    \exists x_1, \dots, x_n \left( \ \bigwedge_{i \neq j, \ 1\leq i\leq n} \neg (x_i = x_j)\ \right)
\]


{\color{CadetBlue}Possiamo assiomatizzare anche la proprietà ``avere dominio di cardinalità \( n \)'' in questo modo:
\[  
    \exists x_1, \dots, x_n \left( \ \bigwedge_{i \neq j, \ 1\leq i\leq n} \neg (x_i = x_j) \land \forall y \left( \bigvee_{i=1}^n (y = x_i)\right)\ \right)
\]
}

\begin{propframe}{Assiomatizzazione di ``avere un dominio finito / infinito''}{}
    La proprietà ``avere dominio infinito'' è assiomatizzabile ma non finitamente assiomatizzabile.

    La proprietà ``avere dominio finito'' non è assiomatizzabile.
\end{propframe}

\begin{pframe}
Consideriamo \( T = \{P_n \mid n \in \N\} \) (``avere dominio di cardinalità almeno \( n \)'' per ogni \( n \)). La teoria \( T \) assiomatizza ``avere un dominio infinito'' {\color{gray}\small (se si ha dominio almeno \( n \) per ogni \( n \))}

Sia per assurdo \( F \) una teoria che assiomatizza \( P = \) ``avere dominio finito''.

Consideriamo \( F \cup T \). \( F\cup T \) non può avere modelli (in quanto parla di essere finito e infinito allo stesso tempo).

Se ne prendo un qualsiasi pezzo finito \( T_0 \subseteq F \cup T \), noto però che esso ha un modello (in quanto descrive, ``alla peggio'', l'avere dominio finito (da \( F \)) e l'avere almeno \( n \) elementi (da \( T \))).

Visto che \( T_0 \) ha un modello, per compattezza tutta la teoria dovrebbe avere un modello \( (\texttt{FINSAT}\implies \texttt{SAT}) \), il che è impossibile. \qed

Vediamo anche che è impossibile che ``avere dominio infinito'' sia \textit{finitamente} assiomatizzabile.

Infatti, se esistesse \( S \) finita t.c. \( \Aa \vDash S \iff \Aa  \) ha dominio infinito, avremmo che \( \neg S \) assiomatizzerebbe ``avere dominio finito'' (impossibile). \qed
\end{pframe}

\begin{lemmaframe}{}{}
    Sia \( P \) assiomatizzabile. Se \( \neg P \) non è assiomatizzabile, allora \( P \) non è finitamente assiomatizzabile.

    Per contrapposizione, se \( P, \neg P \) sono assiomatizzabili, allora P è finitamente assiomatizzabile.
\end{lemmaframe}

\begin{lemmaframe}{}{}
    Se \( P \) è assiomatizzabile da \( T \) e \( P \) è finitamente assiomatizzabile, allora \( \exists T_0 \subseteq T \) che assiomatizza \( P \).
\end{lemmaframe}

\begin{pframe}
    Sia $\phi$ l'enunciato (o la congiunzione finita di enunciati) che assiomatizza finitamente $P$.
    Quindi, per ogni struttura $\Aa$:
    \[ \Aa \in P \iff \Aa \vDash \phi \]
    Poiché per ipotesi $T$ assiomatizza $P$, ogni modello di $T$ deve avere la proprietà $P$, e quindi deve soddisfare $\phi$:
    \[ T \vDash \phi \]
    Per il \textbf{Teorema di Compattezza}, se $T\vDash \phi$, allora allora esiste un sottoinsieme finito $T_0 \subseteq T$ tale che $T_0 \vDash \phi$.

    $T_0$ assiomatizza $P$, cioè $\Aa \vDash T_0 \iff \Aa \in P$:
    \begin{itemize}
        \item[($\Leftarrow$)] Se $\Aa \in P$, allora $\Aa \vDash T$ (perché $T$ assiomatizza $P$). Poiché $T_0 \subseteq T$, ne segue che $\Aa \vDash T_0$.
        \item[($\Rightarrow$)] Se $\Aa \vDash T_0$, dato che abbiamo stabilito $T_0 \vDash \phi$, allora $\Aa \vDash \phi$. Poiché $\phi$ assiomatizza $P$, allora $\Aa \in P$.
    \end{itemize}
    Dunque $P$ è assiomatizzata dal sottoinsieme finito $T_0$ di $T$.
\end{pframe}

\begin{lemmaframe}{}{}
    Se \( T \) ha modelli finiti arbitrariamente grandi (per ogni \( n \) c'è un modello con almeno \( n \) elementi), allora \( T \) ha anche modelli infiniti.
\end{lemmaframe}

\begin{gframe}{(Non) assiomatizzazione di ``essere un grafo connesso``}
    Consideriamo i grafi, con linguaggio \( \Ll = \{E(x,y)\} \), e la proprietà \( P = \) ``essere un grafo connesso''.

    Possiamo scrivere la proprietà \( D_n = \) ``essere a distanza \( \geq n \)'' in questo modo:
    \[ \neg (\exists x_1, \dots, x_n \left(\bigwedge_{i \neq j}\neg (x_i = x_j) \land E(c, x_1)\land E(x_1, x_2) \land \dots \land E(x_n, d)\right))\]

    Supponiamo che \( P \) sia assiomatizzabile da una teoria \( C \).

    Consideriamo \( C \cup \{D_n \mid n\geq 0\} \) - questa teoria non può avere un modello.

    Come prima, consideriamo un pezzo finito \( T_0 \subseteq C \cup \{D_n \mid n\geq 0\} \). 

    Come prima, questo sottoinsieme ha un modello (un grafo connesso con vertici a distanza \( > \) del massimo \( n \)). Come prima, avremmo \(\texttt{FINSAT} \implies \texttt{SAT} \), e per questo si ha che \( P \) non è assiomatizzabile. \qed
\end{gframe}

\subsection{Modelli non standard dell'aritmetica}

Dato \( \Nn = (\N, 0, 1, +, *, \leq ) \), possiamo definire la sua teoria \( T = Th(\Nn) = \{E \mid \N \vDash E\} \).

Sia \( \Aa \vDash Th(\Nn) \). Quanto assomiglia \( \Aa \) ad \( \N \)?

Noi vorremmo \( \Aa \iso \Nn \), ma in realtà esistono molti modelli di \( \Nn \) molto differenti dai numeri naturali che conosciamo.

Consideriamo per esempio una nuova costante \( c \) e la teoria:
\[ T \cup \{A_n \mid n\in \N\} \]
con \( A_n = \underbracket{1 + \dots + 1}_{n} < c \).

Un sottooinsieme qualsiasi \( T_0 \subseteq T \cup \{A_n \mid n\in \N\} \) ha un modello - basta dare un'interpretazione alla costante \( c \).

Per esempio, \( \Aa = (\N, +^\Nn, x^\Nn, 0^\Nn, 1^\Nn, c^\Aa = max(a_1, \dots, a_k)+1)\) è un modello di \( T_0 \).

Per compattezza, quindi, \(T\cup \{A_n \mid n \in \N\}  \) ha un modello.

Ma come interpretiamo \( c^\Aa \) in questo modello? Deve esserci un unico \( c \) tale che, \( \forall n, \underbracket{1 + \dots + 1}_{n} <^\Aa c^\Aa  \).

Deve quindi esserci un \( c \) maggior di tutti gli elementi di \( \N \). 

Questo modello è molto diverso da \( \N \).\( \Aa \) è quello che si dice \textbf{modello non-standard} dell'aritmetica, e \( c^\Aa \) è un \textit{naturale non-standard}.

Inizia infatti con \( \N \), ma contiene almeno un elemento maggiore di tutti i numeri standard. Inoltre, se \( a\in \Aa \)  è un numero non-standard, allora anche il suo predecessore è un numero non-standard. Un elemento non-standard ha quindi infiniti predecessori e successori, nessuno dei quali può essere standard. 

Intorno a \( c^\Aa \) si sviluppa quindi una copia isomorfa a \( \Z \).

Si esclude quindi che si possa definire una teoria \( T \) che assiomatizzi \( Th(\Nn) \) in modo che valga, come per DLO< che tutti i modelli numerabili di \( T \) sono isomorfi. Resta aperta però la possibilità di trovare un insieme di assiomi \( T \) con insieme di teoremi computabilmente enumerabili che coincida con la ``vera'' Teoria dei Numeri \( Th(\Nn) \).Una tale teoria sarebbe completa e dunque decidibile e fornirebbe un algoritmo per decidere automaticamente se un enunciato \( E \) è un teorema della Teoria dei Numeri o no.

\subsection*{Vademecum su limiti espressivi e cardinalità}
\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|l|c|p{8cm}|}
\hline
\textit{proprietà del Modello} $M$ & \textit{assiom.?} & \textit{causa} \\ \hline
Essere finito & NO & \textbf{Compattezza.} Se $T$ ha modelli finiti arbitrariamente grandi, ne ha anche uno infinito. \\ \hline
Essere numerabile (esattamente $\aleph_0$) & NO & \textbf{LS Up.} Se ha un modello infinito numerabile, ne ha anche uno più che numerabile. \\ \hline
Essere più che numerabile ($>\aleph_0$) & NO & \textbf{LS Down.} Se ha un modello più che numerabile (in ling. numerabile), ne ha anche uno numerabile. \\ \hline
Essere ben ordinato & NO & \textbf{Compattezza.} I modelli non-standard contengono sempre copie di $\mathbb{Z}$ o parti dense. \\ \hline
\end{tabular}
\caption{Proprietà NON Assiomatizzabili (Limiti Espressivi)}
\end{table}

\begin{table}[h!]
\centering
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|l|c|p{8cm}|}
\hline
\textit{proprietà del Modello} $M$ & \textit{assiom.?} & \textit{come ?} \\ \hline
Avere almeno $n$ elementi & SÌ & $\exists x_1 \dots x_n (\bigwedge_{i \neq j} x_i \neq x_j)$ \\ \hline
Avere al più $n$ elementi & SÌ & $\exists x_1 \dots x_n \forall y (\bigvee_{i=1}^n y=x_i)$ \\ \hline
Avere esattamente $n$ elementi & SÌ & Congiunzione di ``almeno $n$'' e ``al più $n$''. \\ \hline
Essere infinito & SÌ & Con una teoria infinita $T_{inf} = \{ \text{``almeno } n \text{''} \mid n \in \mathbb{N} \}$. \\ \hline
\end{tabular}
\caption{Proprietà Assiomatizzabili in Logica del Primo Ordine}
\end{table}


\chapter{I teoremi di Gödel}
\section{Funzioni calcolabili (algoritmiche)}
Esistono diverse definizioni di algoritmo. Le principali ci vengono date da Gödel, Herbrand e Kleene (in chiave matematica), da Turing (attraverso le TM), e da Church (nel \( \lambda \)-calcolo).

\begin{defframe}{Funzioni calcolabili}{}
    La classe \( \Cc \) delle funzioni parziali calcolabili è la minima classe di funzioni del tipo \( \N^k \to \N \) (con \( k\in N \)) t.c.:
    \begin{itemize}
        \item \( +, * \in \Cc \)
        \item \( i(x, y) = \begin{cases}
                1 & \text{se } x = y\\
                0 & \text{se } x \neq y
        \end{cases} \)
    \item \( \prod_i^n (x_1, \dots, x_n) = x_i \) \ {\color{CadetBlue}(proiezione)}
    \end{itemize}
    e \( \Cc \) chiusa sotto composizione -
    date \( \theta_1, \dots, \theta_n: \N^k \to \N, \psi:\N^m \to \N \), la composta \( \phi \) è definita come segue:
    \[ \phi(x_1, \dots, x_n) = \psi(\theta_1(x_1, \dots, x_n), \dots, \theta_n(x_1, \dots, x_k)) \]

    \( \Cc \) è chiusa anche sotto \textit{minimalizzazione}:
    data \( g(\vec{x}, y)\), la funzione \( h(\vec{x}) \) è definita come \( h(\vec{x}) = min \ z\) t.c. 
\begin{itemize}
    \item i valori \( g(\vec{x}, 0 ), g(\vec{x}, 1), \dots, g(\vec{x}, z-1)\) sono definiti e \( \neq 0 \)
    \item \(g(\vec{x}, z ) = 0 \)
    \item (se un tale \( z \) non esiste, la funzione non è definita)
\end{itemize}

\end{defframe}

\begin{propframe}{}{}
    Si ha che \( f\in \Cc \implies f  \) calcolabile.
\end{propframe}

\begin{itemize}
    \item Nella composizione di funzioni $h(g_1, \dots, g_m)$:
    \begin{itemize}
        \item Se tutte le $g_i$ e $h$ fossero totali, si applicherebbero semplicemente le $g_i$ e poi $h$ sul risultato.
        \item Se una delle $g_i$ è indefinita, il calcolo procede comunque secondo la logica algoritmica: il programma semplicemente non termina (non si arriva mai ad applicare $h$).
            \subitem (anche se il risultato è indefinito, il processo rimane algoritmico).
    \end{itemize}
\end{itemize}

Per calcolare una composizione come $h(g_1(\vec{x}), g_2(\vec{x}), \dots)$, è necessario stabilire un ordine di esecuzione:
\begin{itemize}
    \item Non si possono far partire le funzioni in parallelo; devono essere eseguite in ordine sequenziale.
    \subitem se si procedesse in parallelo, si potrebbe trovare un risultato per $g_2$ mentre $g_1$ sta ancora calcolando (o è in loop infinito).
    \item Per definizione, se un argomento è indefinito, l'intera composizione deve esserlo. Procedendo in ordine, se ci si ``ferma'' su $g_1$, il calcolo si arresta correttamente senza produrre risultati parziali o errati basati sugli altri argomenti.
\end{itemize}

(Anche \( g(\vec{x}, y) \) è algoritmica perché lo è \( h(\vec{x}) \))

\begin{propframe}{Calcolabilità}{}
    

\begin{itemize}
    \item Una funzione $\varphi: \mathbb{N}^k \rightarrow \mathbb{N}$ è calcolabile $\iff \varphi \in \mathcal{C}$.
    \item  $R \subseteq \mathbb{N}^k$ si dice calcolabile se la sua \textbf{funzione caratteristica} $\chi_R$ è calcolabile.
    \subitem 
    \(
    \chi_R(\vec{x}) = \begin{cases} 
    1 & \text{se } \vec{x} \in R \\ 
    0 & \text{se } \vec{x} \notin R 
    \end{cases}
    \)
\end{itemize}
\end{propframe}

\section{Teorema di Definibilità}
\begin{defframe}{Definibilità}{}
    Diciamo che \( \varphi \) è \textbf{rappresentabile} in \( \Nn \) da una formula \( F(x_1, \dots, x_k, y) \) se per ogni tupla di numeri naturali \((a_1, \dots, a_k, b) \subseteq \mathbb{N}^{k+1}\), vale l'equivalenza:
    \[
        \varphi(a_1, \dots, a_k) = b \iff \Nn \models F \left[\ass{x_1, \dots, x_k, y}{a_1, \dots, a_k, b}\right]
    \]
i.e. se le k+1-ple \( (a_1, \dots, a_k, b) \) appartententi al grafo di \( \varphi \) sono esattamente quelle che soddisfano in \( \Nn \) la formula \( F(x_1, \dots, x_k, y) \) assegnando \( a_i \) a \( x_i \) e \( b \) a \( y \).

{\color{Gray}\small(la formula è vera nel modello standard \(\mathcal{N}\) se e solo se la funzione, calcolata sugli input \(a_i\), restituisce \(b\)).}

Nel linguaggio dell'aritmetica, ogni numero naturale \( n\in \N \) ha un nome canonico (\textbf{numerale}) costituito dalla somma di \( n \) volte la costante \( 1 \).

Quindi, vale che:
\[  \Nn \models F \left[\ass{x_1, \dots, x_k, y}{a_1, \dots, a_k, b}\right] \iff \Nn \vDash F(\bar{a_1}, \dots, \bar{a_k}, \bar{b})\]
\end{defframe}

\begin{thmframe}{Teorema di Definibilità}{}
    Le funzioni calcolabili sono definibili in \( \Nn \).
\end{thmframe}

\begin{proofframe}[title=per induzione]
    \begin{itemize}
        \item \textbf{C.B.}: le funzioni di base sono definibili in \( \Nn \)

            \subitem L'addizione è definita dalla formula \( F(x, y, z) := ((x + y) = z) \), la moltiplicazione dalla formula \( G(x, y, z) := ((x \times y) = z) \), la proiezione \( \pi_{i}^{n}(x_1, \dots, x_n) = x_i \) (dove \( i \in [1, n] \)) è definibile dalla formula \( H(x_1, \dots, x_n, z) := (x_1 = x_1 \land \dots \wedge x_i = z \wedge \dots \wedge x_n = x_n) \), la funzione caratteristica dell'uguaglianza dalla formula \( I(x, y, z) := (x = y \wedge z = 1) \lor (x \neq y \wedge z = 0) \). \hfill \(\square\)

        \item \textbf{chiusura per composizione}: le funzioni definibili in \( \Nn \) sono chiuse per composizione

Siano:
\begin{align*}
    H_1(x_1, \dots, x_k, y_1) & \quad \text{che rappresenta } \vartheta_1 \\
    H_2(x_1, \dots, x_k, y_2) & \quad \text{che rappresenta } \vartheta_2 \\
    \vdots & \\
    H_m(x_1, \dots, x_k, y_m) & \quad \text{che rappresenta } \vartheta_m
\end{align*}

E sia:
\[
G(y_1, \dots, y_m, z) \quad \text{che rappresenta } \Psi
\]

Voglio una formula $F(x_1, \dots, x_k, w)$ che rappresenti la funzione composta $\Psi(\vartheta_1, \dots, \vartheta_m)$.

Quand'è che \((x_1, \dots, x_k, w) \in \text{grafico composta}(\Psi, \vartheta_1, \dots, \vartheta_m)$? Se $W$ è il valore di $\Psi$ con argomenti = $m$ valori di $\vartheta_1, \dots, \vartheta_m$ applicate a $(x_1, \dots, x_k)\).

La formula è:
\[
\exists y_1 \dots y_m \quad (\text{se esistono gli } m \text{ valori intermedi})
\]
tale che:
\[
H_1(x_1 \dots x_k, y_1) \land H_2(x_1 \dots x_k, y_2) \land \dots \land H_m(x_1 \dots x_k, y_m)
\]
\[
\land \quad G(y_1, \dots, y_m, W) \quad (\text{valore } G(y_1 \dots y_m))
\]

\textit{NB:} Questo finisce nel grafico della composta se \(\exists y_1 \dots\) (se le intermedie sono indefinite, anche la composta lo è).

Si vede che questa formula è soddisfatta $\iff$ l'elemento appartiene al grafico della composta.
        \subitem siano 
        
        \item \textbf{chiusura per minimo}: le funzioni definibili in \( \Nn \) sono chiuse per minimo

Sia \(H(x_1, \dots, x_k, y, z)\) una formula che rappresenta \(\vartheta(x_1, \dots, x_k, y)\).

Voglio \(G\) con variabili \((x_1, \dots, x_k, S)\) dove \(S\) è il minimo tale che:
\[
\vartheta(x_1, \dots, x_k, S) \downarrow = 0 \quad
\land \quad \forall w \ (0 \le w < S, \ \vartheta(x_1, \dots, x_k, w) \downarrow \neq 0)
\]

La formula risultante è:
\[
H(x_1, \dots, x_k, S, 0) \land \forall w (w < S \to \exists z (H(x_1, \dots, x_k, w, z) \land z \neq 0))
\]
    \end{itemize}
\end{proofframe}

\begin{defframe}{Calcolabilità e rappresentabilità di una relazione}{}
    Una relazione \( R \subseteq N^n \) è calcolabile se e solo se la sua funzione caratteristica è calcolabile.

    Una relazione \( R \) è rappresentabile in \( \Nn \) se e solo se \( \exists F(x_1, \dots, x_k) \) t.c. \( \forall n_1, \dots, n_k \in \N\):
    \begin{align*}
        (n_1, \dots, n_k) \in R &\implies \Nn \vDash F(\bar{n_1}, \dots, \bar{n_k}) \\
        (n_1, \dots, n_k) \not\in R &\implies \Nn \vDash \neg F(\bar{n_1}, \dots, \bar{n_k})
    \end{align*}
\end{defframe}
\begin{thmframe}{Rappresentabilità di relazioni}{}
     Tutte le relazioni calcolabili sono rappresentabili in \( \Nn \)
\end{thmframe}
\begin{pframe}
    \( R \) è calcolabile se e solo se \( \chi_R \in \Cc \).

    Sia \( F(x_1, \dots, x_k, y) \) che rappresenta \( \chi_R \).

    Questo significa che \( \chi_R(n_1, \dots, n_k)=b \iff \Nn \vDash F(\bar{n_1}, \dots, \bar{n_k}, \bar{b}) \). Abbiamo che \( b\in \{0,1\} \).

    I vettori che appartengono a \( R \) sono quelli che danno \( 1 \) (per come definiamo \( \chi_R \)), quindi \( F(x_1, \dots, x_k, 1)\) rappresenta \( R \).

    Ovvero, presi \((n_1, \dots, n_k) \in R, \ \ \chi_R(n_1, \dots, n_k) = 1  \implies \mathcal{N} \models F(\bar{n}_1, \dots, \bar{n}_k, 1) \)

Se invece $(n_1, \dots, n_k) \notin R, \ \ \chi_R(n_1, \dots, n_k) = 0 \implies \mathcal{N} \models F(\bar{n}_1, \dots, \bar{n}_k, 0)  \implies \mathcal{N} \models \neg F(\bar{n}_1, \dots, \bar{n}_k, 1)$

\begin{gframe}{}
L'implicazione finale vale perché:
\begin{itemize}
    \item \(\mathcal{N} \models \neg(0=1)\)

    \item \(\mathcal{N} \models \text{``}F \text{ è funzionale''}\)
    \subitem (dato che \(F\) rappresenta una funzione, non ci possono essere 2 valori diversi per cui sia vera sullo stesso parametro)
\end{itemize}

\end{gframe}
\end{pframe}


\textbf{Osservazione}: notiamo che tutte le funzioni calcolabili hanno una simile struttuta sintattica: sono formate da quantificatori esistenziali seguiti da una formula in cui non compaiono quantificatori o essi appaiono solo "limitati" ( es. \( \forall x (x\leq 7 \to \dots) \)) - queste formule vengono dette \( \sum_1^0 \).

\section{I numeri di Gödel}
{\color{gray} \small Vogliamo mostrare che \( Th(\Nn) \) non è calcolabile mostrando che non è rappresentabile in \( \Nn \).}

Funzioni e relazioni calcolabili hanno come argomenti numeri naturali. Ci serve quindi poter codificare funzioni e relazioni su altri tipi di oggetti.

Gödel inventa una codifica \( code: \{\text{enunciati aritmetici}\} \to \N \) tale che:
\begin{itemize}
    \item ad ogni simbolo di base del linguaggio (parentesi, connettivi, variabili, simboli di funzione/relazione, costanti) viene associato un \textbf{intero positivo dispari}
    \item ogni formula ben formata è una sequenza \( u_0, u_1, \dots, u_n \) di simboli di base, che viene codificata in questo modo:
        \subitem \( code(u_0, u_1, \dots, u_n) = 2^{code(u_0)} \cdot 3^{code(u_1)} \cdot \ldots \cdot p_n^{code(u_n)} \)
    \item ogni derivazione è una sequenza \( e_0, e_1, \dots, e_n \) di formule, che viene codificata in questo modo:
        \subitem \( code(e_0, e_1, \dots, e_n) = 2^{code(e_0)} \cdot 3^{code(e_1)} \cdot \ldots \cdot p_n^{code(e_n)} \)
\end{itemize}

La funzione \( code \) è iniettiva e permette di distinguere algoritmicamente tra codici di simboli di base (pari), ``formule'' (pari con primo esponene dispari) e ``derivazioni'' (pari con primo esponente pari).

Quando si parla dell'esprimibilità di un insieme di enunciati in una teoria, si intende l'esprimibilità dell'insieme dei codici numerici enunciati.

Ci chiediamo quindi se \( \{cod(E) \mid \Nn \vDash E\} \) sia rappresentabile in \( \Nn \) {\color{gray}\small (non lo è)}.

\section{Indecidibilità algoritmica dell'aritmetica (Tarski)}

\begin{thmframe}{Teorema di indefinibilità di Tarski}{}
\textit{La verità aritmetica non può essere definita all'interno dell'aritmetica.}

(L'insieme delle verità aritmetiche \( Th(\Nn) = \{E \mid \Nn \vDash E\} \) non è rappresentabile in \( \Nn \))
\end{thmframe}

Supponiamo per assurdo che \( Th(\Nn) \) sia rappresentabile.
Si tratta di un insieme, quindi è descritto da una formula con una variabile libera.

Sia \( T(x) \) la formula che lo rappresenta.
\begin{itemize}
    \item \( E \in Th(\Nn) \implies \Nn \vDash V(\overline{code(E)})\)
    \item \( E \not\in Th(\Nn) \implies \Nn \vDash \neg V(\overline{code(E)})\)
\end{itemize}

Introduciamo una nuova funzione \( \delta : \N \to \N \).
Dato \( p\in \N \), \( \delta \) controlla se \( p \) è il codice numerico di una formula \( A(x) \) una variabile libera. Se lo è, \( \delta(p) =  \) codice di \( A(x/\bar{p}) \).

{\color{CadetBlue}(dato \( p\), controllo se codifica una FML \( A(x) \) - se sì, scrivo \( A(p) \) (metto il numerale \( p \) al posto della variabile {\small(quindi do alla formula il suo stesso codice)}), codifico la nuova stringa e restituisco il suo codice numerico \( q \))}

\( \delta \) è evidentemente calcolabile (uso la tesi di Church-Turing {\color{gray} - ogni funzione descrivibile tramite un algoritmo è calcolabile da una TM - } per non doverlo dimostrare esplicitamente). In quanto calcolabile, \( \delta\in\Cc \), e quindi \( \delta \) rappresentabile.

Quindi, sia \( D(x, y) \) una formula che rappresenta \( \delta \) in \( \Nn \), ovvero tale che:
\[ \delta(a) = b \iff \Nn \vDash D(\bar{a}, \bar{b})\]

Consideriamo la formula
\[ \forall y (D(x, y)\to \neg V(y)) \]
(che dichiara ``per ogni \( y \) valore di \( \delta(x) \) {\color{gray}\small(quindi formula \( A(y/\bar{x}) \) in cui \( x = code(A)\))}, \( y \) non è un enunciato vero in \( \Nn \))

Questa formula è una formula con una variabile libera \( x \) (chiamiamola \( A(x) \)). (In quanto tale può essere codificata). 

Sia \( p \) il codice di \( A(x) \).

Consideriamo \( A(x/\bar{p}) \), ovvero
\[ \forall y (D(\bar{p}, y)\to \neg V(y)) \]
(che dichiara che ogni \( y \) valore di \( \delta(p)\) non è un enunciato vero in \(\Nn \))

Sia \( q \) il suo codice (quindi \( \delta(p) = q  \)).

Notiamo subito che la formula genera una contraddizione: la formula dichiara che ogni numero che sia \( = \delta(p) \) non è vero in \( \Nn \), ma essa stessa è uno di quei numeri (quindi sta dichiarando di ``mentire'' (di non essere vera)).

Dimostriamolo formalmente, ovvero che l'ipotesi che la verità esprimibile porti alla contraddizione \( \Nn \vDash V(q) \land \Nn \vDash \neg V(q) \).

Dato che la formula \( D\) definisce la funzione \( \delta \) in \( \N \), abbiamo che
\[ \N \vDash D(p, q) \]

Dimostriamo \( \N \vDash \neg V(q) \):
\begin{itemize}
    \item \textbf{caso 1}: \( \N \not\vDash A(p) \) 
        \subitem \( A(p) \) non è una verità in \( \N \), dunque \( code(A(p)) = q \not\in Th(\N) \), dunque per ipotesi \( \N \vDash \neg V(q) \)
    \item \textbf{caso 2}: \( \N \vDash A(p) \) 
        \subitem se \( A(p) \) è vero, è vero per \( y = q \) \ {\color{gray}\small(\( \N \vDash D(p, q)\to \neg V(q) \))},\ \  quindi, dato che \( \N \vDash D(p, q) \) otteniamo \( \N \vDash \neg V(q) \)
\end{itemize}


Dimostriamo ora \( \N \vDash V(q) \):

Da \( \N\vDash D(p,q) \) e dalla funzionalità della formula \( D \) segue \( \N \vDash (p, y ) \to y = q \).

Visto che abbiamo appena dimostrato \( \N \vDash \neg V(q) \), abbiamo {\color{gray}\small(se non vale per \( q \), sicuramente se \( y=q \) non vale per \( y \))}
\[ \N \vDash y = q \to \neg V(y) \]
Dunque, {\color{gray}\small(poiché \( \N \vDash (p, y ) \to y = q \))}, abbiamo anche
\[ \N \vDash D(p, y)\to \neg V(y) \]

Se vale con variabile libera allora vale anche nella forma
\[ \N \vDash \forall y (D(p, y)\to \neg V(y)) \]
che è esattamente \( A(p) \).

Dunque, \( A(p)\in Th(\N) \), ovvero \( A(p) \) è una verità aritmetica.

Quindi, dato che \( V \) rappresenta \( Th(\N) \), abbiamo
\[ \N \vDash V(code(A(p))) = V(q) \]
il che è impossibile.

Abbiamo quindi:
\begin{corframe}{}{}
    L'insieme delle verità aritmetiche \( Th(\N) \) non è algoritmicamente decidibile.
\end{corframe}

\subsection{Prima forma debole di Incompletezza}
Otteniamo quindi una prima forma debole del Primo Teorema di Incompletezza di Gödel
\begin{thmframe}{Primo Teorema di Incompletezza (forma debole)}{}
    Se \( T \) è una teoria decidibile e tale che \( \N \vDash T \), allora \( T \) non è completa: esiste un enunciato \( G \) tale che \( T\not\vDash G \land T \not\vdash\neg G \)
\end{thmframe}
\begin{pframe}
    Se \( T \) fosse completa, dato che \( \N\vDash T \) seguirebbe che \( \{E \mid T\vdash E\} \subseteq \{E \mid \N \vDash E\} \). In più, per completezza, poiché abbiamo \( T\vdash E \xor T\vdash \neg E \), e poiché, visto che \( \N \vDash T \), \( E \) è o vero o falso in \( \N \), abbiamo
    \[  \{E \mid T\vdash E\} = \{E \mid \N \vDash E\} =Th(\N)  \]
    Sapendo che \( Th(\N) \) non è decidibile, otteniamo che:
    \begin{itemize}
        \item se \( T \) decidibile e completa, allora i teoremi di \( T \) sono decidibili
        \item se \( T \) completa e \( \N \vDash T \) allora i teoremi di \( T \) sono indecidibili
    \end{itemize}
    ovvero, se \( \N \vDash T \), è impossibile che \( T \) sia sia completa che decidibile.
\end{pframe}

\section{Primo Teorema di Incompletezza di Gödel}
\begin{thmframe}{Primo Teorema di Incompletezza}{}
    Se \( T \) è decidibile, coerente e contiene un minimo di aritmetica (MA, aritmetica minimale), allora \( T  \) è incompleta.

    \begin{gframe}{}
        NB: in realtà, Gödel ha dimostrato una versione più debole che assume la \( \omega\)-coerenza (e non la coerenza)
    \end{gframe}
\end{thmframe}

La differenza principale di questa versione rispetto a quella precedente è che non si assume \( \N \vDash T \): le ipotesi su \( T \) sono di natura sintattica e non fanno riferimento a strutture infinite o al concetto semantico di soddisfacibilità.

\subsection{Aritmetica minimale (MA)}
L'aritmetica minimale è assiomatizzata dai seguenti assiomi nel linguaggio \( \{0, 1, +, \times\} \). Per ogni \( n\in \N \) denotiamo con \( n \) il termine ottenuto sommando la costante \( 1 \) a se stessa \( n \) volte.
\begin{mdframed}
        \begin{itemize}
            \item[(Ax 1)] \( 0 + 1 = 1 \)
            \item[(Ax 2)] \( \forall x(x + 1 \neq 0) \)
            \item[(Ax 3)] \( \forall x(x \neq 0 \to \exists z(z + 1 = x)) \)
            \item[(Ax 4)] \( \forall x\forall y(x + 1 = y + 1 \to x = y) \)
            \item[(Ax 5)] \( \forall x(x + 0 = x) \)
            \item[(Ax 6)] \( \forall x\forall y(x + (y + 1) = (x + y) + 1) \)
            \item[(Ax 7)] \( \forall x(x \times 0 = 0) \)
            \item[(Ax 8)] \( \forall x\forall y(x \times (y + 1) = (x \times y) + x) \)
            \item[(Ax 9)] \( \forall x\forall y(x < y \lor x = y \lor y < x) \)
        \end{itemize}
\end{mdframed}

Dobbiamo verificare che MA sia sufficiente a rappresentare tutte le funzioni calcolabili.

\begin{defframe}{Rappresentabilità di una funzione in una teoria}{}
Una funzione \( \varphi : \N^k \to \N \) è rappresentabile in una teoria \( T \) se esiste una formula \( F_{\varphi}(x_1, \dots, x_k, z) \) nel linguaggio di \( T \) tale che
\[
T \vdash (\forall x_1)\dots(\forall x_k)(\forall y)(\forall z)[F_{\varphi}(x_1, \dots, x_k, y) \land F_{\varphi}(x_1, \dots, x_k, z) \to y = z],
\]
e per ogni \( n_1, \dots, n_k, m \) in \( \N \)
\[
\text{Se } \varphi(n_1, \dots, n_k) = m \text{ allora } T \vdash F_{\varphi}(\bar{n}_1, \dots, \bar{n}_k, \bar{m}).
\]
(se l'ultima implicazione si inverte, si parla di \textit{rappresentabilità forte}).
\end{defframe}

\begin{thmframe}{Rappresentabilità in MA}{}
    Tutte le funzioni calcolabili sono rappresentabili in MA.
    \begin{proofframe}{}{}
        La dimostrazione segue quella del Teorema di Rappresentabilità delle funzioni computabili in \( \N \) sostituendo gli argomenti semantici (\( \N \vDash \)) con argomenti sintattici MA (\( \vdash\)).
    \end{proofframe}
\end{thmframe}


\begin{defframe}{Rappresentabilità di una relazione in una teoria}{}
Una relazione \( R \subseteq \N^k \) è rappresentabile in una teoria \( T \) se esiste una formula \( F_R(x_1, \dots, x_k) \) nel linguaggio di \( T \) con \( k \) variabili libere tale che
\begin{itemize}
    \item[(1)] Se \( (n_1, \dots, n_k) \in R \) allora \( T \vdash F_R(\bar{n}_1, \dots, \bar{n}_k) \),
    \item[(2)] Se \( (n_1, \dots, n_k) \notin R \) allora \( T \vdash \neg F_R(\bar{n}_1, \dots, \bar{n}_k) \)
\end{itemize}
\begin{gframe}{}
    Se ogni funzione è rappresentabile, ogni relazione è rappresentabile.
\end{gframe}
\end{defframe}

\subsection{Il teorema}
Gödel ha individuato una relazione binaria \( R \subseteq \N \times \N \) tale che:
\begin{align*}
    (m, n) \in R \iff & m \text{ è il codice numerico di una formula \( A \) con una variabile libera e}\\
                      & n \text{ è il codice numerico di una dimostrazione in \( T \) di \( A(\overline{m}) \) }
\end{align*}

Notiamo che questa relazione è \textbf{calcolabile} (poiché \( T \) è decidibile, posso controllare algoritmicamente se una sequenza di formule è una dimostrazione valida). È quindi anche \textbf{rappresentabile} in \( T \) da una formula \( F(x, y) \) tale che:
\begin{itemize}
    \item \( (m, n)\in R \implies T\vdash F(m, n) \)
    \item \( (m, n)\not\in R \implies T\vdash \neg F(m, n) \)
\end{itemize}

Consideriamo l'enunciato \( A(x)\equiv \forall y \neg F(x, y) \) (che dice ``non esiste una dimostrazione di me stesso'') 

Sia \( m \) il codice di \( A(x) \). 

Abbiamo che \( G = A(\bar{m}) \equiv \forall y \neg F(\bar{m}, y) \), ovvero ``per ogni \( y \), \( y \) non è il codice di una dimostrazione della formula che ha codice \( m \)'' (ovvero \( A(\bar{m}) \) stessa).

\begin{lemmaframe}{}{}
    \( G \) non è dimostrabile né refutabile in \( T \), ovvero:
    \[ T\not\vdash  \forall y \neg F(\bar{m}, y)  \]
    \[ T\not\vdash \neg(\forall y \neg F(\bar{m}, y)) \]
\end{lemmaframe}
\begin{pframe}
    \begin{enumerate}
        \item \( T\not\vdash  \forall y \neg F(\bar{m}, y) \)
           
            Supponiamo per assurdo \( T \) coerente e \( T \vdash \forall y \neg F(\bar{m}, y)  \).

            Vuol dire che ne esiste una dimostrazione con derivazione formale. Sia \( n \) il codice di una tale derivazione. Poiché \( n \) è la dimostrazione di \( G \), si ha \( (m, n)\in R \). 

            Poiché \( R \) è rappresentata da \( F \), otteniamo che \( T\vdash F(\bar{m}, n) \), quindi 
            \[ T\vdash \exists y F(\bar{m}, n) \]
            che è esattamente l'opposto dell'ipotesi \( T \vdash \forall y \neg F(\bar{m}, y)   \) (ovvero avremmo \( T \) incoerente)


        \item \( T\not\vdash  \forall y \neg F(\bar{m}, y) \)

            Supponiamo per assurdo \(T\vdash\neg (\forall y \neg F(\bar{m}, y))\equiv \exists y F(m, y)\).
            (ovvero, in termini intuitivi, ``Esiste un numero \( y \) che è il codice della dimostrazione di \( G \)''

            Dalla prima parte del teorema (basata sulla semplice coerenza), sappiamo però che \( G \) non è dimostrabile. Pertanto, nessun numero naturale \(  n \in \mathbb{N}\) corrisponde al codice di una sua dimostrazione.
Poiché la teoria \( T \) è corretta nel verificare le proprietà calcolabili (rappresentabilità forte), per ogni specifico numero \( n \) la teoria dimostra che esso non è la dimostrazione cercata:
\[
\forall n \in \mathbb{N}, \quad T \vdash \neg F(m, n)
\]

Sorge questa situazione apparentemente paradossale:
\begin{itemize}
    \item  La teoria dice \( \exists y \)
    \item  Ma dice anche \( \forall n \in \mathbb{N}, \quad T \vdash \neg F(m, n)\)
\end{itemize}
La semplice coerenza logica non vieta questa situazione (la teoria potrebbe riferirsi a un elemento ``infinito'' non standard). Per escludere questo caso, Gödel introduce la \textbf{$\omega$-coerenza}.

\begin{defframe}{$\omega$-coerenza}{}
Una teoria $T$ è $\omega$-coerente se non accade mai che:
\[
T \vdash \exists x \varphi(x) \quad \text{e contemporaneamente} \quad \forall n \in \mathbb{N}, \; T \vdash \neg \varphi(n)
\]
\end{defframe}
Se assumiamo che \( T \) sia \(\omega\)-coerente, la situazione descritta sopra è impossibile.
Poiché \(\forall n \in \mathbb{N}, \quad T \vdash \neg F(m, n) \) è un fatto vero e inevitabile, dobbiamo rifiutare l'ipotesi iniziale \(T\vdash \exists y F(m, y) \).

Quindi, se \( T \) è \(\omega\)-coerente, \(\neg G\) non è dimostrabile in \( T \).

    \end{enumerate}
\end{pframe}

Possiamo quindi formulare più accuratamente il Primo Teorema di Incompletezza:
\begin{thmframe}{Primo Teorema di Incompletezza}{}
    Sia \( T \) una teoria formale che estende MA.
    \begin{itemize}
        \item se \( T \) è coerente, allora \( G \) è indimostrabile in \( T \)
        \item se \( T \) è \( \omega\)-coerente, allora \( \neg G \) è indimostrabile in \( T \)
    \end{itemize}

    Dunque, se \( T \) è \( \omega\)-coerente, \( T \) è incompleta.
\end{thmframe}


\end{document}
